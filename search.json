[{"title":"Cookie 使用总结","url":"/931d8cd0-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n1 常用属性及描述\nname，Cookie 的名称，Cookie 一旦创建，名称便不可更改\nvalue，Cookie 的值。如果值为 Unicode 字符，需要为字符编码。如果值为二进制数据，则需要使用 BASE64 编码\nmaxAge，Cookie 失效的时间，单位秒。如果为正数，则该 Cookie 在 maxAge 秒之后失效。如果为负数，该 Cookie 为临时 Cookie，关闭浏览器即失效，浏览器也不会以任何形式保存该 Cookie。如果为 0，表示删除该 Cookie。默认为 -1。\nsecure，该 Cookie 是否仅被使用安全协议传输。安全协议。安全协议有 HTTPS，SSL 等，在网络上传输数据之前先将数据加密。默认为 false。\npath，Cookie 的使用路径。如果设置为 /sessionWeb/，则只有 contextPath 为 /sessionWeb 的程序可以访问该 Cookie。如果设置为 /，则本域名下 contextPath 都可以访问该 Cookie。\n注意：最后一个字符必须为 /\n\n\ndomain，可以访问该 Cookie 的域名。如果设置为 .google.com，则所有以 google.com 结尾的域名都可以访问该 Cookie\n注意：第一个字符必须为 .\n\n\ncomment，该 Cookie 的用处说明，浏览器显示 Cookie 信息的时候显示该说明。\nversion，Cookie 使用的版本号，0 表示遵循 Netscape 的 Cookie 规范，1 表示遵循 W3C 的 RFC 2109 规范\n\n2 Cookie 的有效期Cookie 的 maxAge 决定着 Cookie 的有效期，单位为秒（Second）。Cookie 中通过 getMaxAge() 方法与 setMaxAge(int maxAge) 方法来读写 maxAge 属性。\n如果 maxAge 属性为正数，则表示该 Cookie 会在 maxAge 秒之后自动失效。浏览器会将 maxAge 为正数的 Cookie 持久化，即写到对应的 Cookie 文件中。无论客户关闭了浏览器还是电脑，只要还在 maxAge 秒之前，登录网站时该 Cookie 仍然有效。下面代码中的 Cookie 信息将永远有效。\n如果 maxAge 为负数，则表示该 Cookie 仅在本浏览器窗口以及本窗口打开的子窗口内有效，关闭窗口后该 Cookie 即失效。maxAge 为负数的 Cookie，为临时性 Cookie，不会被持久化，不会被写到 Cookie 文件中。Cookie 信息保存在浏览器内存中，因此关闭浏览器该 Cookie 就消失了。Cookie 默认的 maxAge 值为-1。\n如果 maxAge 为 0，则表示删除该 Cookie。Cookie 机制没有提供删除 Cookie 的方法，因此通过设置该 Cookie 即时失效实现删除 Cookie 的效果。失效的 Cookie 会被浏览器从 Cookie 文件或者内存中删除，\nresponse 对象提供的 Cookie 操作方法只有一个添加操作 add(Cookie cookie)\n要想修改 Cookie 只能使用一个同名的 Cookie 来覆盖原来的 Cookie，达到修改的目的。删除时只需要把 maxAge 修改为 0 即可。\n从客户端读取 Cookie 时，包括 maxAge 在内的其他属性都是不可读的，也不会被提交。浏览器提交 Cookie 时只会提交 name 与 value 属性。maxAge 属性只被浏览器用来判断 Cookie 是否过期。\n3 Cookie 的修改、删除Cookie 并不提供修改、删除操作。如果要修改某个 Cookie，只需要新建一个同名的 Cookie，添加到 response 中覆盖原来的 Cookie。\n如果要删除某个 Cookie，只需要新建一个同名的 Cookie，并将 maxAge 设置为 0，并添加到 response 中覆盖原来的 Cookie。\n\n注意：修改、删除 Cookie 时，新建的 Cookie 除 value、maxAge 之外的所有属性，例如 name、path、domain 等，都要与原 Cookie 完全一样。否则，浏览器将视为两个不同的 Cookie 不予覆盖，导致修改、删除失败。\n\n4 Cookie 的域名Cookie 是不可跨域名的。域名 www.google.com 颁发的 Cookie 不会被提交到域名 www.baidu.com。这是由 Cookie 的隐私安全机制决定的。隐私安全机制能够禁止网站非法获取其他网站的 Cookie。\n正常情况下，同一个一级域名下的两个二级域名如 www.baidu.com 和 p_w_picpaths.baidu.com 也不能交互使用 Cookie，因为二者的域名并不严格相同。如果想所有 baidu.com 名下的二级域名都可以使用该 Cookie，需要设置 Cookie 的 domain 参数为 .baidu.com\n可以修改本机 C:\\WINDOWS\\system32\\drivers\\etc 下的 hosts 文件来配置多个临时域名来验证 domain 属性。\n\n注意：domain 参数必须以点（.）开始。另外，name 相同但 domain 不同的两个 Cookie 是两个不同的 Cookie。如果想要两个域名完全不同的网站共有 Cookie，可以生成两个 Cookie，domain 属性分别为两个域名，输出到客户端。\n\n5 Cookie 的路径domain 属性决定运行访问 Cookie 的域名，而 path 属性决定允许访问 Cookie 的路径（ContextPath）。例如，如果只允许 /sessionWeb/ 下的程序使用 Cookie，可以这么写 cookie.setPath(&quot;/session/&quot;);\n设置为 / 时允许所有路径使用 Cookie。path 属性需要使用符号 / 结尾。name 相同但 domain 相同的两个 Cookie 也是两个不同的 Cookie。\n页面只能获取它属于的 Path 的 Cookie。例如 /session/test/a.jsp 不能获取到路径为 /session/abc/ 的 Cookie。\n6 Cookie 的安全属性HTTP 协议不仅是无状态的，而且是不安全的。使用 HTTP 协议的数据不经过任何加密就直接在网络上传播，有被截获的可能。使用 HTTP 协议传输很机密的内容是一种隐患。如果不希望 Cookie 在 HTTP 等非安全协议中传输，可以设置 Cookie 的 secure 属性为 true。浏览器只会在 HTTPS 和 SSL 等安全协议中传输此类 Cookie。设置 secure 属性为 true 的代码是 cookie.setSecure(true);\nsecure 属性并不能对 Cookie 内容加密，因而不能保证绝对的安全性。如果需要高安全性，需要在程序中对 Cookie 内容加密、解密，以防泄密。\n7 JavaScript 操作 CookieCookie 是保存在浏览器端的，因此浏览器具有操作 Cookie 的先决条件。浏览器可以使用脚本程序如 JavaScript 或者 VBScript 等操作 Cookie。这里以 JavaScript 为例介绍常用的 Cookie 操作。例如下面的代码会输出本页面所有的 Cookie。\n&lt;script&gt;  document.write(document.cookie);&lt;/script&gt;\n\n由于 JavaScript 能够任意地读写 Cookie，给网站带来安全隐患，W3C 标准的浏览器会阻止 JavaScript 读写任何不属于自己网站的 Cookie。换句话说，A 网站的 JavaScript 程序读写 B 网站的 Cookie 不会有任何结果。\n部分浏览器支持设置 HttpOnly 属性，如果在 cookie 中设置了 HttpOnly 属性，那么通过 js 脚本将无法读取到 cookie 信息，这样能有效的防止 XSS\n8 在 Java 服务端使用注意不能直接使用逗号这种特殊符号（对 cookie 0 版本标准而言，新版本 cookie 1 没问题）作为 cookie 的内容。而新版本的 Cookie（参见 RFC 2109）目前还不被 Javax.servlet.http.Cookie 包所支持。Cookie Version 0 中，某些特殊的字符，例如：空格，方括号，圆括号，等于号，逗号，双引号，斜杠，问号，@符号，冒号，分号都不能作为 Cookie 的内容。\n9 在前端使用注意前端请求如果携带 cookie 信息，那么后端 Access-Control-Allow-Origin 不能为 *，否则该请求会失败，在 Options 预请求时会被拦截下来。可参见 MDN 文档 ：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Access_control_CORS， 在 springboot 中，可以增加 .allowCredentials(true) 设置，如下代码所示：\n@Configurationpublic class WebConfig implements WebMvcConfigurer &#123;    @Override    public void addCorsMappings(CorsRegistry registry) &#123;        registry.addMapping(&quot;/**&quot;)                .allowedHeaders(&quot;*&quot;)                .allowedMethods(&quot;*&quot;)                .maxAge(1800)                .allowedOrigins(&quot;*&quot;)                // 允许携带cookie                .allowCredentials(true);    &#125;&#125;\n\n10 fetch 发送请求携带 cookie 的设置fetch 发送请求默认是不发送 cookie 的，不管是同域还是跨域；对于那些需要权限验证的请求就可能无法正常获取数据，这时需要设置 fetch 的第二个参数，即 credentials：\nfetch(url, &#123; credentials: &quot;include&quot; &#125;);\n\ncredentials 有 3 个可选值：\n\nomit: 忽略 cookie 的发送\nsame-origin: 表示 cookie 只能同域发送，不能跨域发送\ninclude: cookie 既可以同域发送，也可以跨域发送\n\nfetch 默认对服务端通过 Set-Cookie 头设置的 cookie 也会忽略，若想选择接受来自服务端的 cookie 信息，也必须要配置 credentials 选项。\n","categories":["前端技术"],"tags":["cookie"]},{"title":"React 有关计时器和数组状态的问题","url":"/bff79390-6294-11ef-9fbd-1b8fc76b8368/","content":"\n\n\n\n1、useState 为数组1）反例\n定义一个 useState 和生成数据的方法\nconst [rows, setRows] = React.useState([]);function createData(column1, column2, column3, column4) &#123;  const column5 = column3 / column4;  return &#123; column1, column2, column3, column4, column5 &#125;;&#125;\n\n按照常规，试图增加元素时，使用以下代码是不生效的：\nsetRows([...rows, createData(column1, column2, column3, column4)]);\n\n如果取 rows 遍历，发现数组只会有最后更新的元素\n2）正例\nsetRows((prevRows) =&gt; [...prevRows,createData(column1, column2, column3, column4),]);\n\n2、 useEffect 中使用定时器所产生的闭包陷阱1）反例\nconst callBack = () =&gt; &#123;    ……    setRows((prevRows) =&gt; [...prevRows, createData(column1, column2, column3, column4)])&#125;useEffect(() =&gt; &#123;    const intervalId = setInterval(&#123;        ……        setRows((prevRows) =&gt; [...prevRows, createData(column1, column2, column3, column4)])    &#125;, 5000)    console.log(&#x27;intervalId=&#x27; + intervalId)    return () =&gt; clearInterval(intervalId)&#125;, [])\n\n运行后观察控制台，会不断输出计时器 id，说明每次执行间隔就创建一次。有关说明可见文章：making-setinterval-declarative-with-react-hooks\n2）正例\nconst intervalRef = useRef()const callBack = () =&gt; &#123;    ……    setRows((prevRows) =&gt; [...prevRows, createData(column1, column2, column3, column4)])&#125;useEffect(() =&gt; &#123;    intervalRef.current = callBack    return () =&gt; &#123;&#125;&#125;)useEffect(() =&gt; &#123;    const tick = () =&gt; &#123;        intervalRef.current()    &#125;    const intervalId = setInterval(tick, 5000)    console.log(&#x27;intervalId=&#x27; + intervalId)    return () =&gt; clearInterval(intervalId)&#125;, [])\n","categories":["前端技术"],"tags":["react","hooks"]},{"title":"create-react-app 脚手架引入 SCSS","url":"/931db3e0-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n1 环境\nreact-scripts 3.4.3\nreact 16.13.1\n\n2 解决方案使用 create-react-app 创建项目后执行以下命令即可。\nnpm install sass-loader node-sass --save-dev\n","categories":["前端技术"],"tags":["react"]},{"title":"exports、module.exports、export 和 export default 的案例和原理解析","url":"/931ddaf0-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n1 案例构建如下几个主要文件用于测试。\n├── src    ├── exports.js    ├── module-exports.js    ├── ES6-export.js    ├── ES6-export-default.js    └── index.js\n\n为便于比较，他们的结构大致相同：\n\nexports.js\n\nvar printMsg = function printMsg() &#123;  console.log(&quot;this message comes from exports&quot;);&#125;;exports.printMsg = printMsg;console.log(exports);console.log(module.exports);console.log(exports === module.exports);\n\n\nmodule-exports.js\n\nvar printMsg = function printMsg() &#123;  console.log(&quot;this message comes from module-exports&quot;);&#125;;module.exports = printMsg;console.log(exports);console.log(module.exports);console.log(exports === module.exports);\n\n\nES6-export.js\n\nvar printMsg = function printMsg() &#123;  console.log(&quot;this message comes from ES6-export&quot;);&#125;;export &#123; printMsg &#125;;\n\n\nES6-export-default.js\n\nvar printMsg = function printMsg() &#123;  console.log(&quot;this message comes from ES6-export-default&quot;);&#125;;export default printMsg;\n\n\nindex.js\n\nimport React from &quot;react&quot;;import ReactDOM from &quot;react-dom&quot;;import exports_test from &quot;./exports&quot;;import module_exports_test from &quot;./module-exports&quot;;import &#123; printMsg &#125; from &quot;./ES6-export&quot;;import any_name from &quot;./ES6-export-default&quot;;class App extends React.PureComponent &#123;  componentDidMount() &#123;    exports_test.printMsg();    module_exports_test();    printMsg();    any_name();  &#125;  render() &#123;    return null;  &#125;&#125;ReactDOM.render(&lt;App /&gt;, document.getElementById(&quot;root&quot;));\n\n执行后，控制台输出结果如下：\nObject &#123; printMsg: printMsg() &#125;Object &#123; printMsg: printMsg() &#125;trueObject &#123;  &#125;function printMsg()falsethis message comes from exportsthis message comes from module-exportsthis message comes from ES6-exportthis message comes from ES6-export-default\n\nCommonJS 是 NodeJs 服务器端模块的规范，ES Module 是在 ES5 中推出的，基于 CommonJS 规范，而 export 和 export default 是 ES6 中的模块化加载语法。在这之前，必须了解 ES6 模块与 CommonJS 模块完全不同。它们有两个重大差异：\n\nCommonJS 模块输出的是一个值的拷贝，ES6 模块输出的是值的引用。\nCommonJS 模块是运行时加载，ES6 模块是编译时输出接口。\n\n第二个差异是因为 CommonJS 加载的是一个对象（即 module.exports 属性），该对象只有在脚本运行完才会生成。而 ES6 模块不是对象，它的对外接口只是一种静态定义，在代码静态解析阶段就会生成。\n2 ES5 中 exports 和 module.exports 的区别\nmodule.exports 才是真正的接口，exports 是它的一个辅助工具。\nnodejs 只会导出 module.exports 的指向，最终返回给调用者的是 module.exports，而不是 exports。\n所有的 exports 收集到的属性和方法，都赋值给了 module.exports。但前提是 module.exports 本身不具备任何属性和方法。如果 module.exports 已经具备一些属性和方法，那么从 exports 收集来的属性和方法将被忽略。\n\n从输出结果来看，也印证了这一点，在 module-exports.js 中的 console.log(exports); 输出的对象没有属性；而 exports.js 的两个输出是具有相同属性的对象。\n3 ES6 中 export 和 export default 区别\nexport 与 export default 均可用于导出常量、函数、文件、模块等。在一个文件或模块中 export、import 可以有多个，export default 仅有一个\nexport 方式只能具名导入，在导入时要加{ }\nexport default 则只能匿名导入\nexport 能直接导出变量表达式，export default 不行。\n\n","categories":["前端技术"],"tags":["js"]},{"title":"jsonp 技术的原理及案例","url":"/931ddaf1-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n1 JSONP 和 JSON说到 AJAX 就会不可避免的面临两个问题，第一个是 AJAX 以何种格式来交换数据？第二个是跨域的需求如何解决？这两个问题目前都有不同的解决方案，比如数据可以用自定义字符串或者用 XML 来描述，跨域可以通过服务器端代理来解决。具体来说，可用 JSON 来传数据，靠 JSONP 来跨域。\nJSON 是一种数据交换格式，而 JSONP 是一种非官方跨域数据交互协议。\n2 产生的背景1、Ajax 直接请求普通文件存在跨域无权限访问的问题，无论是静态页面、动态网页、web 服务、WCF，只要是跨域请求，一律不准；\n2、Web 页面上调用 js 文件时则不受是否跨域的影响（不仅如此，我们还发现凡是拥有 src 这个属性的标签都拥有跨域的能力，比如 &lt;script&gt;、&lt;img&gt;、&lt;iframe&gt;）；\n3、于是可以判断，当前阶段如果想通过纯 web 端（ActiveX 控件、服务端代理、Websocket 除外）跨域访问数据就只有一种可能，那就是在远程服务器上设法把数据装进 js 格式的文件里，供客户端调用和进一步处理；\n4、恰巧我们已经知道 json 这种纯字符数据格式可以简洁的描述复杂数据，更妙的是 json 还被 js 原生支持，所以在客户端几乎可以随心所欲的处理这种格式的数据；\n5、这样子解决方案就呼之欲出了，web 客户端通过与调用脚本一模一样的方式，来调用跨域服务器上动态生成的 js 格式文件（一般以 json 为后缀），显而易见，服务器之所以要动态生成 json 文件，目的就在于把客户端需要的数据装入进去。\n6、客户端在对 json 文件调用成功之后，也就获得了自己所需的数据，剩下的就是按照自己需求进行处理和展现了，这种获取远程数据的方式看起来非常像 AJAX，但其实并不一样。\n7、为了便于客户端使用数据，逐渐形成了一种非正式传输协议，人们把它称作 JSONP，该协议的一个要点就是允许用户传递一个 callback 参数给服务端，然后服务端返回数据时会将这个 callback 参数作为函数名来包裹住 JSON 数据，这样客户端就可以随意定制自己的函数来自动处理返回数据了。\n3 JSONP 的客户端具体实现不管 jQuery 也好，extjs 也罢，又或者是其他支持 jsonp 的框架，他们幕后所做的工作都是一样的，下面我来循序渐进的说明一下 jsonp 在客户端的实现：\n1、我们知道，对于跨域 js 文件中的代码（当然指符合 web 脚本安全策略的），web 页面也是可以无条件执行的。远程服务器 remoteserver.com 根目录下有个 remote.js 文件代码如下：\nalert(&quot;我是远程文件&quot;);\n\n本地服务器 localserver.com 下有个 jsonp.html 页面代码如下：\n&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;  &lt;head&gt;    &lt;title&gt;&lt;/title&gt;    &lt;script      type=&quot;text/javascript&quot;      src=&quot;http://remoteserver.com/remote.js&quot;    &gt;&lt;/script&gt;  &lt;/head&gt;  &lt;body&gt;&lt;/body&gt;&lt;/html&gt;\n\n毫无疑问，页面将会弹出一个提示窗体，显示跨域调用成功。\n2、现在我们在 jsonp.html 页面定义一个函数，然后在远程 remote.js 中传入数据进行调用。\njsonp.html 页面代码如下：\n&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;  &lt;head&gt;    &lt;title&gt;&lt;/title&gt;    &lt;script type=&quot;text/javascript&quot;&gt;      var localHandler = function (data) &#123;        alert(          &quot;我是本地函数，可以被跨域的remote.js文件调用，远程js带来的数据是：&quot; +            data.result        );      &#125;;    &lt;/script&gt;    &lt;script      type=&quot;text/javascript&quot;      src=&quot;http://remoteserver.com/remote.js&quot;    &gt;&lt;/script&gt;  &lt;/head&gt;  &lt;body&gt;&lt;/body&gt;&lt;/html&gt;\n\nremote.js 文件代码如下：\nlocalHandler(&#123; result: &quot;我是远程js带来的数据&quot; &#125;);\n\n运行之后查看结果，页面成功弹出提示窗口，显示本地函数被跨域的远程 js 调用成功，并且还接收到了远程 js 带来的数据。很欣喜，跨域远程获取数据的目的基本实现了，但是又一个问题出现了，我怎么让远程 js 知道它应该调用的本地函数叫什么名字呢？毕竟是 jsonp 的服务者都要面对很多服务对象，而这些服务对象各自的本地函数都不相同啊？我们接着往下看。\n3、聪明的开发者很容易想到，只要服务端提供的 js 脚本是动态生成的就行了呗，这样调用者可以传一个参数过去告诉服务端「我想要一段调用 XXX 函数的 js 代码，请你返回给我」，于是服务器就可以按照客户端的需求来生成 js 脚本并响应了。\n看 jsonp.html 页面的代码：\n&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;  &lt;head&gt;    &lt;title&gt;&lt;/title&gt;    &lt;script type=&quot;text/javascript&quot;&gt;      // 得到航班信息查询结果后的回调函数      var flightHandler = function (data) &#123;        alert(          &quot;你查询的航班结果是：票价 &quot; +            data.price +            &quot; 元，&quot; +            &quot;余票 &quot; +            data.tickets +            &quot; 张。&quot;        );      &#125;;      // 提供jsonp服务的url地址（不管是什么类型的地址，最终生成的返回值都是一段javascript代码）      var url =        &quot;http://flightQuery.com/jsonp/flightResult.aspx?code=CA1998&amp;callback=flightHandler&quot;;      // 创建script标签，设置其属性      var script = document.createElement(&quot;script&quot;);      script.setAttribute(&quot;src&quot;, url);      // 把script标签加入head，此时调用开始      document.getElementsByTagName(&quot;head&quot;)[0].appendChild(script);    &lt;/script&gt;  &lt;/head&gt;  &lt;body&gt;&lt;/body&gt;&lt;/html&gt;\n\n这次的代码变化比较大，不再直接把远程 js 文件写死，而是编码实现动态查询，而这也正是 jsonp 客户端实现的核心部分，本例中的重点也就在于如何完成 jsonp 调用的全过程。\n我们看到调用的 url 中传递了一个 code 参数，告诉服务器我要查的是 CA1998 次航班的信息，而 callback 参数则告诉服务器，我的本地回调函数叫做 flightHandler，所以请把查询结果传入这个函数中进行调用。\nOK，服务器很聪明，这个叫做 flightResult.aspx 的页面生成了一段这样的代码提供给 jsonp.html（服务端的实现这里就不演示了，与你选用的语言无关，说到底就是拼接字符串）：\nflightHandler(&#123;    &quot;code&quot;: &quot;CA1998&quot;,    &quot;price&quot;: 1780,    &quot;tickets&quot;: 5&#125;);\n\n我们看到，传递给 flightHandler 函数的是一个 json，它描述了航班的基本信息。运行一下页面，成功弹出提示窗口，jsonp 的执行全过程顺利完成！\n4、到这里为止的话，相信你已经能够理解 jsonp 的客户端实现原理了吧？剩下的就是如何把代码封装一下，以便于与用户界面交互，从而实现多次和重复调用。\n什么？你用的是 jQuery，想知道 jQuery 如何实现 jsonp 调用？好吧，那我就好人做到底，再给你一段 jQuery 使用 jsonp 的代码（我们依然沿用上面那个航班信息查询的例子，假定返回 jsonp 结果不变）：\n&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt; &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; &gt; &lt;head&gt;     &lt;title&gt;Untitled Page&lt;/title&gt;      &lt;script type=&quot;text/javascript&quot; src=jquery.min.js&quot;&gt;&lt;/script&gt;      &lt;script type=&quot;text/javascript&quot;&gt;     jQuery(document).ready(function()&#123;        $.ajax(&#123;             type: &quot;get&quot;,             async: false,             url: &quot;http://flightQuery.com/jsonp/flightResult.aspx?code=CA1998&quot;,             dataType: &quot;jsonp&quot;,             jsonp: &quot;callback&quot;,//传递给请求处理程序或页面的，用以获得jsonp回调函数名的参数名(一般默认为:callback)             jsonpCallback:&quot;flightHandler&quot;,//自定义的jsonp回调函数名称，默认为jQuery自动生成的随机函数名，也可以写&quot;?&quot;，jQuery会自动为你处理数据             success: function(json)&#123;                 alert(&#x27;您查询到航班信息：票价： &#x27; + json.price + &#x27; 元，余票： &#x27; + json.tickets + &#x27; 张。&#x27;);             &#125;,             error: function()&#123;                 alert(&#x27;fail&#x27;);             &#125;         &#125;);     &#125;);     &lt;/script&gt;     &lt;/head&gt;  &lt;body&gt;  &lt;/body&gt; &lt;/html&gt;\n\n是不是有点奇怪？为什么我这次没有写 flightHandler 这个函数而且竟然也运行成功了！这就是 jQuery 的功劳了，jquery 在处理 jsonp 类型的 ajax 时，自动帮你生成回调函数并把数据取出来供 success 属性方法来调用。\n4 针对 ajax 与 jsonp 之间异同的补充说明1、ajax 和 jsonp 这两种技术在调用方式上「看起来」很像，目的也一样，都是请求一个 url，然后把服务器返回的数据进行处理，因此 jquery 和 ext 等框架都把 jsonp 作为 ajax 的一种形式进行了封装；\n2、但 ajax 和 jsonp 其实本质上是不同的东西。ajax 的核心是通过 XmlHttpRequest 获取非本页内容，而 jsonp 的核心则是动态添加 &lt;script&gt; 标签来调用服务器提供的 js 脚本。\n3、所以说，其实 ajax 与 jsonp 的区别不在于是否跨域，ajax 通过服务端代理一样可以实现跨域，jsonp 本身也不排斥同域的数据的获取。\n4、还有就是，jsonp 是一种方式或者说非强制性协议，如同 ajax 一样，它也不一定非要用 json 格式来传递数据，如果你愿意，字符串都行，只不过这样不利于用 jsonp 提供公开服务。\n","categories":["前端技术"],"tags":["jsonp"]},{"title":"webpack 打包 ES6 扩展运算符时出错","url":"/931ddaf2-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n1 问题描述ERROR in ./src/router.jsxModule build failed (from ./node_ modules/babel-loader/lib/index.js):SyntaxError: C:/desk/copyiceworks/src/router.jsx: Unexpected token (36:55)&lt;Switch&gt;    &#123;routes.map((route, id) =&gt; &#123;        const &#123; component: RouteComponent, children, ...others ] = route;    return (        &lt;Route            key=&#123;id&#125;\n\n2 解决方案安装 babel-preset-stage-3\nnpm install babel-preset-stage-3 --save-dev\n\n修改配置文件，增加 &#39;stage-3&#39;\nmodule: &#123;    rules: [        &#123;            test: /\\.(js|jsx)$/,            use: &#123;                loader: &#x27;babel-loader&#x27;,                options: &#123;                    presets: [&#x27;es2015&#x27;, &#x27;react&#x27;, &#x27;stage-3&#x27;],                &#125;            &#125;,            exclude: /node_modules/        &#125;    ]&#125;\n\n不过从 Babel v7 开始，所有针对处于标准提案阶段的功能所编写的预设（stage preset）都已被弃用。详见 官方说明。针对上述问题，在 7.6.x 中使用 @babel&#x2F;plugin-proposal-object-rest-spread 插件：\nnpm install @babel/plugin-proposal-object-rest-spread --save-dev\n\n附加内容：升级到 Babel 7.x 相关的名称改变：\n\nbabel-core → @babel&#x2F;core\nbabel-loader 名称未改变\nbabel-preset-react → @babel&#x2F;preset-react\nbabel-preset-es2015 → @babel&#x2F;preset-es2015，但是有提示如下：\n\nnpm WARN deprecated @babel/preset-es2015@7.0.0-beta.53: ????We&#x27;ve deprecated any official yearly presets in 6.x in favor or babel-preset-env.For 7.x it would be @babel/preset-env.\n\n因此，在 7.x 中，应安装 @babel&#x2F;preset-env\n注意：对应的配置文件也要修改名称\nmodule: &#123;    rules: [        &#123;            test: /\\.(js|jsx)$/,            use: &#123;                loader: &#x27;babel-loader&#x27;,                options: &#123;                    presets: [&#x27;@babel/preset-env&#x27;, &#x27;@babel/preset-react&#x27;],                    &quot;plugins&quot;: [                        &quot;@babel/plugin-proposal-object-rest-spread&quot;                    ]                &#125;            &#125;,            exclude: /node_modules/        &#125;    ]&#125;\n","categories":["前端技术"],"tags":["webpack"]},{"title":"webpack 配置 vue 基础环境的笔记","url":"/931e0200-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n一、webpack 的配置和使用0 主要组件版本\nnpm：5.6.0\nwebpack：4.29.6\nnode：8.11.3\nbabel：6.26.3\nVue：2.6.10\n\n1 安装webpack 依赖于 node.js，需要先进行 node.js 的安装，再运行 npm init 命令初始化项目。填写完提示信息后（可全部回车最后选 Y），在目录生成 package.json 文件。注：也可使用 npm init –y，从当前目录中提取的信息生成默认的 package.json，创建过程中不会提问。可参考建立以下目录结构：\n.├── dist（存放产品输出）├── src（存放 css、js、html 文件）├── node_modules├── package.json（应用程序的信息）├── package-lock.json\n\n1.1 全局安装 webpack运行命令 npm install webpack -g，这样就能在全局使用 webpack 的命令，在项目中即使安装了本地 webpack，也无法识别命令。\n1.2 本地安装 webpack在项目根目录中运行 npm i webpack --save-dev 安装到项目开发环境依赖中。\n注意：在 webpack 3.x 及之前版本，CLI 已经整合，但是 4.x 版本将两者分开，需要另外安装，否则会提示 Cannot find module ‘webpack-cli&#x2F;bin&#x2F;config-yargs’，输入查看版本号命令 npm -v 时，也会提示安装。执行 npm install webpack-cli –g 全局安装即可。\n附加内容：查看&#x2F;修改 npm 默认的全局安装目录\n\n查看：使用命令 npm config ls，查看 prefix 值可知当前默认的全局安装目录。\n修改：使用命令 npm config set prefix &quot;D:\\npm_global_modules&quot;\n\n附加内容：npm 下载使用淘宝镜像使用命令 npm install cnpm -g --registry=https://registry.npm.taobao.org\n附加内容：什么时候用本地或全局安装\n\n当试图安装命令行工具的时候，例如 grunt CLI 的时候，使用全局安装。全局安装的方式：npm install &lt;name&gt; -g\n当试图通过 npm 安装某个模块，并通过 require(&#39;xx&#39;) 的方式引入的时候，使用本地安装。\n\n附加内容：npm –save 和 npm –save-dev 的区别\n\nnpm install &lt;name&gt; 安装好后，写入 package.json 的 dependencies 中（生产环境依赖）\nnpm install &lt;name&gt; --save 安装好后写入 package.json 的 dependencies 中（生产环境依赖）。在 npm 5 之后的版本可以用 npm install &lt;name&gt; --save-prod，同样的效果。\nnpm install &lt;name&gt; --save-dev 安装好后写入 package.json 的 devDepencies 中（开发环境依赖），如果在 dependencies 存在，则移动到 devDepencies。\ndependencies 是运行时依赖，devDependencies 是开发时的依赖。devDependencies 下列出的模块是开发时用的，比如我们安装 js 的压缩包 gulp-uglify 时，我们采用的是 npm install --save-dev gulp-uglify 命令安装，因为我们在发布后用不到它，而只是在我们开发才用到它。dependencies 下的模块，则是我们发布后还需要依赖的模块，如 jQuery 库，在开发完后还要依赖，否则无法运行。\n\n附加内容：查看和删除模块\n\n查看全局新安装模块：npm list -g --depth 0\n删除全局模块：npm uninstall &lt;name&gt; -g\n删除本地模块：npm uninstall &lt;name&gt;，删除模块时，无论安装在 dependencies 还是 devDepencies 中都会删除，并更新在 package.json 中的对应信息。命令后面加不加 --save 或 --save-dev 参数效果都一样。\n\n附加内容：查看最新和所有版本\n\n查看所有版本：npm view webpack versions\n查看最新版本：npm view webpack version\n查看版本及版本信息：npm info webpack\n\n附加内容：查看所有包的最新版本\n\nnpm outdated -g\n\n附加内容：全局包升级到最新版本\n\nnpm install –g &lt;name&gt;\n\n注：默认方式只能逐个升级。\n附加内容：安装指定版本的包\n\n在包名后添加版本：npm install jquery@3.0.0 --save-dev\n\n附加内容：排除 node_modules 目录npm install 命令可以自动安装当前目录下 package.json 中记录下来的包。因此，复制项目或上传项目时，可以排除 node_modules 目录。例如在 .ignore 中添加：node_modules/。\n2 配置2.1 webpack 4.x 的配置变化（与旧版本相比）\nwebpack 4.x 中，CLI 被移动到了一个专门的包 webpack-cli 里了, 需要全局安装 webpack-cli：npm install webpack-cli -g\n输出命令 webpack &lt;目标路径&gt; &lt;输出路径&gt; 在 4.x 版本不能再使用，必须使用配置文件 webpack.config.js。\n配置文件 webpack.config.js 不再支持 module 下的 loaders，需要把 loaders 改成 rules，如下所示：\n\nmodule: &#123;  rules: [    //针对css文件，进行对应的loader处理    &#123; test: /\\.css$/, loader: &quot;style-loader!css-loader&quot; &#125;,  ];&#125;\n\n\n新增配置项 mode，取值 ‘development’ 或 ‘production’，例如：\n\nmodule.exports = &#123;  mode: &quot;production&quot;,&#125;;\n\n\n为了更加简便，并实现自动打包、编译，页面自动刷新的功能，可安装 webpack-dev-server。使用命令：npm install webpack-dev-server --save-dev\n\n注意 1：使用 webpack-dev-server 要求 webpack 必须在本地安装，即使全局安装过，也要执行一次本地安装。webpack-cli 全局安装即可，不用在本地安装。\n注意 2：本地安装的 webpack-dev-server 无法作为脚本命令在 powershell 终端中直接运行，只有安装到全局才能在终端中正常执行。\n注意 3：安装完成后需要在 package.json 中 &lt;script&gt; 添加下列语句：\n&quot;dev&quot;:&quot;webpack-dev-server --open --config webpack.config.js&quot;\n\n表示添加启动命令 dev，运行时自动打开默认浏览器展示效果，指定配置文件。系列参数也可以在配置文件中设置，在 webpack.config.js 增加 dev-server 配置项即可（不推荐这种方式，推荐用命令）：\n  devServer: &#123;    open: true, // 自动打开浏览器    port: 3000, // 设置启动时候的运行端口contentBase: &#x27;src&#x27;, // 指定托管的根目录，自动打开时以此目录为基础找index.html    hot: true // 启用热更新（第一步）。在配置文件中设置热部署（第二步），在webpack.config.js中增加一项：const webpack = require(&#x27;webpack&#x27;)  &#125; ,  plugins: [new webpack.HotModuleReplacementPlugin() // 实例化一个热更新的模块对象（第三步）]\n\n以上配置等同于在 package.json 中 &lt;script&gt; 添加：\n&quot;dev&quot;:&quot;webpack-dev-server --open --port 3000 --contentBase src --hot&quot;\n\n配置完成后，使用命令：npm run dev，即可打开页面。\n注意：用命令配置最为简便。而且经过试验，在 webpack 4.x 中已经自带热更新，如果命令中使用参数 --hot，执行 npm run dev 后反而不会自动刷新。\n3 使用（1）创建 main.js 文件，将项目依赖都写在这里。\n（2）例如，本地安装 jquery 3.0.0，执行 npm install jquery@3.0.0 --save-dev\n（4）在 main.js 中，引入本地 jquery，使用命令：import $ from &#39;jquery&#39;，这种是 ES6 中导入模块的方式，部分浏览器可能不支持 ES6 语法，需要用 webpack 处理。webpack 不仅能够处理 JS 文件的互相依赖关系，还能够处理 JS 的兼容问题，把高级的、浏览器不识别的语法，转为低级的，能正常识别的语法。\n（5）将 main.js 用 webpack 进行处理。输入命令：webpack .\\src\\main.js .\\dist\\bundle.js，（注意：这种方式在 4.x 版本不能再使用，必须使用配置文件）指定目标和输出目录。每次都要手动指定目录非常不便，此时在配置文件 webpack.config.js 中设置入口和出口，之后直接使用 webpack 命令即可输出。配置文件内容：\nconst path = require(&quot;path&quot;);module.exports = &#123;  // 指定入口，表示要使用 webpack 打包的文件  entry: path.join(__dirname, &quot;./src/main.js&quot;),  // 输出文件相关的配置  output: &#123;    path: path.join(__dirname, &quot;./dist&quot;), // 指定打包好的文件的输出目录    filename: &quot;bundle.js&quot;, // 指定输出的文件的名称  &#125;,&#125;;\n\n4 输出webpack-dev-server 帮我们打包生成的 bundle.js 文件，并没有存放到实际的物理磁盘上，而是托管到了内存中，项目根目录中，找不到这个打包好的 bundle.js。可以认为 webpack-dev-server 把打包好的文件，以一种虚拟的形式，托管到项目的根目录中，虽然看不到它，但是它和 dist、src、node_modules 目录平级，能够在浏览器地址栏可输入：http://localhost:8080/bundle.js 访问到，在 index.html 页面中的引用，应使用根目录的 bundle.js，即：&lt;script src=&quot;/bundle.js&quot;&gt;，放到内存中能够不受硬盘转速影响，提高实时打包速度，减少硬盘读写。\n4.1 使用 html-webpack-plugin 插件。使用该插件之后，我们不再需要手动处理 bundle.js 的引用路径了，因为这个插件已经帮我们自动创建了合适的 script, 并且在页面引用了正确的路径。安装命令：\nnpm install html-webpack-plugin --save-dev\n\n安装完成后，在 webpack.config.js 中增加两个配置：\n//导入插件const htmlWebpackPlugin = require(&quot;html-webpack-plugin&quot;);//在 plugins 节点增加一项数据，创建一个在内存中生成 HTML 页面的插件plugins: [  new htmlWebpackPlugin(&#123;    template: path.join(__dirname, &quot;./src/index.html&quot;), // 指定模板页面，根据指定的页面路径生成内存中的页面    filename: &quot;index.html&quot;, // 指定生成的页面的名称  &#125;),];\n\n该插件可在内存中生成一个 html 页面，同时自动把打包好的 bundle.js 追加到页面中去，浏览器查看页面源代码可以发现，底部自动插入了一行：&lt;script type=&quot;text/javascript&quot; src=&quot;bundle.js&quot;&gt;&lt;/script&gt;\n注意：如果直接使用 webpack 命令输出 bundle.js 到指定路径，试图在 index.html 通过 &lt;script&gt; 标签引入会导致失败，提示找不到文件。因此，应使用 html-webpack-plugin 进行。\n4.2 使用 ProvidePlugin 插件其加载的模块在使用时，不再需要 import 或 require 进行引入：\nplugins: [  new webpack.ProvidePlugin(&#123;    //引入jquery    $: &quot;jquery&quot;,    jQuery: &quot;jquery&quot;,    &quot;windows.jQuery&quot;: &quot;jquery&quot;,    //引入 lodash/debounce    debounce: &quot;lodash/debounce&quot;,    // 引入 echarts/dist/echarts    echarts: &quot;echarts/dist/echarts&quot;,  &#125;),];\n\n5 webpack 导入样式5.1 引入模块加载器在 main.js 中引入样式：import &#39;./css/index.css&#39;。webpack 默认只能处理 js 类型的文件，处理 css 文件需要引入两个 loader，命令：npm i style-loader css-loader –d\n5.2 配置第三方模块加载器安装完成后，在 webpack.config.js 增加 module 配置项，配置所有第三方模块加载器：\nmodule: &#123;  //所有第三方模块的匹配规则  rules: [    //配置处理 .css 文件的第三方loader 规则    &#123; test: /\\.css$/, use: [&quot;style-loader&quot;, &quot;css-loader&quot;] &#125;,    //配置处理 .less 文件的第三方 loader 规则    &#123; test: /\\.less$/, use: [&quot;style-loader&quot;, &quot;css-loader&quot;, &quot;less-loader&quot;] &#125;,    //配置处理 .scss 文件的 第三方 loader 规则    &#123; test: /\\.scss$/, use: [&quot;style-loader&quot;, &quot;css-loader&quot;, &quot;sass-loader&quot;] &#125;,  ];&#125;\n\n5.3 webpack 处理第三方文件类型的过程（1）发现要处理的文件不是 JS 文件，然后在配置文件中，查找有没有对应的第三方 loader 规则；\n（2）如果能找到对应的规则， 就会调用对应的 loader 处理这种文件类型；\n（3）在调用 loader 的时候，是从后往前调用的；\n（4）当最后的一个 loader 调用完毕，会把处理的结果，直接交给 webpack 进行打包合并，最终输出到 bundle.js\n5.4 匹配 less 文件和 scss 文件分别另外安装专用 loader：\n\n命令：npm install less-loader --save–dev\n命令：npm install sass-loader --save–dev\n\n5.5 处理图片有如下 css 样式。默认情况下，webpack 无法处理 CSS 文件中的 url 地址，不管是图片还是字体库，只要是 URL 地址，都处理不了。\nhtml, body&#123;    .box&#123;        background: url(&#x27;../images/xx.jpg&#x27;);    &#125;&#125;\n\n需要安装两个专用 loader，使用命令：npm install url-loader file-loader --save–dev，其中 file-loader 是内部依赖。再增加匹配规则，处理 jpg、png、gif、bmp、jpeg 文件：\n&#123;    test: /\\.(jpg|png|gif|bmp|jpeg)$/,    use: &#x27;url-loader?limit=7631&amp;name=[hash:8]-[name].[ext]&#x27;&#125;\n\nurl-loader 参数名称是固定的，意义如下：\n\nlimit：文件大小决定是否使用 base64 处理，如果小于给定值则转为 base64 字符串。\nname：不指定该参数时，默认使用 hash 值命名防止重名，[hash:8] 代表图片 8 位 hash 值，最长 32 位；[name] 为真实文件名。\n\n5.6 处理字体文件例如要使用 bootstrap 的样式 &lt;link rel=&quot;stylesheet&quot; href=&quot;/node_modules/bootstrap/dist/css/bootstrap.css&quot;&gt; 引入一个图标 &lt;span class=&quot;glyphicon glyphicon-heart&quot; aria-hidden=&quot;true&quot;&gt;&lt;/span&gt;，需要在 main.js 中引入 import &#39;bootstrap/dist/css/bootstrap.css&#39;，再指定处理字体文件的 loader：&#123; test: /\\.(ttf|eot|svg|woff|woff2)$/, use: &#39;url-loader&#39; &#125;\n注意： 如果要通过路径的形式，去引入 node_modules 中相关的文件，可以直接省略路径前面的 node_modules 这一层目录，直接写包的名称，然后后面跟上具体的文件路径。不写 node_modules 这一层目录 ，默认就会去 node_modules 中查找。\n6 webpack 下 babel 的安装和配置class 关键字，是 ES6 中提供的新语法，是用来实现 ES6 中面向对象编程的方式，例子用法：\nclass Person &#123;  static info = &#123; name: &quot;zs&quot;, age: 20 &#125;;&#125;var p1 = new Person();\n\n访问 Person 类身上的 info 静态属性：console.log(Person.info)。这种方法与 Java、C# 等实现面向对象的方式完全一样了，class 是从后端语言中借鉴过来的，来实现面向对象。\n使用 static 关键字，可以定义静态属性，所谓的静态属性，就是可以直接通过类名，直接访问的属性。实例属性是只能通过类的实例，来访问的属性，叫做实例属性。以前的实现构造函数方式：\nfunction Animal(name) &#123;  this.name = name;&#125;var a1 = new Animal(&quot;小花&quot;);Animal.info = 123;//静态属性：console.log(Animal.info);//实例属性：console.log(a1.name);\n\n但是上述代码无法在浏览器中运行，此时需要引入 babel。\n引入 babel在 webpack 中，默认只能处理一部分 ES6 的新语法，一些更高级的 ES6 语法或者 ES7 语法，webpack 是处理不了的。这时候，就需要借助于第三方的 loader 来帮助 webpack 处理这些高级的语法，当第三方 loader 把高级语法转为低级的语法之后，会把结果交给 webpack 去打包到 bundle.js 中。可通过 Babel 帮我们将高级的语法转换为低级的语法。\n（1）在 webpack 中，可以运行如下命令，安装两套包，安装 Babel 相关的 loader 功能：\n\n第一套包：Babel 的转化工具，共 3 个包：npm install babel-core babel-loader babel-plugin-transform-runtime --save–dev\n第二套包： 高级语法到低级语法的对应关系字典，共 2 个包：npm install babel-preset-env babel-preset-stage-0 --save–dev\n\n注：babel-preset-env 是比较新的 ES 语法字典，它包含了所有的和 ES 相关的语法。之前经常安装的是 babel-preset-es2015，ES2015 也就是 ES6。\n（2）打开 webpack 的配置文件，在 module 节点下的 rules 数组中，添加一个新的匹配规则：&#123; test:/\\.js$/, use: &#39;babel-loader&#39;, exclude:/node_modules/ &#125;\n注意：在配置 babel 的 loader 规则的时候，必须把 node_modules 目录通过 exclude 选项排除掉。如果不排除，babel 会把 node_modules 中所有的第三方 JS 文件打包编译，这样非常消耗 CPU，打包速度非常慢。即使把所有 node_modules 中的 JS 转换完毕了，项目也无法正常运行。\n（3）在项目根目录中，新建一个叫做 .babelrc 的 babel 配置文件，该文件属于 JSON 格式，所以，在写 .babelrc 配置的时候，必须符合 JSON 语法规范：不能写注释，字符串必须用双引号。\n安装的两套包中 babel-preset 前缀是语法类的包，babel-plugin 前缀是插件类的包。在 .babelrc 中根据安装的包写如下的配置：\n&#123;    &quot;presets&quot;: [&quot;env&quot;, &quot;stage-0&quot;],    &quot;plugins&quot;: [&quot;transform-runtime&quot;]&#125;\n\n配置完成后，即可运行 ES6 语法的相关内容。\n二、webpack 下使用 vue1 安装\n执行命令：npm install vue --save-dev\n在 main.js 中导入：import Vue from &quot;vue&quot;，但是这种方式引入的 vue 构造是运行时版本（runtime-only），功能并不完全，传统例子不能运行。\n\n附加内容：导入 vue 包的查找规则：\n（1）找项目根目录中有没有 node_modules 的文件夹\n（2）在 node_modules 中根据包名，找对应的 vue 文件夹\n（3）在 vue 文件夹中，找一个叫做 package.json 的包配置文件\n（4）在 package.json 文件中，查找一个 main 属性，该属性指定了这个包在被加载时候，的入口文件。&quot;main&quot;: &quot;dist/vue.runtime.common.js&quot;，在 main.js 中导入的 Vue 就是从这里拿到，转到 dist 目录，发现有其他的包，vue.min.js、vue.js。因此可以有以下方法：\n\n给定路径，import Vue from &quot;../node_modules/vue/dist/vue.js&quot;\n在 webpack.config.js 中添加 resolve 数据项，修改 Vue 结尾的文件被导入时候的引用包的路径：\n\nresolve: &#123;    alias: &#123;       &quot;vue$&quot;: &quot;vue/dist/vue.js&quot;    &#125;  &#125;\n\n2 使用 runtime-only 模式渲染组件（1）建立 vue 文件，例子，建立 login.vue，内容如下：\n&lt;template&gt;  &lt;div&gt;&lt;h1&gt;这是登录组件，使用 .vue 文件定义出来的 --- &#123;&#123;msg&#125;&#125;&lt;/h1&gt;&lt;/div&gt;&lt;/template&gt;&lt;script&gt;  export default &#123;    data() &#123;      // 注意：组件中的 data 必须是 function      return &#123;        msg: &quot;123&quot;,      &#125;;    &#125;,    methods: &#123;      show() &#123;        console.log(&quot;调用了 login.vue 中的 show 方法&quot;);      &#125;,    &#125;,  &#125;;&lt;/script&gt;&lt;style&gt;&lt;/style&gt;\n\n（2）main.js 中导入该组件：import login from &#39;./login.vue&#39;，默认情况下 webpack 无法打包 .vue 文件，需要安装相关的 loader：npm install vue-loader vue-template-compiler --save-dev\n在配置文件中，新增 loader 配置项 ，vue-template-compiler 是内部依赖：&#123; test:/\\.vue$/, use: &#39;vue-loader&#39; &#125;\n注意：webpack 4.x 中使用 vue-loader 要在 webpack.config.js 中另外配置以下内容：\nconst VueLoaderPlugin = require(&quot;vue-loader/lib/plugin&quot;);//在plugins节点增加一项数据new VueLoaderPlugin();\n\n（3）在 webpack 中要使用 vue 文件渲染，要使用 render 函数的方式，不能在 runtime-only 模式下使用传统的添加标签，否则报错。例子：\nrender: function (createElements) &#123;    return createElements(login)&#125;\n\n改为 ES6 语法\nrender: (c) =&gt; c(login);\n\n完成以上配置后，执行 npm run dev 后组件成功加载。\n附加内容：在传统标签使用 render 函数\n与传统使用组件的方式不同，该函数能够将绑定的操作区域整体替换为组件，例子中的 &lt;p&gt; 标签内容不会出现，并且每个操作区域只能渲染一个组件。\n&lt;body&gt;&lt;div id=&quot;app&quot;&gt;    &lt;p&gt;test!&lt;/p&gt;&lt;/div&gt;&lt;script src=&quot;https://unpkg.com/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/x-template&quot; id=&quot;tempComp&quot;&gt;    &lt;div&gt;我是模板组件&lt;/div&gt;&lt;/script&gt;&lt;script&gt;    var tempComp = &#123;        template: &quot;#tempComp&quot;    &#125;    new Vue(&#123;        el: &quot;#app&quot;,        render: function (createElement) &#123;            return createElement(tempComp);        &#125;    &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n3 export、import在 ES6 中，也通过规范的形式，规定了 ES6 中如何导入和导出模块，ES6 中导入模块，可使用两种方式：\n\nimport 模块名称 from &#39;模块标识符&#39;\nimport &#39;路径&#39;\n\n在 ES6 中，使用 export default 和 export 向外暴露成员：module.exports = &#123;&#125;，这是 Node 中向外暴露成员的形式。\n使用要点：\n\nexport default 向外暴露的成员，可以使用任意的变量名来接收。注意： 在一个模块中，export default 只允许向外暴露 1 次。\n在一个模块中，可以同时使用 export default 和 export 向外暴露成员。\n使用 export 向外暴露的成员，只能使用 { } 的形式（解构赋值）来接收。\nexport 可以向外暴露多个成员，如果某些成员在 import 的时候不需要，则可以不在 { } 中定义，这种方式称为按需导出。注意：使用 export 导出的成员，必须严格按照导出时候的名称来使用。\n使用 export 导出的成员，可以使用 as 来起别名。\n\n例子：src 目录下的 test.js 中有如下内容：\nvar info = &#123;  name: &quot;zs&quot;,  age: 20,&#125;;export default info;export var title = &quot;标题&quot;;export var content = &quot;目录&quot;;\n\n在 src 目录下的 main.js 中调用：\nimport abc, &#123; title as myTitle, content &#125; from &quot;./test.js&quot;;console.log(abc); //abc对应default，控制台输出对象info。注意：只能有一个defaultconsole.log(myTitle + &quot; --- &quot; + content); //myTitle是title的别名，对应test.js中的title\n\n4 使用路由4.1 通用案例（单路由）（1）定义备用组件，假设有 components 目录，该路径下新建 pageOne.vue、pageTwo.vue，两者结构及内容类似：\n&lt;template&gt;  &lt;p&gt;one&lt;/p&gt;&lt;/template&gt;&lt;script&gt;  export default &#123;    name: &quot;pageOne&quot;,  &#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt;\n\n（2）定义 app.vue，内容如下。实现首页加载时显示 pageOne.vue，发送 &#x2F;pageTwo 请求后显示 pageTwo.vue\n&lt;template&gt;  &lt;div&gt;    &lt;router-link to=&quot;/pageTwo&quot;&gt;123&lt;/router-link&gt;    &lt;router-view&gt;&lt;/router-view&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;  export default &#123;    name: &quot;app&quot;,  &#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt;\n\n首页 index.html 内容如下：\n&lt;!DOCTYPE html&gt;&lt;html&gt;  &lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot; /&gt;    &lt;title&gt;Title&lt;/title&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;div id=&quot;app&quot;&gt;&lt;/div&gt;  &lt;/body&gt;&lt;/html&gt;\n\n（3）在 routers.js 文件中定义路由。也可以在这个文件中使用 new vueRouter({}) 新建路由对象，返回给 main.js，但为了避免重复引入 vue-router 等组件，这里仅返回一个对象数组，由 main.js 统一对路由进行配置。\nimport FormOne from &quot;./components/pageOne.vue&quot;;import FormTwo from &quot;./components/pageTwo.vue&quot;;export default [  &#123; path: &quot;/&quot;, component: FormOne &#125;,  &#123; path: &quot;/pageTwo&quot;, component: FormTwo &#125;,];\n\n（4）在 main.js 中引入 routers.js 及路由配置，内容如下。也可以将 new vueRouter({}) 的内容不通过 getRouter 而直接传递给 router，这里为了体现细节，多进行了一个步骤。\nimport Vue from &quot;vue&quot;;import vueRouter from &quot;vue-router&quot;;import App from &quot;./App.vue&quot;;import goodRouter from &quot;./routers.js&quot;;Vue.use(vueRouter);const getRouter = new vueRouter(&#123;  mode: &quot;history&quot;,  routes: goodRouter,&#125;);new Vue(&#123;  el: &quot;#app&quot;,  render: (h) =&gt; h(App),  router: getRouter,&#125;);\n\n注意：在模块化工程中，必须使用 Vue.use() 安装路由模块 Vue.use(VueRouter);\n附加内容：history 模式的弊端某些情况下不希望在 URL 中存在 # 标记，用 history 模式可以避免，但是换成 history 模式会导致页面刷新无法显示。对于这个问题，我们只需要在服务器配置，如果 URL 匹配不到任何静态资源，跳转到默认的 index.html。以 nginx 的配置为例：\n案例 1，该方式容易被第三方劫持\nlocation / &#123;    root   /data/nginx/html;    index  index.html index.htm;    error_page 404 /index.html;&#125;\n\n方案 2：\nlocation / &#123;    root   /data/nginx/html;    index  index.html index.htm;    if (!-e $request_filename) &#123;        rewrite ^/(.*) /index.html last;        break;    &#125;&#125;\n\n方案 3，vue.js 官方教程里提到的 https://router.vuejs.org/zh-cn/essentials/history-mode.html\nserver &#123;    #默认端口是 80，如果端口没被占用可以不用修改    listen  9999;    server_name  localhost;    #vue 项目的打包后的 dist    root E:/dist;    location / &#123;        #需要指向下面的 @router 否则会出现 vue 的路由在 nginx 中刷新出现 404        try_files $uri $uri/ @router;        index  index.html index.htm;    &#125;    #对应上面的 @router，主要原因是路由的路径资源并不是一个真实的路径，所以无法找到具体的文件    #因此需要 rewrite 到 index.html 中，然后交给路由在处理请求资源    location @router &#123;        rewrite ^.*$ /index.html last;    &#125;    #其他部分略……&#125;\n\n4.1 动态路由匹配假设有一个 User 组件，对于所有 ID 各不相同的用户，都要使用这个组件来渲染。那么，我们可以在 vue-router 的路由路径中使用动态路径参数来达到这个效果：\n&#123; path: &#x27;/user/:id&#x27;,name: &quot;user&quot;, component: User &#125;\n\n现在呢，像 &#x2F;user&#x2F;foo 和 &#x2F;user&#x2F;bar 都将映射到相同的路由。也可以在组件中获取到传入的动态参数和 name 属性：\n&lt;template&gt;  &lt;div&gt;    &lt;ul&gt;      &lt;li&gt;        &lt;router-link to=&quot;/user/foo&quot;&gt;Go&lt;/router-link&gt;      &lt;/li&gt;      &lt;li&gt;路由名称：&#123;&#123;getRouteName&#125;&#125;&lt;/li&gt;      &lt;li&gt;路由参数：&#123;&#123;getRouteParam&#125;&#125;&lt;/li&gt;    &lt;/ul&gt;    &lt;router-view&gt;&lt;/router-view&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;  export default &#123;    computed: &#123;      getRouteName() &#123;        return this.$route.name;      &#125;,      getRouteParam() &#123;        return this.$route.params.id;      &#125;,    &#125;,  &#125;;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt;\n\n注意：return this.$route.params.id; 的 id 参数没有自动完成提示，IDE 可能会报 Unresolved variable，但是可以正常获取。\n4.2 路由查询参数4.3 通配符路由4.4 响应路由参数的变化当使用路由参数时，例如从 &#x2F;user&#x2F;foo 导航到 &#x2F;user&#x2F;bar，原来的组件实例会被复用。因为两个路由都渲染同个组件，比起销毁再创建，复用则显得更加高效。不过，这也意味着组件的生命周期钩子不会再被调用。\n复用组件时，想对路由参数的变化作出响应的话，你可以简单地 watch (监测变化) $route 对象：\n// 其他内容略&lt;script&gt;  export default &#123;      computed: &#123;          getRouteName() &#123;              return this.$route.name;          &#125;,          getRouteParam()&#123;              return this.$route.params.id;          &#125;      &#125;，      watch: &#123;        &#x27;$route&#x27; (to, from) &#123;          // 对路由变化作出响应...        &#125;      &#125;  &#125;&lt;/script&gt;\n\n或者使用 2.2 中引入的 beforeRouteUpdate 导航守卫：（该部分要细化修改）\nconst User = &#123;  template: &quot;...&quot;,  beforeRouteUpdate(to, from, next) &#123;    // react to route changes...    // don&#x27;t forget to call next()  &#125;,&#125;;\n\n4.5 匹配优先级有时候，同一个路径可以匹配多个路由，此时，匹配的优先级就按照路由的定义顺序：谁先定义的，谁的优先级就最高。\n4.6 路由嵌套5 子路由（待完善）还是使用上面的例子，子路由，独立一个路由 router.js 文件，内容如下：\nimport VueRouter from &quot;vue-router&quot;;// 导入 Account 组件import account from &quot;./main/Account.vue&quot;;import goodslist from &quot;./main/GoodsList.vue&quot;;// 导入Account的两个子组件import login from &quot;./subcom/login.vue&quot;;import register from &quot;./subcom/register.vue&quot;;// 3. 创建路由对象var router = new VueRouter(&#123;  routes: [    // account的子路由，即渲染account后再进一步渲染login或register。    // 注意：子路由不带“/”    &#123;      path: &quot;/account&quot;,      component: account,      children: [        &#123; path: &quot;login&quot;, component: login &#125;,        &#123; path: &quot;register&quot;, component: register &#125;,      ],    &#125;,    &#123; path: &quot;/goodslist&quot;, component: goodslist &#125;,  ],&#125;);// 把路由对象暴露出去export default router;\n","categories":["前端技术"],"tags":["webpack","vue"]},{"title":"修改 nodejs 默认的全局安装包位置","url":"/931ddaf3-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n1 解决方案npm config set prefix &quot;D:\\MyProject\\npm_global_modules&quot;npm config set cache &quot;D:\\MyProject\\npm_global_modules&quot;\n\n注意：设置之后要配置环境变量，否则全局包的命令行不生效，如：webpack -v。可在高级系统设置的 Path 中直接添加路径：\nD:\\MyProject\\npm_global_modules\n","categories":["前端技术"],"tags":["nodejs"]},{"title":"原生js实现ajax请求","url":"/8a9d69d0-e38d-11ee-8d05-110f62540784/","content":"\n\n\n\n1 XMLHttpRequest 对象XMLHttpRequest 对象是 ajax 的基础,XMLHttpRequest 用于在后台与服务器交换数据。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。目前所有浏览器都支持 XMLHttpRequest\n\n\n\n方 法\n描 述\n\n\n\nabort()\n停止当前请求\n\n\ngetAllResponseHeaders()\n把 HTTP 请求的所有响应首部作为键&#x2F;值对返回\n\n\ngetResponseHeader(“header”)\n返回指定首部的串值\n\n\nopen(“method”,”URL”,[asyncFlag],[“userName”],[“password”])\n建立对服务器的调用。method 参数可以是 GET、POST 或 PUT。url 参数可以是相对 URL 或绝对 URL。这个方法还包括 3 个可选的参数，是否异步，用户名，密码\n\n\nsend(content)\n向服务器发送请求\n\n\nsetRequestHeader(“header”, “value”)\n把指定首部设置为所提供的值。在设置任何首部之前必须先调用 open()。设置 header 并和请求一起发送 (‘post’方法一定要 )\n\n\n2 案例1）get 请求：\n// 创建异步对象var ajax = new XMLHttpRequest();// 设置请求的url参数，参数一是请求的类型，参数二是请求的url，可带参数传递到服务端ajax.open(&quot;get&quot;, &quot;getStar.php?starName=&quot; + name);// 发送请求ajax.send();// 注册事件 onreadystatechangeajax.onreadystatechange = function () &#123;  if (ajax.readyState == 4 &amp;&amp; ajax.status == 200) &#123;    // 正常响应，输出    console.log(ajax.responseText);  &#125;&#125;;\n\n2）post 请求：\n// 创建异步对象var xhr = new XMLHttpRequest();// 设置请求的类型及url，post请求一定要添加请求头xhr.setRequestHeader(&quot;Content-type&quot;, &quot;application/x-www-form-urlencoded&quot;);xhr.open(&quot;post&quot;, &quot;02.post.php&quot;);// 发送请求xhr.send(&quot;name=fox&amp;age=18&quot;);xhr.onreadystatechange = function () &#123;  // 正常响应，输出  if (xhr.readyState == 4 &amp;&amp; xhr.status == 200) &#123;    console.log(xhr.responseText);  &#125;&#125;;\n","categories":["前端技术"],"tags":["js"]},{"title":"通过 fetch 发送 post 请求下载文件","url":"/931e0201-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n1 案例通过 fetch 发起请求获取文件，再用 Blob 对象来接收处理。接收到后端返回的文件后，将其放入 a 标签 的 href，并触发下载行为。实现的代码如下：\nconst formData = new FormData();formData.append(&quot;msg&quot;, &quot;download&quot;);fetch(url, &#123;  method: &quot;POST&quot;,  body: formData,  headers: new Headers(&#123; &quot;Content-Type&quot;: &quot;application/json;charset=UTF-8&quot; &#125;),&#125;)  .then((response) =&gt; &#123;    return response.blob();  &#125;)  .then((blob) =&gt; &#123;    const link = document.createElement(&quot;a&quot;);    link.style.display = &quot;none&quot;;    link.href = URL.createObjectURL(blob);    document.body.appendChild(link);    link.click();    // 释放的 URL 对象并移除 a 标签    URL.revokeObjectURL(link.href);    document.body.removeChild(link);  &#125;);\n\n\n注意：调用 response 的 blob 方法会返回一个 promise 对象\n\n2 处理文件名上一个步骤下载得到的文件名是无意义的。假设服务端把文件名放在 content-disposition 头：\nresponse.setContentType(&quot;application/octet-stream&quot;);response.setHeader(&quot;Access-Control-Expose-Headers&quot;, &quot;Content-disposition&quot;);response.setHeader(&quot;Content-disposition&quot;, &quot;attachment;filename=&quot; + fileName);response.flushBuffer();workbook.write(response.getOutputStream());\n\n前端可采用 split 方法提取。完整实现：\nfetch(url, &#123;  method: &quot;POST&quot;,  body: formData,  headers: new Headers(&#123; &quot;Content-Type&quot;: &quot;application/json;charset=UTF-8&quot; &#125;),&#125;).then(function (response) &#123;  const filename = res.headers    .get(&quot;content-disposition&quot;)    .split(&quot;;&quot;)[1]    .split(&quot;=&quot;)[1];  response.blob().then((blob) =&gt; &#123;    const link = document.createElement(&quot;a&quot;);    link.style.display = &quot;none&quot;;    link.download = filename;    link.href = URL.createObjectURL(blob);    document.body.appendChild(link);    link.click();    // 释放的 URL 对象并移除 a 标签    URL.revokeObjectURL(link.href);    document.body.removeChild(link);  &#125;);&#125;);\n\n\n注：a 标签的 download 属性就是文件名\n\n或者用 async/await 实现：\nasync function download(url) &#123;   const request = &#123;     method: &#x27;POST&#x27;,     body: formData,     headers: new Headers(&#123; &quot;Content-Type&quot;: &quot;application/json;charset=UTF-8&quot; &#125;),   &#125;   const response = await fetch(url, request)   const filename = response.headers.get(&#x27;content-disposition&#x27;).split(&#x27;;&#x27;)[1].split(&#x27;=&#x27;)[1]   const blob = await response.blob()   const link = document.createElement(&#x27;a&#x27;)   link.download = decodeURIComponent(filename)   link.style.display = &#x27;none&#x27;   link.href = URL.createObjectURL(blob)   document.body.appendChild(link)   link.click()   URL.revokeObjectURL(link.href)   document.body.removeChild(link)j&#125;\n","categories":["前端技术"],"tags":["fetch","post"]},{"title":"3-things-every-java-developer-should-stop-doing","url":"/5886d182-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n3 Things Every Java Developer Should Stop Doing每个 Java 开发者都应该停止的三件事\n\n转译自：https://dzone.com/articles/3-things-every-java-developer-should-stop-doing\n\n\nLooking for a few bad habits to drop? Let’s take a look at null, functional programming, and getters and setters to see how you can improve your coding.\n\n前言：想改掉一些坏习惯吗？让我们从 null、函数式编程以及 getter 和 setter 着手，看看如何改善代码。\nFrom returning null values to overusing getters and setters, there are idioms that we as Java developers are accustom to making, even when unwarranted. While they may be appropriate in some occasions, they are usually forces of habit or fallbacks that we make to get the system working. In this article, we will go through three things that are common among Java developers, both novice and advanced, and explore how they can get us into trouble. It should be noted that these are not hard-and-fast rules that should always be adhered to, regardless of the circumstances. At times, there may be a good reason to use these patterns to solve a problem, but on the whole, they should be used a lot less than they are now. To start us off, we will begin with one of the most prolific, but double-edged keywords in Java: Null.\n作为 Java 开发人员，我们会使用一些习惯用法，典型的例子，如：返回 null 值、滥用 getter 和 setter，即使在没有依据的情况下也是如此。虽然在某些情况下，使用它们可能是适当的，但通常是我们为使系统正常工作而形成的习惯或权宜之计。在本文中，我们将介绍 Java 开发（包括新手和高级开发人员）中常见的三种情况，并探究它们是如何给我们带来麻烦的。应该指出的是，文中总结的规则并不是无论何时都应该始终遵守的硬性要求。有时候，可能有一个很好的理由来使用这些模式解决问题，但是总的来说，还是应该减少这些用法。首先，我们将从 Null 这个关键字开始，它也是 Java 中使用最频繁、但也是最具两面性特性的关键字之一。\n1. Returning Null返回 Null\nNull has been the best friend and worst enemy of developers for decades and null in Java is no different. In high-performance applications, null can be a solid means of reducing the number of objects and signaling that a method does not have a value to return. In contrast to throwing an exception, which has to capture the entire stack trace when it is created, null serves as a quick and low-overhead way to signal clients that no value can be obtained.\nnull 一直是开发者最好的朋友，也是最大的敌人，这在 Java 中也不例外。在高性能应用中，使用 null 是一种减少对象数量的可靠方法，它表明方法没有要返回的值。与抛出异常（创建异常时必须捕获整个堆栈跟踪）不同，使用 null 是一种快速且低开销的方法，用于通知客户机不能获取任何值。\nOutside the context of high-performance systems, null can wreak havoc in an application by creating more tedious checks for null return values and causing NullPointerExceptions when dereferencing a null object. In most applications, nulls are returned for three primary reasons: (1) to denote no elements could be found for a list, (2) to signal that no valid value could be found, even if an error did not occur, or (3) to denote a special case return value.\n在高性能系统的环境之外，null 可以通过创建更繁琐的 null 返回值检查来破坏应用程序，并在非关联化 null 对象时导致 NullPointerExceptions 异常。在大多数应用程序中，返回 null 有三个主要原因：（1）表示列表中找不到元素；（2）表示即使没有发生错误，也找不到有效值;（3）表示特殊情况下的返回值。\nBarring any performance reasons, each of these cases has a much better solution which does not use null and force developers to handle null cases. Whatsmore, clients of these methods are not left scratching their heads wondering if the method will return a null in some edge case. In each case, we will devise a cleaner approach that does not involve returning a null value.\n除非有任何性能方面的原因，否则以上每一种情况都有更好的解决方案，它们不使用 null，并且强制开发人员处理出现 null 的情况。更重要的是，这些方法的客户端不会为该方法是否会在某些边缘情况下返回 null 而伤脑筋。在每种情况下，我们将设计一种不返回 null 值的简洁方法。\nNo Elements集合中没有元素的情况\nWhen returning lists or other collections, it can be common to see a null collection returned in order to signal that elements for that collection could not be found. For example, we could create a service that manages users in a database that resembles the following (some method and class definitions have been left out for brevity):\n在返回列表或其他集合时，通常会看到返回空集合，以表明无法找到该集合的元素。例如，我们可以创建一个服务来管理数据库中的用户，该服务类似于以下内容（为了简洁起见，省略了一些方法和类定义）：\npublic class UserService &#123;    public List&lt;User&gt; getUsers() &#123;        User[] usersFromDb = getUsersFromDatabase();        if (usersFromDb == null) &#123;            // No users found in database            return null;        &#125;        else &#123;            return Arrays.asList(usersFromDb);        &#125;    &#125;&#125;UserServer service = new UserService();List&lt;Users&gt; users = service.getUsers();if (users != null) &#123;    for (User user: users) &#123;        System.out.println(&quot;User found: &quot; + user.getName());    &#125;&#125;\n\nSince we have elected to return a null value in the case of no users, we are forcing our client to handle this case before iterating over the list of users. If instead, we returned an empty list to denote no users were found, the client can remove the null check entirely and loop through the users as normal. If there are no users, the loop will be skipped implicitly without having to manually handle that case; in essence, looping through the list of users functions as we intend for both an empty and populated list without having to manually handle one case or the other:\n因为我们选择在没有用户的情况下返回 null 值，所以我们在遍历用户列表之前强制客户端处理这种情况。如果我们返回一个空列表来表示没有找到用户，那么客户端可以完全删除空检查并像往常一样遍历用户。如果没有用户，则隐式跳过循环，而不必手动处理这种情况；从本质上说，循环遍历用户列表的功能就像我们为空列表和填充列表所做的那样，而不需要手动处理任何一种情况：\npublic class UserService &#123;    public List&lt;User&gt; getUsers() &#123;        User[] usersFromDb = getUsersFromDatabase();        if (usersFromDb == null) &#123;            // No users found in database            return Collections.emptyList();        &#125;        else &#123;            return Arrays.asList(usersFromDb);        &#125;    &#125;&#125;UserServer service = new UserService();List&lt;Users&gt; users = service.getUsers();for (User user: users) &#123;    System.out.println(&quot;User found: &quot; + user.getName());&#125;\n\nIn the case above, we have elected to return an immutable, empty list. This is an acceptable solution, so long as we document that the list is immutable and should not be modified (doing so may throw an exception). If the list must be mutable, we can return an empty, mutable list, as in the following example:\n在上面的例子中，我们返回的是一个不可变的空列表。这是一个可接受的解决方案，只要我们记录该列表是不可变的并且不应该被修改（这样做可能会抛出异常）。如果列表必须是可变的，我们可以返回一个空的可变列表，如下例所示：\npublic List&lt;User&gt; getUsers() &#123;    User[] usersFromDb = getUsersFromDatabase();    if (usersFromDb == null) &#123;        // No users found in database        return new ArrayList&lt;&gt;();    // A mutable list    &#125;    else &#123;        return Arrays.asList(usersFromDb);    &#125;&#125;\n\nIn general, the following rule should be adhered to when signaling that no elements could be found:\n一般来说，在发出找不到元素的信号时，应遵守以下规则：\nReturn an empty collection (or list, set, queue, etc.) to denote that no elements can be found\n返回一个空集合（或 list、set、queue 等等）表明找不到元素。\nDoing so not only reduces the special-case handling that clients must perform, but it also reduces the inconsistencies in our interface (i.e. we return a list object sometimes and not others).\n这样做不仅减少了客户端必须执行的特殊情况处理，而且还减少了接口中的不一致性（例如，我们有时返回一个 list 对象，而不是其他对象）。\nOptional Value可选值\nMany times, null values are returned when we wish to inform a client that an optional value is not present, but no error has occurred. For example, getting a parameter from a web address. In some cases, the parameter may be present, but in other cases, it may not. The lack of this parameter does not necessarily denote an error, but rather, it denotes that the user did not want the functionality that is included when the parameter is provided (such as sorting). We can handle this by returning null if no parameter is present or the value of the parameter if one is supplied (some methods have been removed for brevity):\n很多时候，我们希望在没有发生错误时通知客户端不存在可选值，此时返回 null。例如，从 web 地址获取参数。在某些情况下，参数可能存在，但在其他情况下，它可能不存在。缺少此参数并不一定表示错误，而是表示用户不希望提供该参数时包含的功能（例如排序）。如果没有参数，则返回 null；如果提供了参数，则返回参数值（为了简洁起见，删除了一些方法）：\npublic class UserListUrl &#123;    private final String url;    public UserListUrl(String url) &#123;        this.url = url;    &#125;    public String getSortingValue() &#123;        if (urlContainsSortParameter(url)) &#123;            return extractSortParameter(url);        &#125;        else &#123;            return null;        &#125;    &#125;&#125;UserService userService = new UserService();UserListUrl url = new UserListUrl(&quot;http://localhost/api/v2/users&quot;);String sortingParam = url.getSortingValue();if (sortingParam != null) &#123;    UserSorter sorter = UserSorter.fromParameter(sortingParam);    return userService.getUsers(sorter);&#125;else &#123;    return userService.getUsers();&#125;\n\nWhen no parameter is supplied, a null is returned and a client must handle this case, but nowhere in the signature of the getSortingValue method does it state that the sorting value is optional. For us to know that this method is optional and may return a null if no parameter is present, we would have to read the documentation associated with the method (if any were provided).\n当没有提供参数时，返回 null，客户端必须处理这种情况，但是在 getSortingValue 方法的签名中，没有任何地方声明排序值是可选的。如果要知道这个方法是可选的，如果没有参数，可能返回null，我们必须阅读与该方法相关的文档（如果提供了文档）。\nInstead, we can make the optionality explicit returning an Optional object. As we will see, the client still has to handle the case when no parameter is present, but now that requirement is made explicit. Whatsmore, the Optional class provides more mechanisms to handle a missing parameter than a simple null check. For example, we can simply check for the presence of the parameter using the query method (a state-testing method) provided by Optional:\n相反，我们可以使可选性显式地返回一个 Optional 对象。正如我们将看到的，当没有参数存在时，客户端仍然需要处理这种情况，但是现在这个需求已经明确了。更重要的是，Optional 类提供了比简单的 null 检查更多的机制来处理丢失的参数。例如，我们可以使用 Optional 类提供的查询方法（一种状态测试方法）简单地检查参数是否存在:\npublic class UserListUrl &#123;    private final String url;    public UserListUrl(String url) &#123;        this.url = url;    &#125;    public Optional&lt;String&gt; getSortingValue() &#123;        if (urlContainsSortParameter(url)) &#123;            return Optional.of(extractSortParameter(url));        &#125;        else &#123;            return Optional.empty();        &#125;    &#125;&#125;UserService userService = new UserService();UserListUrl url = new UserListUrl(&quot;http://localhost/api/v2/users&quot;);Optional&lt;String&gt; sortingParam = url.getSortingValue();if (sortingParam.isPresent()) &#123;    UserSorter sorter = UserSorter.fromParameter(sortingParam.get());    return userService.getUsers(sorter);&#125;else &#123;    return userService.getUsers();&#125;\n\nThis is nearly identical to that of the null-check case, but we have made the optionality of the parameter explicit (i.e. the client cannot access the parameter without calling get(), which will throw a NoSuchElementException if the optional is empty). If we were not interested in returning the list of users based on the optional parameter in the web address, but rather, consuming the parameter in some manner, we could use the ifPresentOrElse method to do so:\n这与「空检查」的情况几乎相同，但是我们已经明确了参数的可选性（即客户机在不调用 get() 的情况下无法访问参数，如果可选参数为空，则会抛出NoSuchElementException）。如果我们不希望根据 web 地址中的可选参数返回用户列表，而是以某种方式使用该参数，我们可以使用 ifPresentOrElse 方法来这样做：\nsortingParam.ifPresentOrElse(    param -&gt; System.out.println(&quot;Parameter is :&quot; + param),    () -&gt; System.out.println(&quot;No parameter supplied.&quot;));\n\nThis greatly reduces the noise required for null checking. If we wished to disregard the parameter if no parameter is supplied, we could do so using the ifPresent method:\n这极大降低了「空检查」的影响。如果我们希望在没有提供参数时忽略参数，可以使用 ifPresent 方法:\nsortingParam.ifPresent(param -&gt; System.out.println(&quot;Parameter is :&quot; + param));\n\nIn either case, using an Optional object, rather than returning null, explicitly forces clients to handle the case that a return value may not be present and provides many more avenues for handling this optional value. Taking this into account, we can devise the following rule:\n在这两种情况下，使用 Optional 对象要优于返回 null 以及显式地强制客户端处理返回值可能不存在的情况，为处理这个可选值提供了更多的途径。考虑到这一点，我们可以制定以下规则：\nIf a return value is optional, ensure clients handle this case by returning an Optional that contains a value if one is found and is empty if no value can be found\n如果返回值是可选的，则通过返回一个 Optional 来确保客户端处理这种情况，该可选的值在找到值时包含一个值，在找不到值时为空\nSpecial-Case Value特殊情况值\nThe last common use case is that of a special case, where a normal value cannot be obtained and a client should handle a corner case different than the others. For example, suppose we have a command factory from which clients periodically request commands to complete. If no command is ready to be completed, the client should wait 1 second before asking again. We can accomplish this by returning a null command, which clients must handle, as illustrated in the example below (some methods are not shown for brevity):\n最后一个常见用例是特殊用例，在这种情况下无法获得正常值，客户端应该处理与其他用例不同的极端情况。例如，假设我们有一个命令工厂，客户端定期从命令工厂请求命令。如果没有命令可以获得，客户端应该等待 1 秒钟再请求。我们可以通过返回一个空命令来实现这一点，客户端必须处理这个空命令，如下面的例子所示（为了简洁起见，没有显示一些方法）：\npublic interface Command &#123;    public void execute();&#125;public class ReadCommand implements Command &#123;    @Override    public void execute() &#123;        System.out.println(&quot;Read&quot;);    &#125;&#125;public class WriteCommand implements Command &#123;    @Override    public void execute() &#123;        System.out.println(&quot;Write&quot;);    &#125;&#125;public class CommandFactory &#123;    public Command getCommand() &#123;        if (shouldRead()) &#123;            return new ReadCommand();        &#125;        else if (shouldWrite()) &#123;            return new WriteCommand();        &#125;        else &#123;            return null;        &#125;    &#125;&#125;CommandFactory factory = new CommandFactory();while (true) &#123;    Command command = factory.getCommand();    if (command != null) &#123;        command.execute();    &#125;    else &#123;        Thread.sleep(1000);    &#125;&#125;\n\nSince the CommandFactory can return null commands, clients are obligated to check if the command received is null and if it is, sleep for 1 second. This creates a set of conditional logic that clients must handle on their own. We can reduce this overhead by creating a null-object (sometimes called a special-case object). A null-object encapsulates the logic that would have been executed in the null scenario (namely, sleeping for 1 second) into an object that is returned in the null case. For our command example, this means creating a SleepCommand that sleeps when executed:\n由于 CommandFactory 可以返回空命令，客户端有义务检查接收到的命令是否为空，如果为空，则休眠1秒。这将创建一组必须由客户端自行处理的条件逻辑。我们可以通过创建一个「空对象」（有时称为特殊情况对象）来减少这种开销。「空对象」将在 null 场景中执行的逻辑（休眠 1 秒）封装到 null 情况下返回的对象中。对于我们的命令示例，这意味着创建一个在执行时休眠的 SleepCommand：\npublic class SleepCommand implements Command &#123;    @Override    public void execute() &#123;        Thread.sleep(1000);    &#125;&#125;public class CommandFactory &#123;    public Command getCommand() &#123;        if (shouldRead()) &#123;            return new ReadCommand();        &#125;        else if (shouldWrite()) &#123;            return new WriteCommand();        &#125;        else &#123;            return new SleepCommand();        &#125;    &#125;&#125;CommandFactory factory = new CommandFactory();while (true) &#123;    Command command = factory.getCommand();    command.execute();&#125;\n\nAs with the case of returning empty collections, creating a null-object allows clients to implicitly handle special cases as if they were the normal case. This is not always possible, though; there may be instances where the decision for dealing with a special case must be made by the client. This can be handled by allowing the client to supply a default value, as is done with the Optional class. In the case of Optional, clients can obtain the contained value or a default using the orElse method:\n与返回空集合的情况一样，创建「空对象」允许客户端隐式处理特殊情况，就像它们是正常情况一样。但这并不总是可行的；在某些情况下，处理特殊情况的决定必须由客户做出。这可以通过允许客户端提供默认值来处理，就像使用 Optional 类一样。在 Optional 的情况下，客户端可以使用 orElse 方法获取包含的值或默认值：\nUserListUrl url = new UserListUrl(&quot;http://localhost/api/v2/users&quot;);Optional&lt;String&gt; sortingParam = url.getSortingValue();String sort = sortingParam.orElse(&quot;ASC&quot;);\n\nIf there is a supplied sorting parameter (i.e. if the Optional contains a value), this value will be returned. If no value exists, “ASC” will be returned by default. The Optional class also allows a client to create a default value when needed, in case the default creation process is expensive (i.e. the default will be created only when needed):\n如果有一个提供的排序参数（例如，如果 Optional 包含一个值），这个值将被返回。如果不存在值，默认情况下将返回「ASC」。Optional 类还允许客户端在需要时创建默认值，以防默认创建过程开销较大（即只在需要时创建默认值）:\nUserListUrl url = new UserListUrl(&quot;http://localhost/api/v2/users&quot;);Optional&lt;String&gt; sortingParam = url.getSortingValue();String sort = sortingParam.orElseGet(() -&gt; &#123;    // Expensive computation&#125;);\n\nUsing a combination of null-objects and default values, we can devise the following rule:\n结合「空对象」和默认值的用法，我们可以设计以下规则：\nWhen possible, handle null cases with a null-object or allow clients to supply a default value\n如果可能，使用「空对象」处理使用 null 关键字的情况，或者允许客户端提供默认值\n2. Defaulting to Functional Programming默认使用函数式编程\nSince streams and lambdas were introduced in Java Development Kit (JDK) 8, there has been a push to migrate towards functional programming, and rightly so. Before lambdas and streams, performing simple functional tasks were cumbersome and resulted in severely unreadable code. For example, filtering a collection in the traditional style resulted in code that resembled the following:\n自从在 JDK 8 中引入了 stream 和 lambda 表达式之后，就出现了向函数式编程迁移的趋势，这理当如此。在 lambda 表达式和 stream 出现之前，执行简单的功能任务是非常麻烦的，并且会导致代码可读性的严重下降。例如，以下代码用传统方式过滤一个集合：\npublic class Foo &#123;    private final int value;    public Foo(int value) &#123;        this.value = value;    &#125;    public int getValue() &#123;        return value;    &#125;&#125;Iterator&lt;Foo&gt; iterator = foos.iterator();while(iterator.hasNext()) &#123;    if (iterator.next().getValue() &gt; 10) &#123;        iterator.remove();    &#125;&#125;\n\nWhile this code is compact, it does not tell us in an obvious way that we are trying to remove elements of a collection if some criterion is satisfied. Instead, it tells us that we are iterating over a collection while there are more elements in the collection and removing each element if its value is greater than 10 (we can surmise that filtering is occurring, but it obscured in the verbosity of the code). We can shrink this logic down to one statement using functional programming:\n虽然这段代码很紧凑，但它并没有以一种明显的方式告诉我们，当满足某个条件时，我们将尝试删除集合的元素。相反，它告诉我们，当集合中有更多的元素时将遍历集合，并将删除值大于 10 的元素（我们可以假设正在进行筛选，但是删除元素的部分被代码的冗长所掩盖）。我们可以使用函数式编程将这个逻辑压缩为一条语句：\nfoos.removeIf(foo -&gt; foo.getValue() &gt; 10);\n\nNot only is this statement much more concise than its iterative alternative, it also tells us exactly what it is trying to do. We can even make it more readable if we name the predicate and pass it to the removeIf method:\n这个语句不仅比迭代方式更简洁，而且准确的告诉我们它的行为。如果我们为 predicate 命名并将其传递给 removeIf 方法，甚至可以使其更具可读性：\nPredicate&lt;Foo&gt; valueGreaterThan10 = foo -&gt; foo.getValue() &gt; 10;foos.removeIf(valueGreaterThan10);\n\nThe final line of this snippet reads like a sentence in English, informing us exactly of what the statement is doing. With code that looks so compact and readable, it is tempting to try and use functional programming in every situation where iteration is required, but this is a naive philosophy. Not every situation lends itself to functional programming. For example, if we tried to print the cross product of the set of suits and ranks in a deck of cards (every combination of suits and ranks), we could create the following (see Effective Java, 3rd Edition for a more detailed listing of this example):\n这段代码的最后一行读起来像一个英语句子，准确地告诉我们语句在做什么。对于看起来如此紧凑和极具可读性的代码，在任何需要迭代的情况下尝试使用函数式编程是很让人向往的，但这是一种天真的想法。并不是每种情况都适合函数式编程。例如，如果我们尝试在一副牌中打印一组花色和等级的排列组合（花色和等级的每一种组合），我们可以创建以下内容（参见 Effective Java，第三版，获得这个示例的详细内容）：\npublic static enum Suit &#123;    CLUB, DIAMOND, HEART, SPADE;&#125;public static enum Rank &#123;    ONE, TWO, THREE, FOUR, FIVE, SIX, SEVEN, EIGHT, NINE, TEN, JACK, QUEEN, KING;&#125;Collection&lt;Suit&gt; suits = EnumSet.allOf(Suit.class);Collection&lt;Rank&gt; ranks = EnumSet.allOf(Rank.class);suits.stream()    .forEach(suit -&gt; &#123;        ranks.stream().forEach(rank -&gt; System.out.println(&quot;Suit: &quot; + suit + &quot;, rank: &quot; + rank));    &#125;);\n\nWhile this is not over-complicated to read, it is not the most straightforward implementation we could devise. It is pretty clear that we are trying to force streams into a realm where traditional iteration is much more favorable. If we used traditional iteration, we could have simplified the cross product of suits and ranks to the following:\n虽然读起来并不复杂，但这种实现并不是最简单的。很明显，我们正试图强行使用 stream，而此时使用传统迭代明显更有利。如果我们使用传统的迭代方法，我们可以将 花色和等级的排列组合简化为：\nfor (Suit suit: suits) &#123;    for (Rank rank: ranks) &#123;        System.out.println(&quot;Suit: &quot; + suit + &quot;, rank: &quot; + rank);    &#125;&#125;\n\nThis style, although much less flashy, is much more straightforward. We can quickly see that we are attempting to iterate over each suit and rank and pair each rank with each suit. The tediousness of functional programming becomes much more acute the larger the stream expression becomes. Take for example the following code snippet created by Joshua Bloch in Effective Java, 3rd Edition (pp. 205, Item 45) to find all the anagrams over a specified length contained in a dictionary at the path supplied by the user:\n这种风格虽然不那么浮华，但却直截了当得多。我们可以很快地理解，我们试图遍历每个花色和等级，并将每个等级与每个花色配对。流表达式越大，函数式编程的乏味性就越明显。以 Joshua Bloch 在《Effective Java, 3rd Edition》第 205 页，第 45 项中创建的以下代码片段为例，在用户提供的路径上查找字典中包含的指定长度内的所有词组：\npublic class Anagrams &#123;    public static void main(String[] args) throws IOException &#123;        Path dictionary = Paths.get(args[0]);        int minGroupSize = Integer.parseInt(args[1]);        try (Stream&lt;String&gt; words = Files.lines(dictionary)) &#123;            words.collect(                groupingBy(word -&gt; word.chars().sorted()                           .collect(StringBuilder::new,                               (sb, c) -&gt; sb.append((char) c),                               StringBuilder::append).toString()))                .values().stream()                    .filter(group -&gt; group.size() &gt;= minGroupSize)                    .map(group -&gt; group.size() + &quot;: &quot; + group)                    .forEach(System.out::println);        &#125;    &#125;&#125;\n\nEven the most seasoned stream adherents would probably balk at this implementation. It is unclear as to the intention of the code and would take a decent amount of thinking to uncover what the above stream manipulations are trying to accomplish. This does not mean that streams are complicated or that they are too wordy, but they are not always the best choice. As we saw above, using the removeIf reduced a complicated group of statements into a single, easily-comprehensible statement. Therefore, we should not try to replace every instance of traditional iteration with streams or even lambdas. Instead, we should abide by the following rule when deciding whether to functional programming or use the traditional route:\n即使是经验最丰富的 stream 使用者也可能会对这个实现感到迷茫。短时间内很难理解代码的意图，需要大量的思考才能发现上面的 stream 操作试图实现什么。这并不意味着 stream 一定很复杂或太冗长，只是因为它们不总是最好的选择。正如我们在上面看到的，使用 removeIf 可以将一组复杂的语句简化为一个易于理解的语句。因此，我们不应该试图用 stream 甚至 lambda 表达式替换传统迭代的每个使用场景。相反，在决定是使用函数式编程还是使用传统路线时，我们应该遵循以下规则：\nFunctional programming and traditional iteration both have their benefits and disadvantages: Use whichever results in the simplest and most readable code\n函数式编程和传统的迭代都有其优点和缺点：应该以简易性和可读性为准来选择\nAlthough it may be tempting to use the flashiest, most up-to-date features of Java in every possible scenario, this is not always the best route. Sometimes, the old-school features work best.\n尽管在每个可能的场景中使用 Java 最炫、最新的特性可能很让人向往，但这并不总是最好的方法。有时候，老式的功能效果反而最好。\n3. Creating Indiscriminate Getters and Setters滥用 getter 和 setter\nOne of the first things that novice programmers are taught is to encapsulate the data associated with a class in private fields and expose them through public methods. In practice, this results in creating getters to access the private data of a class and setters to modify the private data of a class:\n新手程序员学到的第一件事是将与类相关的数据封装在私有字段中，并通过公共方法公开它们。在实际使用时，通过创建 getter 来访问类的私有数据，创建 setter 来修改类的私有数据：\npublic class Foo &#123;    private int value;    public void setValue(int value) &#123;        this.value = value;    &#125;    public int getValue() &#123;        return value;    &#125;&#125;\n\nWhile this is a great practice for newer programmers to learn, it is not a practice that should go unrefined into intermediate or advanced programming. What normally occurs in practice is that every private field is given a pair of getters and setters, exposing the internals of the class to external entities. This can cause some serious issues, especially if the private fields are mutable. This is not only a problem with setters but even when only a getter is present. Take for example the following class, which exposes its only field using a getter:\n虽然这对于新程序员来说是一个很好的学习实践，但这种做法不能未经思索就应用在中级或高级编程。在实际中通常发生的情况是，每个私有字段都有一对 getter 和 setter 将类的内部内容公开给外部实体。这会导致一些严重的问题，特别是在私有字段是可变的情况下。这不仅是 setter 的问题，甚至在只有 getter 时也是如此。以下面的类为例，该类使用 getter 公开其唯一的字段：\npublic class Bar &#123;    private Foo foo;    public Bar(Foo foo) &#123;        this.foo = foo;    &#125;    public Foo getFoo() &#123;        return foo;    &#125;&#125;\n\nThis exposure may seem innocuous since we have wisely restricted removed a setter method, but it is far from it. Suppose that another class accesses an object of type Bar and changes the underlying value of Foo without the Bar object knowing:\n由于我们删除了 setter 方法，这么做可能看起来明智且无害，但并非如此。假设另一个类访问 Bar 类型的对象，并在 Bar 对象不知道的情况下更改 Foo 的底层值：\nFoo foo = new Foo();Bar bar = new Bar(foo);// Another place in the codebar.getFoo().setValue(-1);\n\nIn this case, we have changed the underlying value of the Foo object without informing the Bar object. This can cause some serious problems if the value that we provided the Foo object breaks an invariant of the Bar object. For example, if we had an invariant that stated the value of Foo could not be negative, then the above snippet silently breaks this invariant without notifying the Bar object. When the Bar object goes to use the value of its Foo object, things may go south very quickly, especially if the Bar object assumed that the invariant held since it did not expose a setter to directly reassign the Foo object it held. This can even cause failure to a system if data is severely altered, as in the following example of an array being inadvertently exposed:\n在本例中，我们更改了 Foo 对象的基础值，而没有通知 Bar 对象。如果我们提供的 Foo 对象的值破坏了 Bar 对象的一个不变量，这可能会导致一些严重的问题。举个例子，如果我们有一个不变量，它表示 Foo 的值不可能是负的，那么上面的代码片段将在不通知 Bar 对象的情况下静默修改这个不变量。当 Bar 对象使用它的 Foo 对象值时，事情可能会迅速向不好的方向发展，尤其是如果 Bar 对象假设这是不变的，因为它没有暴露 setter 直接重新分配它所保存的 Foo 对象。如果数据被严重更改，这甚至会导致系统失败，如下面例子所示，数组的底层数据在无意中暴露：\npublic class ArrayReader &#123;    private String[] array;    public String[] getArray() &#123;        return array;    &#125;    public void setArray(String[] array) &#123;        this.array = array;    &#125;    public void read() &#123;        for (String e: array) &#123;            System.out.println(e);        &#125;    &#125;&#125;public class Reader &#123;    private ArrayReader arrayReader;    public Reader(ArrayReader arrayReader) &#123;        this.arrayReader = arrayReader;    &#125;    public ArrayReader getArrayReader() &#123;        return arrayReader;    &#125;    public void read() &#123;        arrayReader.read();    &#125;&#125;ArrayReader arrayReader = new ArrayReader();arrayReader.setArray(new String[] &#123;&quot;hello&quot;, &quot;world&quot;&#125;);Reader reader = new Reader(arrayReader);reader.getArrayReader().setArray(null);reader.read();\n\nExecuting this code would cause a NullPointerException because the array associated with the ArrayReader object is null when it tries to iterate over the array. What is disturbing about this NullPointerException is that it can occur long after the change to the ArrayReader was made and maybe even in an entirely different context (such as in a different part of the code or maybe even in a different thread), making the task of tracking down the problem very difficult.\n执行此代码将导致 NullPointerException 异常，因为当 ArrayReader 的实例对象试图遍历数组时，与该对象关联的数组为 null。这个 NullPointerException 异常的令人不安之处在于，它可能在对 ArrayReader 进行更改很久之后才发生，甚至可能发生在完全不同的上下文中（例如在代码的不同部分中，甚至在不同的线程中），这使得调试变得非常困难。\nThe astute reader may also notice that we could have made the private ArrayReader field final since we did not expose a way to reassign it after it has been set through the constructor. Although it might seem that this would make the ArrayReader constant, ensuring that the ArrayReader object we return cannot be changed, this is not the case. Instead, adding final to a field only ensures that the field itself is not reassigned (i.e. we cannot create a setter for that field). It does not stop the state of the object itself from being changed. If we tried to add final to the getter method, this is futile as well, since final modifier on a method only means that the method cannot be overridden by subclasses.\n读者如果仔细考虑，可能还会注意到，我们可以将私有的 ArrayReader 字段设置为 final，因为我们在通过构造函数赋值之后，没有对它重新赋值的方法。虽然这看起来会使 ArrayReader 成为常量，确保我们返回的 ArrayReader 对象不会被更改，但事实并非如此。如果将 final 添加到字段中只能确保字段本身没有重新赋值（即，不能为该字段创建 setter）而不会阻止对象本身的状态被更改。或者我们试图将 final 添加到 getter 方法中，这也是徒劳的，因为方法上的 final 修饰符只意味着该方法不能被子类重写。\nWe can even go one step further and defensively copy the ArrayReader object in the constructor of Reader, ensuring that the object that was passed into the object cannot be tampered with after it has been supplied to the Reader object. For example, the following cannot happen:\n我们甚至可以更进一步考虑，在 Reader 的构造函数中防御性地复制 ArrayReader 对象，确保在将对象提供给 Reader 对象之后，传入该对象的对象不会被篡改。例如，应避免以下情况发生：\nArrayReader arrayReader = new ArrayReader();arrayReader.setArray(new String[] &#123;&quot;hello&quot;, &quot;world&quot;&#125;);Reader reader = new Reader(arrayReader);arrayReader.setArray(null);    // Change arrayReader after supplying it to Readerreader.read();    // NullPointerException thrown\n\nEven with these three changes (the final modifier on the field, the final modifier on the getter, and the defensive copy of the ArrayReader supplied to the constructor), we still have not solved the problem. The problem is not found in how we are exposing the underlying data of our class, but in the fact that we are doing it in the first place. For us to solve this issue, we have to stop exposing the internal data of our class and instead provide a method to change the underlying data, while still adhering to the class invariants. The following code solves this problem, while at the same time introducing a defensive copy of the supplied ArrayReader and marking the ArrayReader field final, as should be the case since there is no setter:\n即使有了这三个更改（字段上增加 final 修饰符、getter 上增加 final 修饰符以及提供给构造函数的 ArrayReader 的防御性副本），我们仍然没有解决问题。问题不在于我们公开底层数据的方式，而是因为我们是在一开始就是错的。要解决这个问题，我们必须停止公开类的内部数据，而是提供一种方法来更改底层数据，同时仍然遵循类不变量。下面的代码解决了这个问题，同时引入了提供的 ArrayReader 的防御性副本，并将 ArrayReader 字段标记为 final，因为没有 setter，所以应该是这样：\n译注：原文的如下代码有一处错误，Reader 类中的 setArrayReaderArray 方法返回值类型应为 void，该方法是为了取代 setter，不应产生返回值。\npublic class ArrayReader &#123;    public static ArrayReader copy(ArrayReader other) &#123;        ArrayReader copy = new ArrayReader();        String[] originalArray = other.getArray();        copy.setArray(Arrays.copyOf(originalArray, originalArray.length));        return copy;    &#125;    // ... Existing class ...&#125;public class Reader &#123;    private final ArrayReader arrayReader;    public Reader(ArrayReader arrayReader) &#123;        this.arrayReader = ArrayReader.copy(arrayReader);    &#125;    public ArrayReader setArrayReaderArray(String[] array) &#123;        arrayReader.setArray(Objects.requireNonNull(array));    &#125;    public void read() &#123;        arrayReader.read();    &#125;&#125;ArrayReader arrayReader = new ArrayReader();arrayReader.setArray(new String[] &#123;&quot;hello&quot;, &quot;world&quot;&#125;);Reader reader = new Reader(arrayReader);reader.read();Reader flawedReader = new Reader(arrayReader);flawedReader.setArrayReaderArray(null);    // NullPointerException thrown\n\nIf we look at the flawed reader, a NullPointerException is still thrown, but it is thrown immediately when the invariant (that a non-null array is used when reading) is broken, not at some later time. This ensures that the invariant fails-fast, which makes debugging and finding the root of the problem much easier.\n如果我们查看这个有缺陷的读取器，它仍然会抛出 NullPointerException 异常，但在不变量（读取时使用非空数组）被破坏时，会立即抛出该异常，而不是在稍后的某个时间。这确保了不变式失败的速度很快，这使得调试和找到问题的根源变得容易得多。\nWe can take this principle one step further and state that it is a good idea to make the fields of a class completely inaccessible if there is no pressing need to allow for the state of a class to be changed. For example, we could make the Reader class fully encapsulated by removing any methods that modify its state after creation:\n我们可以进一步利用这一原则。如果不迫切需要更改类的状态，那么让类的字段完全不可访问是一个好主意。例如，我们可以通过删除所有能够修改 Reader 类实例对象状态的方法，实现 Reader 类的完全封装：\npublic class Reader &#123;    private final ArrayReader arrayReader;    public Reader(ArrayReader arrayReader) &#123;        this.arrayReader = ArrayReader.copy(arrayReader);    &#125;    public void read() &#123;        arrayReader.read();    &#125;&#125;ArrayReader arrayReader = new ArrayReader();arrayReader.setArray(new String[] &#123;&quot;hello&quot;, &quot;world&quot;&#125;);Reader reader = new Reader(arrayReader);// No changes can be made to the Reader after instantiationreader.read();\n\nTaking this concept to its logical conclusion, it is a good idea to make a class immutable if it is possible. Thus, the state of the object never changes after the object has been instantiated. For example, we can create an immutable Car object as follows:\n从逻辑上总结这个概念，如果可能的话，让类不可变是一个好主意。因此，在实例化对象之后，对象的状态永远不会改变。例如，我们可以创建一个不可变的 Car 对象如下：\npublic class Car &#123;    private final String make;    private final String model;    public Car(String make, String model) &#123;        this.make = make;        this.model = model;    &#125;    public String getMake() &#123;        return make;    &#125;    public String getModel() &#123;        return model;    &#125;&#125;\n\nIt is important to note that if the fields of the class are non-primitive, a client can modify the underlying object as we saw above. Thus, immutable objects should return defensive copies of these objects, disallowing clients to modify the internal state of the immutable object. Note, though, that defensive copying can reduce performance since a new object is created each time the getter is called. This issue should not be prematurely optimized (disregarding immutability for the promise of possible performance increases), but it should be noted. The following snippet provides an example of defensive copying for method return values:\n需要注意的是，如果类的字段不是基本数据类型，客户端可以如前所述那样修改底层对象。因此，不可变对象应该返回这些对象的防御性副本，不允许客户端修改不可变对象的内部状态。但是请注意，防御性复制会降低性能，因为每次调用 getter 时都会创建一个新对象。对于这个缺陷，不应该过早地进行优化（忽视不可变性，以保证可能的性能提高），但是应该注意到这一点。下面的代码片段提供了一个方法返回值的防御性复制示例：\npublic class Transmission &#123;    private String type;    public static Transmission copy(Transmission other) &#123;        Transmission copy = new Transmission();        copy.setType(other.getType);        return copy;    &#125;    public String setType(String type) &#123;        this.type = type;    &#125;    public String getType() &#123;        return type;    &#125;&#125;public class Car &#123;    private final String make;    private final String model;    private final Transmission transmission;    public Car(String make, String model, Transmission transmission) &#123;        this.make = make;        this.model = model;        this.transmission = Transmission.copy(transmission);    &#125;    public String getMake() &#123;        return make;    &#125;    public String getModel() &#123;        return model;    &#125;    public Transmission getTransmission() &#123;        return Transmission.copy(transmission);    &#125;&#125;\n\nThis leaves us with the following principle:\n这给我们提示了以下原则：\nMake classes immutable, unless there is a pressing need to change the state of a class. All fields of an immutable class should be marked as private and final to ensure that no reassignments are performed on the fields and no indirect access should be provided to the internal state of the fields\n使类不可变，除非迫切需要更改类的状态。不可变类的所有字段都应该标记为 private 和 final，以确保不会对字段执行重新赋值，也不会对字段的内部状态提供间接访问\nImmutability also brings with it some very important advantages, such as the ability of the class to be easily used in a multi-threaded context (i.e. two threads can share the object without fear that one thread will alter the state of the object while the other thread is accessing that state). In general, there are many more instances that we can create immutable classes than we realize at first: Many times, we add getters or setters out of habit.\n不变性还带来了一些非常重要的优点，例如类能够在多线程上下文中轻松使用（即两个线程可以共享对象，而不用担心一个线程会在另一个线程访问该状态时更改该对象的状态）。总的来说，在很多实际情况下我们可以创建不可变的类，要比我们意识到的要多很多，只是我们习惯了添加了 getter 或 setter。\nConclusion结论\nMany of the applications we create end up working, but in a large number of them, we introduce sneaky problems that tend to creep up at the worst possible times. In some of those cases, we do things out of convenience, or even out of habit, and pay little mind to whether these idioms are practical (or safe) in the context we use them. In this article, we delved into three of the most common of these practices, such null return values, affinity for functional programming, and careless getters and setters, along with some pragmatic alternatives. While the rules in this article should not be taken as absolute, they do provide some insight into the uncommon dangers of common practices and may help in fending off laborious errors in the future.\n我们创建的许多应用程序最终都能正常工作，但是在大量应用程序中，我们无意引入的一些问题可能只会在最极端的情况下出现。在某些情况下，我们做事情是出于方便，甚至是出于习惯，而很少注意这些习惯在我们使用的上下文中是否实用（或安全）。在本文中，我们深入研究了在实际应用中最常见的三种问题，如：空返回值、函数式编程的魅力、粗心的 getter 和 setter，以及一些实用的替代方法。虽然本文中的规则不是绝对的，但是它们确实为一些在实际应用中遇到的罕见问题提供了见解，并且在将来可能会有助于避免产生一些需要费力解决的错误。\n","categories":["文献翻译","java"],"tags":["未标记"]},{"title":"9-differences-between-Array-and-ArrayList-in-Java","url":"/46868f90-2bb6-11ee-879b-0b2c36f14b2e/","content":"\n\n\n\n9 differences between Array and ArrayList in JavaJava 中数组和 ArrayList 的 9 个区别\n\n转译自：https://www.javacodegeeks.com/2016/01/9-differences-between-array-and-arraylist-in-java.html\n\nBoth array and ArrayList are two important data structures in Java and are frequentl used in Java programs. Even though ArrayList is internally backed by an array, knowing the difference between an array and an ArrayList in Java is critical for becoming a good Java developer. If you know the similarity and differences, you can judiciously decide when to use an array over an AraryList or vice-versa.\n数组和 ArrayList 都是 Java 中非常重要的数据结构，在 Java 程序中经常使用。虽然 ArrayList 是由数组内部支持的，了解 Java 中数组和 ArrayList 之间的区别对于成为一名优秀的 Java 开发人员至关重要。如果你知道相似性和差异性，你就可以明智地决定何时以 AraryList（取代）数组，反之亦然。\nIn this article, I’ll help you understand the difference. If you are coming from C or C++ background then you already know that array is one of the most useful data structure in the programming world. It offers O(1) performance for index-based search and one of the fundamental way to store data.\n在本文中，我将帮助你理解其中的区别。如果你有 C 或 C++ 背景，那么肯定知道数组是编程世界中最有用的数据结构之一。它为基于索引的搜索提供了 O(1) 性能，是存储数据的基本方式之一。\nThe ArrayList one the other hand is a class in Java Collection framework which was introduced as a dynamic array. Since an array is static in nature i.e. you cannot change the size of an array once created, So, if you need an array which can resize itself then you should use the ArrayList. This is the fundamental difference between an array and an ArrayList.\nArrayList 是 Java 集合框架中的一个类，作为动态数组引入。由于数组本质上是静态的，也就是说，一旦创建了数组，你就不能更改数组的大小，因此，如果你需要一个能够调整自身大小的数组，那么你应该使用 ArrayList。这是数组和 ArrayList 的基本区别。\nArray vs ArrayList in JavaJava 中的数组与 ArrayList\nIt’s best to compare two things on some points, this will make the differences easy to understand. So let’s see what are the points on which you can compare an array with the ArrayList in Java\n最好在某些技术点上比较两件事情，这将使两者的区别容易理解。那么，让我们看看在哪些技术点上可以将数组与 Java 中的 ArrayList 进行比较。\n1、Implementation实现\nThe array is a native programming component or data structure but ArrayList is a class from Java Collections framework, an API. In fact, ArrayList is internally implemented using an array. Since ArrayList is a class, it holds all properties of a class e.g. you can create objects and call methods but even though the array is an object in Java it doesn’t provide any method. It just exposes a length attribute to give you the length of the array, which is constant.\n数组是原生编程组件或数据结构，而 ArrayList 是 Java 集合框架中的一个类，是一个 API。实际上，ArrayList 内部是使用数组实现的。因为 ArrayList 是一个类，它包含一个类的所有属性，例如，你可以创建对象和调用方法，但即使数组是 Java 中的一个对象，它也不提供任何方法。它只是公开了一个 length 属性来给你数组的长度，这是常量。\n2、Performance性能\nSince ArrayList is based upon array, you would assume that it provides the same performance as an array. This is true at some extent but because of extra functionality ArrayList provides there is some difference in performance between ArrayList and array, mainly in terms of memory usage and CPU time.\n由于 ArrayList 是基于数组的，因此可以假设它提供了与数组相同的性能。这在某种程度上是正确的，但是由于 ArrayList 提供了额外的功能，所以 ArrayList 和数组之间的性能有一些不同，主要是在内存使用和 CPU 时间方面。\nFor index-based access, both ArrayList and array provides O(1) performance but add can be O(logN) in ArrayList if adding a new element triggers resize, as it involves creating a new array in background and copying elements from the old array to new array. The memory requirement for ArrayList is also more than an array for storing the same number of objects e.g. an int[] will take less memory to store 20 int variables than an ArrayList because of object metadata overhead on both ArrayList and wrapper class.\n对于基于索引的访问，ArrayList 和数组都提供了 O(1) 性能，但是如果在 ArrayList 中添加一个新元素会触发调整大小，那么 add 可以是 O(logN)，因为它涉及在后台创建一个新数组，并将元素从旧数组复制到新数组。ArrayList 的内存需求也不仅仅是存储相同数量对象的数组，例如 int[] 比 ArrayList 存储 20 个 int 变量所需内存更少，因为 ArrayList 和包装类上都有对象元数据开销。\n3、Type Safety类型安全\nArrayList is type safe because it supports generics which allows the compiler to check if all objects stored in ArrayList are of the correct type. On the other hand, the array doesn’t support Generics. Which means compile time checking is not possible but array provides runtime type checking by throwing ArrayStoreException if you try to store an incorrect object into array e.g. storing a String into an int array.\nArrayList 是类型安全的，因为它支持泛型，允许编译器检查存储在 ArrayList 中的所有对象是否都是正确的类型。另一方面，数组不支持泛型。这意味着编译时检查是不可能的，但是如果你试图将一个不正确的对象存储到数组中，例如将一个字符串存储到 int 数组中，数组通过抛出 ArrayStoreException（体现）提供了运行时类型检查。\n4、Flexibility灵活性\nFlexibility is the single most important thing that separates array and ArrayList. In short, ArrayList is more flexible than a plain native array because it’s dynamic. It can grow itself when needed, which is not possible with the native array. ArrayList also allows you to remove elements which are not possible with native arrays. By remove, we mean not just assigning null to the corresponding index but also copying rest of elements one index down, which ArrayList automatically does for you. You can learn more about removing objects from ArayList in my article difference between clear() and removeAll().\n灵活性是区分数组和数组列表最重要的一点。简而言之，ArrayList 比普通的原生数组更灵活，因为它是动态的。它可以在需要时自行增长，这在原生数组中是不可能的。ArrayList 还允许删除原生数组无法删除的元素。所谓删除，我们的意思不仅仅是给相应的索引分配 null，还包括将其他元素的一个索引复制下来，ArrayList 会自动为你这样做。在我的文章《clear() 和 removeAll() 的区别》中，你可以了解关于从 ArayList 中删除对象的更多信息。\n5、Primitives基本数据类型\nIf you first start using ArrayList then you will realize that you cannot store primitives on ArrayList. This is a key difference between array and ArrayList because array allows storing both primitives and object. For example int[] numbers are valid but ArrayList of int is not valid. how do you deal with this problem?\n如果你第一次开始使用 ArrayList，那么你将意识到不能在 ArrayList 上存储基本数据类型。这是数组和 ArrayList 之间的一个关键区别，因为数组允许存储基本数据类型和对象。例如 int[] 数字是有效的，但是 ArrayList 是无效的。你如何处理这个问题？\nSuppose you want to store int primitives into ArrayList than how do you that? Well, you can use the wrapper class. This is one of the reasons why wrapper class was introduced in Java. So if you want to store int 2 into ArrayList just put it, autoboxing will do the rest. Btw, this difference is not so obvious from Java 5 onwards because of auto-boxing as you will see that ArrayList.add(21) is perfectly valid and works.\n假设你想把 int 类型存储到 ArrayList 中，你会怎么做？你可以使用包装器类。这是 Java 中引入包装类的原因之一。如果你想把 int 2 存储到 ArrayList 中，只要把它放进去，自动装箱就能完成剩下的。顺便说一下，从 Java 5 开始，由于自动装箱的原因，这种差异就不那么明显了，因为你将看到 ArrayList.add(21) 是完全有效的，并且可以工作。\n6、Generics泛型\nOne more significant（重要的） difference between an ArrayList and an array is that the former supports Generic but the latter doesn’t. Since an array is of covariant type, you can use Generics with them. This means it’s not possible for a compiler to check the type-safety of an array at compile time but they can verify type-safety of Array. So how do you deal with this problem while writing a type-safe class in Java? Well, you can use the technique shown in Effective Java, where you can declare an array like E[] and later use type casting.\nArrayList 和数组的另一个重要区别是前者支持泛型，而后者不支持泛型。由于数组是协变类型的，所以可以使用泛型。这意味着编译器不可能在编译时检查数组的类型安全性，但它们可以验证数组的类型安全性。那么，在用 Java 编写类型安全类时，如何处理这个问题呢？你可以使用 Effective Java 中所示的技术，可以声明一个像 E[] 这样的数组，然后使用类型转换。\n7、Iteration迭代\nArrayList provides more ways for iteration i.e. accessing all elements one by one than an array. You can only use loop e.g. for, while, enhanced for loop and do-while to iterate over an array but you can also use Iterator and ListIterator class to iterate over ArrayList. See here to learn different ways to iterate over ArrayList in Java.\nArrayList 相比数组而言为迭代，即逐个访问所有元素，提供了更多的方法。你只能使用 for 循环、 while 循环、增强 for 循环和 do-while 来迭代数组，但你也可以使用 Iterator 和 ListIterator 类来迭代 ArrayList。请参阅此处以了解在 Java 中迭代 ArrayList 的不同方法。\n8、Supported Operations运算符支持\nSince ArrayList is backed by an array internally, it exposes（揭露） the operation which is possible with an array but given its dynamic nature it also added operation which is not possible with native array e.g. you can store elements in both array and ArrayList, but only ArrayList allows you to remove an element. Though you can simulate that with an array by assigning null to respective index, it won’t be like remove unless you also move all element above that index in the array to one level down.\n因为 ArrayList 是由数组在内部支持的，所以它公开了使用数组可以实现的操作，但考虑到它的动态特性，它还添加了使用原生数组不可能实现的操作，例如，你可以在数组和 ArrayList 中存储元素，但只有 ArrayList 允许你删除元素。虽然你可以通过将 null 赋值给相应的索引来模拟这个过程，但是它不会像 remove （方法）那样，除非你还将数组中位于该索引之上的所有元素向下移动一层。\nBoth ArrayList and array provide ways to retrieve an element e.g. get() method of ArrayList uses an index to get an element from array e.g. version[0] will return the first element.\nArrayList 和数组都提供了检索元素的方法，例如 ArrayList 的 get() 方法使用索引从数组中获取元素，例如 version[0] 将返回第一个元素。\nArrayList also provides an operation to clear and reuse（重 chong 用） e.g. clear() and removeAll(), the array doesn’t provide that but you can loop over Array and assign each index null to simulate that.\nArrayList 还提供了一个清除和重用的操作，例如 clear() 和 removeAll()，数组没有提供这个功能，但是你可以用循环数组，为每个索引分配 null 的方式来模拟它。\n9、Size() vs lengthSize() 方法与 length 属性\nArray only provides a length attribute which tells you the number of slots in the array i.e. how many elements it can store, it doesn’t provide you any method to find out how many are filled and how many slots are empty i.e. the current number of elements. While ArrayList does provides a size() method which tells a number of objects stored in ArrayList at a given point of time. The size() is always different than length, which is also the capacity of ArrayList. If you want to know more, I suggest you read the difference between size() and length in ArrayList article.\n数组只提供一个 length 属性，它告诉你数组中的槽数，也就是它可以存储多少个元素，它不提供任何方法来找出有多少个被填充，有多少个槽是空的，也就是当前元素的数量。虽然 ArrayList 提供了一个 size() 方法，它告诉在给定时间点存储在 ArrayList 中的许多对象。size() 总是与 length 不同，length 也是 ArrayList 的容量。如果你想了解更多，我建议你阅读 ArrayList 文章中的 size() 和 length 之间的区别。\n10、Dimension维度\nAnother significant（重要的） difference between an array and an ArrayList is that array can be multi-dimensional e.g. you can have a two-dimensional array or a three-dimensional array, which makes it a really special data structure to represent matrices and 2D terrains. On the other hand, ArrayList doesn’t allow you to specify dimension. See this tutorial learn more about how to use a multi-dimensional array in Java.\n数组和 ArrayList 的另一个重要区别是，数组可以是多维的，例如，你可以有一个二维数组或三维数组，这使得它可以成为一种非常特殊的数据结构来表示矩阵和二维地形。另一方面，ArrayList 不允许指定维度。请参阅本教程，了解如何在 Java 中使用多维数组。\nHere is the nice slide highlighting all important difference between Array and ArrayList in Java:\n下面这张幻灯片（注：已将图片内容转为文字）突出了 Java 中数组和 ArrayList 的所有重要区别：\nDifference between array vs ArrayList in JavaJava 中数组与 ArrayList 的区别\n1、An array is static, you cannot change it’s length once created, but ArrayList is dynamic, it can grow to accommodate more elements.\n数组是静态的，一旦创建就不能改变它的长度，但是 ArrayList 是动态的，它可以增长以适应更多的元素。\n2、The array doesn’t support generics, hence they are not type-safe but ArrayList support Generics, hence they provide compile time type-safety.\n数组不支持泛型，因此它们不是类型安全的，但是 ArrayList 支持泛型，因此它们提供编译时类型安全。\n3、Array takes less memory than Arrayist for storing same number of elements or objects.\n在存储相同数量的元素或对象时，数组比 Arrayist 占用更少的内存。\n4、ArrayList allows you to remove element, but array doesn’t provide such methods.\nArrayList 允许删除元素，但数组不提供这样的方法。\n5、Array can accommodate both primitive and objects, but Arraylist can only accommodate objects.\n数组可以同时容纳基础数据类型和对象，但 Arraylist 只能容纳对象。\n译注：本文第 5 点提到了，从 Java 5 开始 Arraylist 也能容纳基础数据类型\n6、Array can be multi-dimensional but ArrayList is always one dimensional.\n数组可以是多维的，但 ArrayList 总是一维的。\n译注：应该说 ArrayList 默认是一维的，如果每个元素也是一个 ArrayList，可以间接实现多维\n7、Array provides length attribute and ArrayList provides size() but both are different, length is capacity, while size() return number of elements.\n数组提供 length 属性，ArrayList 提供 size()，但两者不同，length 是容量，size() 返回元素数量。\nSimilarities between Array and ArrayList数组和数组列表的相似性\nSo far you have seen the difference between an ArrayList and an array, now let’s concentrate（关注） on some of the similarities. Since ArrayList internally uses array, it’s bound to have lot of similarities as seen below:\n到目前为止，你已经看到了 ArrayList 和数组之间的区别，现在让我们关注一些相似之处。由于 ArrayList 内部使用数组，两者肯定有很多相似之处，如下所示：\n1、Data Structure数据结构\nBoth allow you to store objects in Java and both are an index-based data structure which provides O(1) performance to retrieve an element, but search without an index is still log(N) if your array is sorted and you use binary search algorithm.\n这两种方法都允许在 Java 中存储对象，并且都是基于索引的数据结构，它提供了 O(1) 性能来检索元素，但是如果数组是有序的，并且使用二进制搜索算法，那么没有索引的搜索仍然是 log(N)。\n2、Order有序性\nBoth array and ArrayList maintain order on which elements are added into them.\n数组和 ArrayList 的元素顺序就是添加时的顺序。\n3、Search搜索\nYou can search for an element using an index, that’s O(1) otherwise you can use linear search if your array is not sorted, which takes around O(n) time or you can use binary search after sorting an array in Java, this is sorting + O(logN).\n你可以用索引来搜索一个元素，它是 O(1) 的，如果你的数组没有排序，你可以用线性搜索，这需要大约 O(n) 的时间，或者你可以用二分法检索，在 Java 中对一个数组排序后，这种排序的时间复杂度为 O(logN)。\n4、Null valuesNull 值\nBoth array and ArrayList allow null values but remember only object array allows null primitive array doesn’t they store the default value of primitive type e.g. zero for int and false for boolean.\n数组和 ArrayList 都允许 null 值，但记住只有对象数组允许 null 基本数据类型数组，它们不存储基本数据类型类型的默认值，例如，0 表示 int, false 表示 boolean。\n5、Duplicates重复\nBoth array and ArrayList allow duplicates. It’s also one of the common array based coding questions to write a program to find out duplicates from an array in place.\n数组和 ArrayList 都允许（元素）重复。它也是一个常见的基于数组的编码问题，即编写一个程序从一个数组中找出（元素）副本。\n6、Performance性能\nArrayList mimic array’s performance e.g. O(1) access if you know the index but it has additional memory overhead because it’s an object and also holds additional data to automatic resize the ArrayList.\nArrayList 模拟数组的性能，如 O(1) 访问，如果你知道索引，但是它有额外的内存开销，因为它是一个对象，而且还包含额外的数据来自动调整 ArrayList 的大小。\n7、Zero-based Index从零开始的索引\nBoth array and ArrayList have zero-based index i.e. first element starts at zeroth index.\n数组和 ArrayList 都有从零开始的索引，即第一个元素从第 0 个索引开始。\nThe most important difference you should remember is that array is static in nature i.e. you cannot change their size once created but ArrayList is a dynamic array, which can resize itself if a number of elements in the ArrayList are more than the resize threshold. Based upon this difference, you should use an array as a data structure to store objects if you know the size in advance and sure it’s not going to change, if you are unsure then just use the ArrayList.\n你应该记住的最重要的区别是数组本质上是静态的，也就是说你不能改变它们的大小，但是 ArrayList 是一个动态数组，如果 ArrayList 中的一些元素超过了阈值，它可以调整自己的大小。基于这种差异，如果你事先知道对象的大小并且确定不会改变对象的大小，那么你应该使用数组作为数据结构来存储对象，如果你不确定，那么就使用 ArrayList。\n","categories":["文献翻译","java"],"tags":["未标记"]},{"title":"Enabling-Cross-Origin-Requests-for-a-RESTful-Web-Service","url":"/4686b6a0-2bb6-11ee-879b-0b2c36f14b2e/","content":"\n\n\n\nEnabling Cross Origin Requests for a RESTful Web Service为 RESTful Web 服务启用跨域请求\n\n转译自：https://spring.io/guides/gs/rest-service-cors/\n\nThis guide walks you through the process of creating a “Hello, World” RESTful web service with Spring that includes headers for Cross-Origin Resource Sharing (CORS) in the response. You can find more information about Spring CORS support in this blog post.\n本指南指导你使用 Spring 创建「Hello, World」RESTful Web 服务，包括响应跨域资源共享（CORS）头。你可以在这篇博客文章中找到更多关于 Spring 支持 CORS 的信息。\nWhat You Will Build你将创建什么项目\nYou will build a service that accepts HTTP GET requests at http://localhost:8080/greeting and responds with a JSON representation of a greeting, as the following listing shows:\n你将建立一个服务器端，它能够接受一个 HTTP GET 请求 http://localhost:8080/greeting，并且响应一个 JSON 格式的数据，如下所示：\n&#123;&quot;id&quot;:1,&quot;content&quot;:&quot;Hello, World!&quot;&#125;\n\nYou can customize the greeting with an optional name parameter in the query string, as the following listing shows:\n你可以在这个查询中为这个问候语定义一个可选的 name 参数，如下所示：\nhttp://localhost:8080/greeting?name=User\n\nThe name parameter value overrides the default value of World and is reflected in the response, as the following listing shows:\nname 参数值将覆盖默认值「World」并体现在响应中，如下所示：\n&#123;&quot;id&quot;:1,&quot;content&quot;:&quot;Hello, User!&quot;&#125;\n\nThis service differs slightly from the one described in Building a RESTful Web Service, in that it uses Spring Framework CORS support to add the relevant CORS response headers.\n这个服务与其他构建 RESTful Web Service 中描述的服务略有不同，因为它使用 Spring Framework CORS 支持来添加相关的 CORS 响应头。\nWhat You Need需要如下环境\n\nAbout 15 minutes\nA favorite text editor or IDE\nJDK 1.8 or later\nGradle 4+ or Maven 3.2+\nYou can also import the code straight into your IDE:\nSpring Tool Suite (STS)\nIntelliJ IDEA\n\n\n\nHow to complete this guide如何完成这个指南\nLike most Spring Getting Started guides, you can start from scratch and complete each step or you can bypass basic setup steps that are already familiar to you. Either way, you end up with working code.\n就像大多数 Spring 入门指南一样，你可以从头开始并完成每个步骤，也可以跳过已经熟悉的基本设置步骤。无论哪种方式，最终得到的都是能够工作的代码。\nTo start from scratch, move on to Starting with Spring Initializr.\n要从头开始，请继续从 Spring Initializr 开始。\nTo skip the basics, do the following:\n要跳过这些基本步骤，请执行以下步骤:\n\nDownload and unzip the source repository for this guide, or clone it using Git: git clone https://github.com/spring-guides/gs-rest-service-cors.git\n\n下载并解压本指南的源码存储库，或者使用 Git 克隆它：git clone https://github.com/spring-guides/gs-rest-service-cors.git\n\ncd into gs-rest-service-cors&#x2F;initial\n\n进入 gs-rest-service-cors/initial 目录\n\nJump ahead to Create a Resource Representation Class.\n\n跳到 Create a Resource Representation Class 前面。\nWhen you finish, you can check your results against the code in gs-rest-service-cors/complete.\n完成后，可以根据 gs-rest-service-cors/complete 目录中的代码检查结果。\nStarting with Spring Initializr从 Spring Initializr 开始\nFor all Spring applications, you should start with the Spring Initializr. The Initializr offers a fast way to pull in all the dependencies you need for an application and does a lot of the setup for you. This example needs only the Spring Web dependency. The following image shows the Initializr set up for this sample project:\n对于所有 Spring 应用程序，应该从 Spring Initializr 开始。Initializr 提供了一种快捷方法来获取应用程序所需的所有依赖项，并做了大量的设置工作。这个例子只需要 Spring Web 依赖项。下图显示了为这个示例项目设置的 Initializr：\n（原文该处为 Spring Initializr 页面图片，略）\n\nThe preceding image shows the Initializr with Maven chosen as the build tool. You can also use Gradle. It also shows values of com.example and rest-service-cors as the Group and Artifact, respectively. You will use those values throughout the rest of this sample.\n\n前面的图片显示了项目以 Maven 作为 Initializr 的构建工具。你也可以使用 Gradle。它还显示了 com.example 的值。将 rest-service-cors 分别作为 Group 和 Artifact 的值。在本示例的其余部分中会使用这些值。\nThe following listing shows the pom.xml file that is created when you choose Maven:\n当选择 Maven 作为构建工具时，生成的 pom.xml 文件如下所示：\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\txsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\t&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\t&lt;parent&gt;\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\t\t&lt;version&gt;2.2.0.RELEASE&lt;/version&gt;\t\t&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\t&lt;/parent&gt;\t&lt;groupId&gt;com.example&lt;/groupId&gt;\t&lt;artifactId&gt;rest-service-cors&lt;/artifactId&gt;\t&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\t&lt;name&gt;rest-service-cors&lt;/name&gt;\t&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;\t&lt;properties&gt;\t\t&lt;java.version&gt;1.8&lt;/java.version&gt;\t&lt;/properties&gt;\t&lt;dependencies&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\t\t\t&lt;scope&gt;test&lt;/scope&gt;\t\t\t&lt;exclusions&gt;\t\t\t\t&lt;exclusion&gt;\t\t\t\t\t&lt;groupId&gt;org.junit.vintage&lt;/groupId&gt;\t\t\t\t\t&lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;\t\t\t\t&lt;/exclusion&gt;\t\t\t&lt;/exclusions&gt;\t\t&lt;/dependency&gt;\t&lt;/dependencies&gt;\t&lt;build&gt;\t\t&lt;plugins&gt;\t\t\t&lt;plugin&gt;\t\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t\t&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\t\t\t&lt;/plugin&gt;\t\t&lt;/plugins&gt;\t&lt;/build&gt;&lt;/project&gt;\n\nThe following listing shows the build.gradle file that is created when you choose Gradle:\n当选择 Gradle 作为构建工具时，生成的 build.gradle 文件如下所示：\nplugins &#123;\tid &#x27;org.springframework.boot&#x27; version &#x27;2.2.0.RELEASE&#x27;\tid &#x27;io.spring.dependency-management&#x27; version &#x27;1.0.8.RELEASE&#x27;\tid &#x27;java&#x27;&#125;group = &#x27;com.example&#x27;version = &#x27;0.0.1-SNAPSHOT&#x27;sourceCompatibility = &#x27;1.8&#x27;repositories &#123;\tmavenCentral()&#125;dependencies &#123;\timplementation &#x27;org.springframework.boot:spring-boot-starter-web&#x27;\ttestImplementation(&#x27;org.springframework.boot:spring-boot-starter-test&#x27;) &#123;\t\texclude group: &#x27;org.junit.vintage&#x27;, module: &#x27;junit-vintage-engine&#x27;\t&#125;&#125;test &#123;\tuseJUnitPlatform()&#125;\n\nAdding the httpclient Dependency增加 httpclient 依赖\nThe tests (in complete&#x2F;src&#x2F;test&#x2F;java&#x2F;com&#x2F;example&#x2F;restservicecors&#x2F;GreetingIntegrationTests.java) require the Apache httpclient library.\n单元测试（路径为 complete/src/test/java/com/example/restservicecors/GreetingIntegrationTests.java）需要 Apache httpclient 库。\nTo add the Apache httpclient library to Maven, add the following dependency:\n在 Maven 增加 Apache httpclient 库的依赖：\n&lt;dependency&gt;  &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;  &lt;artifactId&gt;httpclient&lt;/artifactId&gt;  &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;\n\nThe following listing shows the finished pom.xml file:\n最终的 pom.xml 文件如下所示：\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\txsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\t&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\t&lt;parent&gt;\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\t\t&lt;version&gt;2.2.0.RELEASE&lt;/version&gt;\t\t&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\t&lt;/parent&gt;\t&lt;groupId&gt;com.example&lt;/groupId&gt;\t&lt;artifactId&gt;rest-service-cors&lt;/artifactId&gt;\t&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\t&lt;name&gt;rest-service-cors&lt;/name&gt;\t&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;\t&lt;properties&gt;\t\t&lt;java.version&gt;1.8&lt;/java.version&gt;\t&lt;/properties&gt;\t&lt;dependencies&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;httpclient&lt;/artifactId&gt;\t\t\t&lt;scope&gt;test&lt;/scope&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\t\t\t&lt;scope&gt;test&lt;/scope&gt;\t\t\t&lt;exclusions&gt;\t\t\t\t&lt;exclusion&gt;\t\t\t\t\t&lt;groupId&gt;org.junit.vintage&lt;/groupId&gt;\t\t\t\t\t&lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;\t\t\t\t&lt;/exclusion&gt;\t\t\t&lt;/exclusions&gt;\t\t&lt;/dependency&gt;\t&lt;/dependencies&gt;\t&lt;build&gt;\t\t&lt;plugins&gt;\t\t\t&lt;plugin&gt;\t\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t\t&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\t\t\t&lt;/plugin&gt;\t\t&lt;/plugins&gt;\t&lt;/build&gt;&lt;/project&gt;\n\nTo add the Apache httpclient library to Gradle, add the following dependency:\n在 Gradle 增加 Apache httpclient 库的依赖：\ntestImplementation &#x27;org.apache.httpcomponents:httpclient&#x27;\n\nThe following listing shows the finished build.gradle file:\n最终的 build.gradle 文件如下所示：\nplugins &#123;\tid &#x27;org.springframework.boot&#x27; version &#x27;2.2.0.RELEASE&#x27;\tid &#x27;io.spring.dependency-management&#x27; version &#x27;1.0.8.RELEASE&#x27;\tid &#x27;java&#x27;&#125;group = &#x27;com.example&#x27;version = &#x27;0.0.1-SNAPSHOT&#x27;sourceCompatibility = &#x27;1.8&#x27;repositories &#123;\tmavenCentral()&#125;dependencies &#123;\timplementation &#x27;org.springframework.boot:spring-boot-starter-web&#x27;\ttestImplementation &#x27;org.apache.httpcomponents:httpclient&#x27;\ttestImplementation(&#x27;org.springframework.boot:spring-boot-starter-test&#x27;) &#123;\t\texclude group: &#x27;org.junit.vintage&#x27;, module: &#x27;junit-vintage-engine&#x27;\t&#125;&#125;test &#123;\tuseJUnitPlatform()&#125;\n\nCreate a Resource Representation Class创建资源表示类\nNow that you have set up the project and build system, you can create your web service.\n现在已经建立了项目和构建系统，可以创建 web 服务了。\nBegin the process by thinking about service interactions.\n在这个过程中考虑服务交互。\nThe service will handle GET requests to &#x2F;greeting, optionally with a name parameter in the query string. The GET request should return a 200 OK response with JSON in the body to represent a greeting. It should resemble the following listing:\n该服务将处理 /greeting 的 GET 请求，也可以在查询字符串中使用 name 参数。GET 请求应该返回一个包含 JSON 的 200 OK 响应来表示问候语。它应该与如下所示类似：\n&#123;  &quot;id&quot;: 1,  &quot;content&quot;: &quot;Hello, World!&quot;&#125;\n\nThe id field is a unique identifier for the greeting, and content is the textual representation of the greeting.\nid 字段是问候语的唯一标识符，而内容是问候语的文本表示。\nTo model the greeting representation, create a resource representation class. Provide a plain old Java object with fields, constructors, and accessors for the id and content data, as the following listing (from src/main/java/com/example/restservicecors/Greeting.java) shows:\n要对问候语表示进行建模，请创建一个资源表示类。为 id 和内容数据提供一个普通的旧 Java 对象，包含字段、构造函数和访问器，如下所示（来自 src/main/ Java /com/example/restservicecors/Greeting.java）：\npackage com.example.restservicecors;public class Greeting &#123;\tprivate final long id;\tprivate final String content;\tpublic Greeting() &#123;\t\tthis.id = -1;\t\tthis.content = &quot;&quot;;\t&#125;\tpublic Greeting(long id, String content) &#123;\t\tthis.id = id;\t\tthis.content = content;\t&#125;\tpublic long getId() &#123;\t\treturn id;\t&#125;\tpublic String getContent() &#123;\t\treturn content;\t&#125;&#125;\n\n\nSpring uses the Jackson JSON library to automatically marshal instances of type Greeting into JSON.\n\nSpring 使用 Jackson JSON 库自动将 Greeting 类型的实例封装到 JSON 中。\nCreate a Resource Controller创建资源控制器\nIn Spring’s approach to building RESTful web services, HTTP requests are handled by a controller. These components are easily identified by the @Controller annotation, and the GreetingController shown in the following listing (from src/main/java/com/example/restservicecors/GreetingController.java) handles GET requests for &#x2F;greeting by returning a new instance of the Greeting class:\n在 Spring 构建 RESTful web 服务的方式中，HTTP 请求由控制器处理。这些组件很容易通过 @Controller 注解定义，下面清单中显示的 GreetingController（来自 src/main/java/com/example/restservicecors/GreetingController.java）通过返回 Greeting 类的一个新实例来处理 GET 请求 /greeting：\npackage com.example.restservicecors;import java.util.concurrent.atomic.AtomicLong;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.CrossOrigin;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class GreetingController &#123;\tprivate static final String template = &quot;Hello, %s!&quot;;\tprivate final AtomicLong counter = new AtomicLong();\t@GetMapping(&quot;/greeting&quot;)\tpublic Greeting greeting(@RequestParam(required=false, defaultValue=&quot;World&quot;) String name) &#123;\t\tSystem.out.println(&quot;==== in greeting ====&quot;);\t\treturn new Greeting(counter.incrementAndGet(), String.format(template, name));\t&#125;&#125;\n\nThis controller is concise and simple, but there is plenty going on under the hood. We break it down step by step.\n这个控制器简洁而简单，但在引擎盖下有很多东西。我们一步一步地分析它。\nThe @RequestMapping annotation ensures that HTTP requests to &#x2F;greeting are mapped to the greeting() method.\n@RequestMapping 注解确保对 /greeting 的 HTTP 请求映射到 greeting() 方法。\n\nThe preceding example uses the @GetMapping annotation, which acts as a shortcut for @RequestMapping(method = RequestMethod.GET).\n\n注意：前面的示例使用的 @GetMapping 注解是 @RequestMapping(method = RequestMethod.GET) 的简写。\n@RequestParam binds the value of the name query string parameter into the name parameter of the greeting() method. This query string parameter is not required. If it is absent in the request, the defaultValue of World is used.\n@RequestParam 将包含 name 参数的查询字符串值绑定到 greeting() 方法的名称参数中。此查询字符串参数不是必需的。如果它在请求中不存在，则使用「World」默认值。\nThe implementation of the method body creates and returns a new Greeting object, with the value of the id attribute based on the next value from the counter and the value of the content based on the query parameter or the default value. It also formats the given name by using the greeting template.\n方法实现创建并返回一个新的 Greeting 对象，其中 id 属性的值基于计数器的下一个值，内容的值基于查询参数或默认值。它还通过使用问候语模板来格式化给定的 name。\nA key difference between a traditional MVC controller and the RESTful web service controller shown earlier is the way that the HTTP response body is created. Rather than relying on a view technology to perform server-side rendering of the greeting data to HTML, this RESTful web service controller populates and returns a Greeting object. The object data is written directly to the HTTP response as JSON.\n传统 MVC 控制器和 RESTful web 服务控制器之间的一个关键区别是 HTTP 响应体的创建方式。与依赖视图技术将问候语数据执行服务器端呈现为 HTML 不同，这个 RESTful web 服务控制器填充并返回一个 Greeting 对象。对象数据直接以 JSON 的形式写入 HTTP 响应。\nTo accomplish this, the @ResponseBody annotation on the greeting() method tells Spring MVC that it does not need to render the greeting object through a server-side view layer. Instead, the returned greeting object is the response body and should be written out directly.\n为此，greeting() 方法上的 @ResponseBody 注解告诉 Spring MVC，它不需要通过服务器端视图层呈现 greeting 对象。相反，返回的 greeting 对象是响应体，应该直接写出来。\nThe Greeting object must be converted to JSON. Thanks to Spring’s HTTP message converter support, you need not do this conversion manually. Because Jackson is on the classpath, Spring’s MappingJackson2HttpMessageConverter is automatically chosen to convert the Greeting instance to JSON.\nGreeting 对象必须转换为 JSON。由于 Spring 的 HTTP 消息转换器支持，不需要手动执行此转换。因为 J ackson 位于类路径中，所以会自动调用 Spring 的 MappingJackson2HttpMessageConverter 将 Greeting 实例转换为 JSON。\nEnabling CORS启用跨域资源共享（CORS）\nYou can enable cross-origin resource sharing (CORS) from either in individual controllers or globally. The following topics describe how to do so:\n你可以在单个控制器或全局控制器中启用跨源资源共享（CORS）。以下主题描述了如何做到这一点：\n\nController Method CORS Configuration\n\n控制器方法的 CORS 配置\n\nGlobal CORS configuration\n\n全局 CORS 配置\nController Method CORS Configuration控制器方法的 CORS 配置\nSo that the RESTful web service will include CORS access control headers in its response, you have to add a @CrossOrigin annotation to the handler method, as the following listing (from src/main/java/com/example/restservicecors/GreetingController.java) shows:\n为了使 RESTful web 服务在其响应中包含 CORS 访问控制头，必须向处理程序方法添加一个 @CrossOrigin 注释，如下所示（来自 src/main/java/com/example/restservicecors/GreetingController.java）：\n@CrossOrigin(origins = &quot;http://localhost:9000&quot;)@GetMapping(&quot;/greeting&quot;)public Greeting greeting(@RequestParam(required=false, defaultValue=&quot;World&quot;) String name) &#123;\tSystem.out.println(&quot;==== in greeting ====&quot;);\treturn new Greeting(counter.incrementAndGet(), String.format(template, name));&#125;\n\nThis @CrossOrigin annotation enables cross-origin resource sharing only for this specific method. By default, its allows all origins, all headers, and the HTTP methods specified in the @RequestMapping annotation. Also, a maxAge of 30 minutes is used. You can customize this behavior by specifying the value of one of the following annotation attributes:\n@CrossOrigin 注解只支持这个特定方法的跨源资源共享。默认情况下，它允许所有的源、所有的头和在 @RequestMapping 注解中指定的 HTTP 方法。此外，最大使用 30 分钟。可以通过指定下列注解属性之一的值来自定义此行为：\n\norigins\nmethods\nallowedHeaders\nexposedHeaders\nallowCredentials\nmaxAge.\n\nIn this example, we allow only http://localhost:9000 to send cross-origin requests.\n在这里例子中，我们只允许 http://localhost:9000 发送跨域请求。\n\nYou can also add the @CrossOrigin annotation at the controller class level as well, to enable CORS on all handler methods of this class.\n\n你同样可以将 @CrossOrigin 注解应用在类级别，以便让其中所有方法开启 CORS\nGlobal CORS configuration全局 CORS 配置\nIn addition (or as an alternative) to fine-grained annotation-based configuration, you can define some global CORS configuration as well. This is similar to using a Filter but can be declared within Spring MVC and combined with fine-grained @CrossOrigin configuration. By default, all origins and GET, HEAD, and POST methods are allowed.\n此外(或作为基于细粒度注释的配置的替代方法)，还可以定义一些全局 CORS 配置。这类似于使用过滤器，但可以在 Spring MVC 中声明，并与细粒度的 @CrossOrigin 配置相结合。默认情况下，允许使用所有域、GET、HEAD 和 POST 方法。\nThe following listing (from src/main/java/com/example/restservicecors/GreetingController.java) shows the greetingWithJavaconfig method in the GreetingController class:\n如下所示（源码参考 src/main/java/com/example/restservicecors/GreetingController.java)）：\n@GetMapping(&quot;/greeting-javaconfig&quot;)public Greeting greetingWithJavaconfig(@RequestParam(required=false, defaultValue=&quot;World&quot;) String name) &#123;\tSystem.out.println(&quot;==== in greeting ====&quot;);\treturn new Greeting(counter.incrementAndGet(), String.format(template, name));&#125;\n\n\nThe difference between the greetingWithJavaconfig method and the greeting method (used in the controller-level CORS configuration) is the route (&#x2F;greeting-javaconfig rather than &#x2F;greeting) and the presence of the @CrossOrigin origin.\n\ngreetingWithJavaconfig 方法和 greeting 方法（在控制器级 CORS 配置中使用）之间的区别是路由(&#x2F;greeting-javaconfig 而不是 &#x2F;greeting)和 @CrossOrigin 来源的存在。\nThe following listing (from src&#x2F;main&#x2F;java&#x2F;com&#x2F;example&#x2F;restservicecors&#x2F;RestServiceCorsApplication.java) shows how to add CORS mapping in the application class:\n下面的清单(源码路径 src/main/java/com/example/restservicecors/RestServiceCorsApplication.java）展示了如何在应用程序类中添加 CORS 映射：\npublic WebMvcConfigurer corsConfigurer() &#123;\treturn new WebMvcConfigurer() &#123;\t\t@Override\t\tpublic void addCorsMappings(CorsRegistry registry) &#123;\t\t\tregistry.addMapping(&quot;/greeting-javaconfig&quot;).allowedOrigins(&quot;http://localhost:9000&quot;);\t\t&#125;\t&#125;;&#125;\n\nYou can easily change any properties (such as allowedOrigins in the example), as well as apply this CORS configuration to a specific path pattern.\n你可以轻松地更改任何属性（例如本例中的 allowedOrigins），也可以将这种 CORS 配置应用于特定的路径模式。\n\nYou can combine global- and controller-level CORS configuration.\n\n你可以结合全局和控制器两种级别的 CORS 配置\nCreating the Application Class生成 Application 类\nThe Spring Initializr creates a bare-bones application class for you. The following listing (from initial&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;example&#x2F;restservicecors&#x2F;RestServiceCorsApplication.java) shows that initial class:\nSpring Initializr 创建了一个基本的应用程序类。下面的清单（来自 initial/src/main/java/com/example/restservicecors/RestServiceCorsApplication.java）显示了这个类：\npackage com.example.restservicecors;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class RestServiceCorsApplication &#123;\tpublic static void main(String[] args) &#123;\t\tSpringApplication.run(RestServiceCorsApplication.class, args);\t&#125;&#125;\n\nYou need to add a method to configure how to handle cross-origin resource sharing. The following listing (from complete&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;example&#x2F;restservicecors&#x2F;RestServiceCorsApplication.java) shows how to do so:\n你需要添加一个方法来配置如何处理跨源资源共享。下面的清单（来自 complete/src/main/java/com/example/restservicecors/RestServiceCorsApplication.java）展示了如何做到这一点：\n@Beanpublic WebMvcConfigurer corsConfigurer() &#123;\treturn new WebMvcConfigurer() &#123;\t\t@Override\t\tpublic void addCorsMappings(CorsRegistry registry) &#123;\t\t\tregistry.addMapping(&quot;/greeting-javaconfig&quot;).allowedOrigins(&quot;http://localhost:9000&quot;);\t\t&#125;\t&#125;;&#125;\n\nThe following listing shows the completed application class:\n完整的应用类如下所示：\npackage com.example.restservicecors;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.servlet.config.annotation.CorsRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;@SpringBootApplicationpublic class RestServiceCorsApplication &#123;\tpublic static void main(String[] args) &#123;\t\tSpringApplication.run(RestServiceCorsApplication.class, args);\t&#125;\t@Bean\tpublic WebMvcConfigurer corsConfigurer() &#123;\t\treturn new WebMvcConfigurer() &#123;\t\t\t@Override\t\t\tpublic void addCorsMappings(CorsRegistry registry) &#123;\t\t\t\tregistry.addMapping(&quot;/greeting-javaconfig&quot;).allowedOrigins(&quot;http://localhost:9000&quot;);\t\t\t&#125;\t\t&#125;;\t&#125;&#125;\n\n@SpringBootApplication is a convenience annotation that adds all of the following:\n@SpringBootApplication 是一个方便的注解，它添加了以下所有内容：\n\n@Configuration: Tags the class as a source of bean definitions for the application context.\n\n将该类标记为应用程序上下文的 bean 定义源。\n\n@EnableAutoConfiguration: Tells Spring Boot to start adding beans based on classpath settings, other beans, and various property settings. For example, if spring-webmvc is on the classpath, this annotation flags the application as a web application and activates key behaviors, such as setting up a DispatcherServlet.\n\n告诉 Spring Boot 根据类路径设置、其他 bean 和各种属性设置开始添加 bean。例如，如果 spring-webmvc 位于 classpath，则该注解将应用程序标记为 web 应用程序并激活关键行为，例如设置 DispatcherServlet。\n\n@ComponentScan: Tells Spring to look for other components, configurations, and services in the com&#x2F;example package, letting it find the controllers.\n\n告诉 Spring 在 com&#x2F;example 包中查找其他组件、配置和服务，让它查找控制器。\nThe main() method uses Spring Boot’s SpringApplication.run() method to launch an application. Did you notice that there was not a single line of XML? There is no web.xml file, either. This web application is 100% pure Java and you did not have to deal with configuring any plumbing or infrastructure.\nmain() 方法使用 Spring Boot 的 SpringApplication.run() 方法来启动应用程序。你注意到没有一行 XML 吗？也没有 web.xml 文件。这个 web 应用程序是 100% 纯 Java 的，不需要配置任何管道或基础设施。\n译注：以下部分过于简单，且不涉及 CORS，不译。\nBuild an executable JARYou can run the application from the command line with Gradle or Maven. You can also build a single executable JAR file that contains all the necessary dependencies, classes, and resources and run that. Building an executable jar so makes it easy to ship, version, and deploy the service as an application throughout the development lifecycle, across different environments, and so forth.\nIf you use Gradle, you can run the application by using .&#x2F;gradlew bootRun. Alternatively, you can build the JAR file by using .&#x2F;gradlew build and then run the JAR file, as follows:\njava -jar build/libs/gs-rest-service-cors-0.1.0.jar\n\nIf you use Maven, you can run the application by using .&#x2F;mvnw spring-boot:run. Alternatively, you can build the JAR file with .&#x2F;mvnw clean package and then run the JAR file, as follows:\njava -jar target/gs-rest-service-cors-0.1.0.jar\n\n\nThe steps described here create a runnable JAR. You can also build a classic WAR file.\n\nLogging output is displayed. The service should be up and running within a few seconds.\nTest the serviceNow that the service is up, visit http://localhost:8080/greeting, where you should see:\n&#123;&quot;id&quot;:1,&quot;content&quot;:&quot;Hello, World!&quot;&#125;\n\nProvide a name query string parameter by visiting http://localhost:8080/greeting?name=User. The value of the content attribute changes from Hello, World! to Hello User!, as the following listing shows:\n&#123;&quot;id&quot;:2,&quot;content&quot;:&quot;Hello, User!&quot;&#125;\n\nThis change demonstrates that the @RequestParam arrangement in GreetingController works as expected. The name parameter has been given a default value of World but can always be explicitly overridden through the query string.\nAlso, the id attribute has changed from 1 to 2. This proves that you are working against the same GreetingController instance across multiple requests and that its counter field is being incremented on each call, as expected.\nNow you can test that the CORS headers are in place and allow a Javascript client from another origin to access the service. To do so, you need to create a Javascript client to consume the service. The following listing shows such a client:\nFirst, create a simple Javascript file named hello.js (from complete&#x2F;public&#x2F;hello.js) with the following content:\n$(document).ready(function () &#123;  $.ajax(&#123;    url: &quot;http://localhost:8080/greeting&quot;,  &#125;).then(function (data, status, jqxhr) &#123;    $(&quot;.greeting-id&quot;).append(data.id);    $(&quot;.greeting-content&quot;).append(data.content);    console.log(jqxhr);  &#125;);&#125;);\n\nThis script uses jQuery to consume the REST service at http://localhost:8080/greeting. It is loaded by index.html, as the following listing (from complete&#x2F;public&#x2F;index.html) shows:\n&lt;!DOCTYPE html&gt;&lt;html&gt;    &lt;head&gt;        &lt;title&gt;Hello CORS&lt;/title&gt;        &lt;script src=&quot;https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js&quot;&gt;&lt;/script&gt;        &lt;script src=&quot;hello.js&quot;&gt;&lt;/script&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div&gt;            &lt;p class=&quot;greeting-id&quot;&gt;The ID is &lt;/p&gt;            &lt;p class=&quot;greeting-content&quot;&gt;The content is &lt;/p&gt;        &lt;/div&gt;    &lt;/body&gt;&lt;/html&gt;\n\n\nThis is essentially the REST client created in Consuming a RESTful Web Service with jQuery, modified slightly to consume the service when it runs on localhost at port 8080. See that guide for more details on how this client was developed.\n\nBecause the REST service is already running on localhost at port 8080, you need to be sure to start the client from another server or port. Doing so not only avoids a collision between the two applications but also ensures that the client code is served from a different origin than the service. To start the client running on localhost at port 9000, run the following Maven command:\n./mvnw spring-boot:run -Dserver.port=9000\n\nOnce the client starts, open http://localhost:9000 in your browser, where you should see the following:\n（原文有图，略）\nIf the service response includes the CORS headers, then the ID and content are rendered into the page. But if the CORS headers are missing (or insufficiently defined for the client), the browser fails the request and the values are not rendered into the DOM. In that case, you should see the following:\n（原文有图，略）\nSummaryCongratulations! You have just developed a RESTful web service that includes Cross-Origin Resource Sharing with Spring.\nSee AlsoThe following guides may also be helpful:\n\nBuilding a RESTful Web Service\n\nBuilding a Hypermedia-Driven RESTful Web Service\n\nCreating API Documentation with Restdocs\n\nAccessing GemFire Data with REST\n\nAccessing MongoDB Data with REST\n\nAccessing data with MySQL\n\nAccessing JPA Data with REST\n\nAccessing Neo4j Data with REST\n\nConsuming a RESTful Web Service\n\nConsuming a RESTful Web Service with AngularJS\n\nConsuming a RESTful Web Service with jQuery\n\nConsuming a RESTful Web Service with rest.js\n\nSecuring a Web Application\n\nBuilding REST services with Spring\n\nReact.js and Spring Data REST\n\nBuilding an Application with Spring Boot\n\n\nWant to write a new guide or contribute to an existing one? Check out our contribution guidelines.\n\nAll guides are released with an ASLv2 license for the code, and an Attribution, NoDerivatives creative commons license for the writing.\n\n","categories":["文献翻译","java"],"tags":["未标记"]},{"title":"Guide to ApplicationContextRunner in Spring Boot","url":"/3c6a9ce0-e213-11ee-8578-cb8bdeddad57/","content":"\n\n\n\n\n转译自：https://www.baeldung.com/spring-boot-context-runner\n\n1 OverviewIt’s well known that auto-configuration is one of the key features in Spring Boot, but testing auto-configuration scenarios can be tricky.\nIn the following sections, we’ll show how ApplicationContextRunner simplifies auto-configuration testing.\n2 Test Auto-Configuration ScenariosApplicationContextRunner is a utility class which runs the ApplicationContext and provides AssertJ style assertions. It’s best used as a field in test class for shared configuration and we make customizations in each test afterward:\nprivate final ApplicationContextRunner contextRunner    = new ApplicationContextRunner();\n\nLet’s move on to show its magic by testing a few cases.\n2.1 Test Class ConditionIn this section, we’re going to test some auto-configuration classes which use @ConditionalOnClass and @ConditionalOnMissingClass annotations:\n@Configuration@ConditionalOnClass(ConditionalOnClassIntegrationTest.class)protected static class ConditionalOnClassConfiguration &#123;    @Bean    public String created() &#123;        return &quot;This is created when ConditionalOnClassIntegrationTest &quot;               + &quot;is present on the classpath&quot;;    &#125;&#125;@Configuration@ConditionalOnMissingClass(    &quot;com.baeldung.autoconfiguration.ConditionalOnClassIntegrationTest&quot;)protected static class ConditionalOnMissingClassConfiguration &#123;    @Bean    public String missed() &#123;        return &quot;This is missed when ConditionalOnClassIntegrationTest &quot;               + &quot;is present on the classpath&quot;;    &#125;&#125;\n\nWe’d like to test whether the auto-configuration properly instantiates or skips the created and missed beans given expected conditions.\nApplicationContextRunner gives us the withUserConfiguration method where we can provide an auto-configuration on demand to customize the ApplicationContext for each test.\nThe run method takes a ContextConsumer as a parameter which applies the assertions to the context. The ApplicationContext will be closed automatically when the test exits:\n@Testpublic void whenDependentClassIsPresent_thenBeanCreated() &#123;    this.contextRunner.withUserConfiguration(ConditionalOnClassConfiguration.class)        .run(context -&gt; &#123;            assertThat(context).hasBean(&quot;created&quot;);            assertThat(context.getBean(&quot;created&quot;))              .isEqualTo(&quot;This is created when ConditionalOnClassIntegrationTest &quot;                         + &quot;is present on the classpath&quot;);        &#125;);&#125;@Testpublic void whenDependentClassIsPresent_thenBeanMissing() &#123;    this.contextRunner.withUserConfiguration(ConditionalOnMissingClassConfiguration.class)        .run(context -&gt; &#123;            assertThat(context).doesNotHaveBean(&quot;missed&quot;);        &#125;);&#125;\n\nThrough the preceding example, we see the simpleness of testing the scenarios in which a certain class is present on the classpath. But how are we going to test the converse, when the class is absent on the classpath?\nThis is where FilteredClassLoader kicks in. It’s used to filter specified classes on the classpath at runtime:\n@Testpublic void whenDependentClassIsNotPresent_thenBeanMissing() &#123;    this.contextRunner.withUserConfiguration(ConditionalOnClassConfiguration.class)        .withClassLoader(new FilteredClassLoader(ConditionalOnClassIntegrationTest.class))        .run((context) -&gt; &#123;            assertThat(context).doesNotHaveBean(&quot;created&quot;);            assertThat(context).doesNotHaveBean(ConditionalOnClassIntegrationTest.class);        &#125;);&#125;@Testpublic void whenDependentClassIsNotPresent_thenBeanCreated() &#123;    this.contextRunner.withUserConfiguration(ConditionalOnMissingClassConfiguration.class)        .withClassLoader(new FilteredClassLoader(ConditionalOnClassIntegrationTest.class))        .run((context) -&gt; &#123;            assertThat(context).hasBean(&quot;missed&quot;);            assertThat(context).getBean(&quot;missed&quot;)              .isEqualTo(&quot;This is missed when ConditionalOnClassIntegrationTest &quot;                         + &quot;is present on the classpath&quot;);            assertThat(context).doesNotHaveBean(ConditionalOnClassIntegrationTest.class);        &#125;);&#125;\n\n2.2 Test Bean ConditionWe’ve just looked at testing @ConditionalOnClass and @ConditionalOnMissingClass annotations, now let’s see what things look like when we are using @ConditionalOnBean and @ConditionalOnMissingBean annotations.\nTo make a start, we similarly need a few auto-configuration classes:\n@Configurationprotected static class BasicConfiguration &#123;    @Bean    public String created() &#123;        return &quot;This is always created&quot;;    &#125;&#125;@Configuration@ConditionalOnBean(name = &quot;created&quot;)protected static class ConditionalOnBeanConfiguration &#123;    @Bean    public String createOnBean() &#123;        return &quot;This is created when bean (name=created) is present&quot;;    &#125;&#125;@Configuration@ConditionalOnMissingBean(name = &quot;created&quot;)protected static class ConditionalOnMissingBeanConfiguration &#123;    @Bean    public String createOnMissingBean() &#123;        return &quot;This is created when bean (name=created) is missing&quot;;    &#125;&#125;\n\nThen, we’d call the withUserConfiguration method like the preceding section and send in our custom configuration class to test if the auto-configuration appropriately instantiates or skips createOnBean or createOnMissingBean beans in different conditions:\n@Testpublic void whenDependentBeanIsPresent_thenConditionalBeanCreated() &#123;    this.contextRunner.withUserConfiguration(        BasicConfiguration.class,        ConditionalOnBeanConfiguration.class    )    // ommitted for brevity&#125;@Testpublic void whenDependentBeanIsNotPresent_thenConditionalMissingBeanCreated() &#123;    this.contextRunner.withUserConfiguration(ConditionalOnMissingBeanConfiguration.class)    // ommitted for brevity&#125;\n\n2.3 Test Property ConditionIn this section, let’s test the auto-configuration classes which use @ConditionalOnProperty annotations.\nFirst, we need a property for this test:\ncom.baeldung.service=custom\n\nAfter that, we write nested auto-configuration classes to create beans based on the preceding property:\n@Configuration@TestPropertySource(&quot;classpath:ConditionalOnPropertyTest.properties&quot;)protected static class SimpleServiceConfiguration &#123;    @Bean    @ConditionalOnProperty(name = &quot;com.baeldung.service&quot;, havingValue = &quot;default&quot;)    @ConditionalOnMissingBean    public DefaultService defaultService() &#123;        return new DefaultService();    &#125;    @Bean    @ConditionalOnProperty(name = &quot;com.baeldung.service&quot;, havingValue = &quot;custom&quot;)    @ConditionalOnMissingBean    public CustomService customService() &#123;        return new CustomService();    &#125;&#125;\n\nNow, we’re calling the withPropertyValues method to override the property value in each test:\n@Testpublic void whenGivenCustomPropertyValue_thenCustomServiceCreated() &#123;    this.contextRunner.withPropertyValues(&quot;com.baeldung.service=custom&quot;)        .withUserConfiguration(SimpleServiceConfiguration.class)        .run(context -&gt; &#123;            assertThat(context).hasBean(&quot;customService&quot;);            SimpleService simpleService = context.getBean(CustomService.class);            assertThat(simpleService.serve()).isEqualTo(&quot;Custom Service&quot;);            assertThat(context).doesNotHaveBean(&quot;defaultService&quot;);        &#125;);&#125;@Testpublic void whenGivenDefaultPropertyValue_thenDefaultServiceCreated() &#123;    this.contextRunner.withPropertyValues(&quot;com.baeldung.service=default&quot;)        .withUserConfiguration(SimpleServiceConfiguration.class)        .run(context -&gt; &#123;            assertThat(context).hasBean(&quot;defaultService&quot;);            SimpleService simpleService = context.getBean(DefaultService.class);            assertThat(simpleService.serve()).isEqualTo(&quot;Default Service&quot;);            assertThat(context).doesNotHaveBean(&quot;customService&quot;);        &#125;);&#125;\n\n3 ConclusionTo sum up, this tutorial just showed how to use ApplicationContextRunner to run the ApplicationContext with customizations and apply assertions.\nWe covered the most frequently used scenarios in here instead of an exhaustive list of how to customize the ApplicationContext.\nIn the meantime, please bear in mind that the ApplicationConetxtRunner is for non-web applications, so consider WebApplicationContextRunner for servlet-based web applications and ReactiveWebApplicationContextRunner for reactive web applications.\nThe source code for this tutorial can be found over on GitHub.\n","categories":["文献翻译","java"],"tags":["springboot"]},{"title":"How-to-design-Classes-and-Interfaces","url":"/4686ddb1-2bb6-11ee-879b-0b2c36f14b2e/","content":"\n\n\n\nHow to design Classes and Interfaces（如何设计类和接口）\n转译自：https://examples.javacodegeeks.com\n\n1、Introduction介绍\nWhatever programming language you are using (and Java is not an exception here), following good design principles is a key factor to write clean, understandable, testable code and deliver（交付） long-living, easy to maintain solutions. In this part of the tutorial we are going to discuss the foundational building blocks which the Java language provides and introduce a couple of design principles, aiming to help you to make better design decisions.\n无论你使用什么编程语言（Java 也不例外），遵循良好设计原则是编写干净的、可理解的、可测试的并且交付后能长期使用的代码，以及易于维护的解决方案的关键因素。\nMore precisely, we are going to discuss interfaces and interfaces with default methods (new feature of Java 8), abstract and final classes, immutable classes, inheritance, composition and revisit a bit the visibility (or accessibility) rules we have briefly touched in part 1 of the tutorial, How to create and destroy objects.\n更准确的说，我们准备讨论接口和带有默认方法的接口（Java 8 的新特性），抽象类和终态类，不可变类、继承、组合，并且重新讨论一下本教程第 1 部分中简要介绍的可见性（或可访问性）规则，即如何创建和销毁对象。\n2、Interfaces接口\nIn object-oriented programming, the concept（概念） of interfaces forms the basics of contract-driven (or contract-based) development. In a nutshell（简而言之）, interfaces define the set of methods (contract) and every class which claims to support this particular interface must provide the implementation of those methods: a pretty simple, but powerful idea.\n在面向对象编程中，接口的概念形成了契约驱动（或基于契约的）开发的基础。简而言之，接口定义了一组方法（契约），并且每个声称支持该特定接口的类都必须提供这些方法的实现：这是一个非常简单但功能强大的想法。\nMany programming languages do have interfaces in one form or another, but Java particularly provides language support for that. Let take a look on a simple interface definition in Java.\n许多编程语言都有这样或那样的接口，但是 Java 特别提供了语言支持。让我们看一下 Java 中一个简单接口的定义。\npackage com.javacodegeeks.advanced.design;public interface SimpleInterface &#123;    void performAction();&#125;\n\nIn the code snippet（片段） above, the interface which we named SimpleInterface declares just one method with name performAction. The principal（主要的） differences of interfaces in respect to（关于） classes is that interfaces outline what the contact is (declare methods), but do not provide their implementations.\n在上面的代码片段中，我们命名为 SimpleInterface 的接口仅仅声明了一个名为 performAction 的方法。接口与类的主要区别在于接口概括了两者的联系是什么（声明方法），但没有提供它们的实现。\nHowever, interfaces in Java can be more complicated（复杂的） than that: they can include nested interfaces, classes, enumerations, annotations (enumerations and annotations will be covered in details in part 5 of the tutorial, How and when to use Enums and Annotations) and constants. For example:\n然而，Java 中的接口可能比这更复杂：它们可以包括嵌套的接口、类、枚举、注解（枚举和注解将在本教程的第 5 部分中详细介绍，如何以及何时使用枚举和注解）和常量。例如：\npackage com.javacodegeeks.advanced.design;public interface InterfaceWithDefinitions &#123;    String CONSTANT = &quot;CONSTANT&quot;;    enum InnerEnum &#123;        E1, E2;    &#125;    class InnerClass &#123;    &#125;    interface InnerInterface &#123;        void performInnerAction();    &#125;    void performAction();&#125;\n\nWith this more complicated example, there are a couple of constraints which interfaces implicitly impose with respect to the nested constructs and method declarations, and Java compiler enforces（强制执行） that. First and foremost, even if it is not being said explicitly, every declaration in the interface is public (and can be only public, for more details about visibility and accessibility rules, please refer to section Visibility). As such, the following method declarations are equivalent:\n对于这个更复杂的示例，有两个约束，接口隐式地对嵌套构造和方法声明施加约束，Java 编译器强制执行这些约束。首先，也是最重要的，即使没有明确说明，接口中的每个声明都是 public 的（并且只能是 public 的，关于可见性和可访问性规则的更多细节，请参阅可见性部分）。因此，以下方法声明是等价的：\npublic void performAction();void performAction();\n\nWorth to mention that every single method in the interface is implicitly declared as abstract and even these method declarations are equivalent:\n值得一提的是，接口中的每个方法都被隐式地声明为抽象的，甚至这些方法声明也是等价的：\npublic abstract void performAction();public void performAction();void performAction();\n\nAs for the constant field declarations, additionally to being public, they are implicitly static and final so the following declarations are also equivalent:\n对于常量字段声明，除了标记为 public 外，它们是隐式的静态的和最终态的，所以下面的声明也是等价的：\nString CONSTANT = &quot;CONSTANT&quot;;public static final String CONSTANT = &quot;CONSTANT&quot;;\n\nAnd finally, the nested classes, interfaces or enumerations, additionally to being public, are implicitly declared as static. For example, those class declarations are equivalent as well:\n最后，嵌套的类、接口或枚举，除了标记为 public 之外，还被隐式地声明为静态的。例如，这些类声明也是等价的：\nclass InnerClass &#123;&#125;static class InnerClass &#123;&#125;\n\nWhich style you are going to choose is a personal preference, however knowledge of those simple qualities of interfaces could save you from unnecessary typing.\n选择哪种风格是个人的喜好，但是了解这些简单的接口特性可以避免不必要的输入。\n3、Marker Interfaces标记接口\nMarker interfaces are a special kind of interfaces which have no methods or other nested constructs defined. We have already seen one example of the marker interface in part 2 of the tutorial Using methods common to all objects, the interface Cloneable. Here is how it is defined in the Java library:\n标记接口是一种特殊的接口，它没有定义任何方法或其他嵌套构造。在本教程的第 2 部分中，我们已经看到了一个标记接口的示例，它使用了所有对象都通用的方法，即接口 Cloneable。下面是它在 Java 库中的定义：\npublic interface Cloneable &#123;&#125;\n\nMarker interfaces are not contracts per se but somewhat useful technique to “attach” or “tie” some particular trait to the class. For example, with respect to Cloneable, the class is marked as being available for cloning however the way it should or could be done is not a part of the interface. Another very well-known and widely used example of marker interface is Serializable:\n标记接口本身不是契约，而是某种有用的技术，可以“附加”或“绑定”类的某些特定特性。例如，对于 Cloneable，类被标记为可用于克隆，但是它应该或可能的方式不是接口的一部分。另一个非常著名和广泛使用的标记接口示例是 Serializable:\npublic interface Serializable &#123;&#125;\n\nThis interface marks the class as being available for serialization and deserialization, and again, it does not specify the way it could or should be done.\n该接口将类标记为可用于序列化和反序列化，并且它没有指定它可以或应该执行的方式。\nThe marker interfaces have their place in object-oriented design, although they do not satisfy the main purpose of interface to be a contract.\n标记接口在面向对象设计中有自己的位置，尽管它们不满足接口作为契约的主要目的。\n4、Functional interfaces, default and static methods功能接口，默认和静态方法\nWith the release of Java 8, interfaces have obtained new very interesting capabilities: static methods, default methods and automatic conversion from lambdas (functional interfaces).\n随着 Java 8 的发布，接口获得了非常有趣的新功能:静态方法、默认方法和 lambdas（函数接口）的自动转换。\nIn section Interfaces we have emphasized（强调） on the fact that interfaces in Java can only declare methods but are not allowed to provide their implementations. With default methods it is not true anymore: an interface can mark a method with the default keyword and provide the implementation for it. For example:\n在部分接口中，我们强调了一个事实，即 Java 中的接口只能声明方法，但不能提供它们的实现。对于默认方法就不再适用：接口可以用 default 关键字标记方法并为其提供实现。例如：\npackage com.javacodegeeks.advanced.design;public interface InterfaceWithDefaultMethods &#123;    void performAction();    default void performDefaulAction() &#123;        // Implementation here    &#125;&#125;\n\nBeing an instance（实例） level, defaults methods could be overridden by each interface implementer, but from now, interfaces may also include static methods, for example:\n作为一个实例，默认方法可以被每个接口实现者覆盖，但是从现在开始，接口也可以包括静态方法，例如:\npackage com.javacodegeeks.advanced.design;public interface InterfaceWithDefaultMethods &#123;    static void createAction() &#123;        // Implementation here    &#125;&#125;\n\nOne may say that providing an implementation in the interface defeats the whole purpose of contract-based development, but there are many reasons why these features were introduced into the Java language and no matter how useful or confusing they are, they are there for you to use.\n有人可能会说，在接口中提供一个实现违背了基于契约开发的全部目的，但是这些特性被引入 Java 语言有很多原因，而且无论它们多么有用或令人困惑，它们都是可供使用的工具。\nThe functional interfaces are a different story and they are proven to be very helpful add-on to the language. Basically, the functional interface is the interface with just a single abstract method declared in it. The Runnable interface from Java standard library is a good example of this concept:\n函数式接口是一个不同的故事，它们被证明是对语言非常有用的附加组件。基本上，函数式接口就是在接口中仅声明一个抽象方法。Java 标准库中的 Runnable 接口就是这个概念很好的例子：\n@FunctionalInterfacepublic interface Runnable &#123;    void run();&#125;\n\nThe Java compiler treats functional interfaces differently and is able to convert the lambda function into the functional interface implementation where it makes sense. Let us take a look on following function definition:\nJava 编译器以不同的方式对待函数式接口，并能够将 lambda 函数转换为有意义的函数式接口实现。让我们来看看下面的函数定义：\npublic void runMe( final Runnable r ) &#123;    r.run();&#125;\n\nTo invoke this function in Java 7 and below, the implementation of the Runnable interface should be provided (for example using Anonymous classes), but in Java 8 it is enough to pass run() method implementation using lambda syntax:\n要在 Java 7 和以下版本中调用此方法，应该提供 Runnable 接口的实现（如使用匿名类），但在 Java 8 中，使用 lambda 语法传递 run()方法就足够了:\nrunMe( () -&gt; System.out.println( &quot;Run!&quot; ) );\n\nAdditionally, the @FunctionalInterface annotation (annotations will be covered in details in part 5 of the tutorial, How and when to use Enums and Annotations) hints（暗示，提示） the compiler to verify that the interface contains only one abstract method so any changes introduced to the interface in the future will not break this assumption（假设）.\n此外，@FunctionalInterface 注解（注解将在本教程的第 5 部分中详细介绍，如何以及何时使用枚举和注解）提示编译器验证该接口只包含一个抽象方法，将来接口引入的任何更改都不能打破这个假设。\n5、Abstract classes抽象类\nAnother interesting concept（概念） supported by Java language is the notion（概念） of abstract classes. Abstract classes are somewhat（有些，稍微） similar to the interfaces in Java 7 and very close to interfaces with default methods in Java 8. By contrast to regular（常规的） classes, abstract classes cannot be instantiated but could be subclassed (please refer to the section Inheritance for more details). More importantly, abstract classes may contain abstract methods: the special kind of methods without implementations, much like interfaces do. For example:\nJava 语言支持的另一个有趣的概念是抽象类的概念。抽象类有点类似于 Java 7 中的接口，与 Java 8 中具有默认方法的接口非常接近。与常规类不同的是，抽象类不能被实例化，但可以被子类化（有关更多细节，请参阅继承部分）。更重要的是，抽象类可能包含抽象方法：没有实现的特殊类型的方法，就像接口一样。例如：\npackage com.javacodegeeks.advanced.design;public abstract class SimpleAbstractClass &#123;    public void performAction() &#123;        // Implementation here    &#125;    public abstract void performAnotherAction();&#125;\n\nIn this example, the class SimpleAbstractClass is declared as abstract and has one abstract method declaration as well. Abstract classes are very useful when most or even some part of implementation details could be shared by many subclasses. However, they still leave the door open and allow customizing（定制） the intrinsic（内在） behavior of each subclass by means of abstract methods.\n在本例中，SimpleAbstractClass 类被声明为抽象类，并且有一个抽象方法声明。抽象类非常有用，因为少部分、甚至大部分实现细节都可以由多个子类共享。然而，它们仍然开放，允许通过抽象方法定制每个子类的内在行为。\nOne thing to mention, in contrast（对比） to interfaces which can contain only public declarations, abstract classes may use the full power of accessibility rules to control abstract methods visibility (please refer to the sections Visibility and Inheritance for more details).\n值得一提的是，与只能包含 public 声明的接口不同，抽象类可以使用可访问性规则的全部功能来控制抽象方法的可见性（有关详细信息，请参阅可见性和继承部分）。\n6、Immutable classes不可变类\nImmutability is becoming more and more important in the software development nowadays. The rise of multi-core systems has raised a lot of concerns related to data sharing and concurrency (in the part 9, Concurrency（并发性） best practices, we are going to discuss in details those topics). But the one thing definitely emerged: less (or even absence of) mutable state leads to better scalability（可伸缩性） and simpler reasoning（推理） about the systems.\n不可变性在当今软件开发中变得越来越重要。多核系统的兴起引起了许多与数据共享和并发相关的关注（在第 9 部分，并发的最佳实践中，我们将详细讨论这些主题）。但有一件事是肯定的：较少（甚至没有）的可变状态会带来更好的可伸缩性和更简单的系统演绎。\nUnfortunately, the Java language does not provide strong support for class immutability. However using a combination（结合） of techniques it is possible to design classes which are immutable. First and foremost, all fields of the class should be final. It is a good start but does not guarantee immutability alone.\n不幸的是，Java 语言没有提供对类不变性的强大支持。然而，结合一系列技术就可以设计出不可变类。首先，类的所有字段都应该是 final。这是一个良好的开端，但并不能保证一成不变。\npackage com.javacodegeeks.advanced.design;import java.util.Collection;public class ImmutableClass &#123;    private final long id;    private final String[] arrayOfStrings;    private final Collection&lt; String &gt; collectionOfString;&#125;\n\nSecondly, follow the proper initialization: if the field is the reference to a collection or an array, do not assign those fields directly from constructor arguments, make the copies instead. It will guarantee that state of the collection or array will not be changed from outside.\n其次，遵循适当的初始化原则：如果字段是对集合或数组的引用，不要直接从构造函数参数中对这些字段赋值，而是生成副本。它将确保集合或数组的状态不会被外部更改。\npublic ImmutableClass( final long id, final String[] arrayOfStrings,        final Collection&lt; String &gt; collectionOfString) &#123;    this.id = id;    this.arrayOfStrings = Arrays.copyOf( arrayOfStrings, arrayOfStrings.length );    this.collectionOfString = new ArrayList&lt;&gt;( collectionOfString );&#125;\n\nAnd lastly, provide the proper accessors (getters). For the collection, the immutable view should be exposed（暴露） using Collections.unmodifiableXxx wrappers.\n最后，提供适当的访问器（getter）。对于集合，不可变视图应该使用 Collections.unmodifiableXxx 之类的包装器公开。\npublic Collection&lt;String&gt; getCollectionOfString() &#123;    return Collections.unmodifiableCollection( collectionOfString );&#125;\n\nWith arrays, the only way to ensure true immutability is to provide a copy instead of returning reference to the array. That might not be acceptable from a practical standpoint as it hugely depends on array size and may put a lot of pressure on garbage collector.\n对于数组，确保真正的不变性的唯一方法是提供一个副本，而不是返回对数组的引用。从实践的角度来看，这可能是不可接受的，因为它很大程度上依赖于数组大小，可能会给垃圾收集器带来很大压力。\npublic String[] getArrayOfStrings() &#123;    return Arrays.copyOf( arrayOfStrings, arrayOfStrings.length );&#125;\n\nEven this small example gives a good idea that immutability is not a first class citizen in Java yet. Things can get really complicated if an immutable class has fields referencing another class instances. Those classes should also be immutable however there is no simple way to enforce that.\n即使是这个小示例也给出了一个好主意：在 Java 中，不可变性还不是一等的公民。如果一个不可变的类有引用另一个类实例的字段，那么事情就会变得非常复杂。这些类也应该是不可变的，但是没有简单的方法来实现它。\nThere are a couple of great Java source code analyzers like FindBugs) and PMD) which may help a lot by inspecting your code and pointing to the common Java programming flaws. Those tools are great friends of any Java developer.\n有一些很棒的 Java 源代码分析程序，比如 FindBugs 和 PMD，它们可以通过检查代码并指出常见的 Java 编程缺陷来帮助你。这些工具是任何 Java 开发人员的好朋友。\n7、Anonymous classes匿名类\nIn the pre-Java 8 era, anonymous classes were the only way to provide in-place class definitions and immediate instantiations. The purpose of the anonymous classes was to reduce boilerplate（样板） and provide a concise and easy way to represent classes as expressions. Let us take a look on the typical old-fashioned way to spawn（大量生产） new thread in Java:\njava 8 之前的时代，匿名类是提供 in-place class 定义和立即实例化的唯一方法。匿名类的目的是减少样板文件，并提供一种简洁而简单的方法来将类表示为表达式。让我们看看在 Java 中产生新线程的典型旧式方法：\npackage com.javacodegeeks.advanced.design;public class AnonymousClass &#123;    public static void main( String[] args ) &#123;        new Thread(            // Example of creating anonymous class which implements            // Runnable interface            new Runnable() &#123;                @Override                public void run() &#123;                    // Implementation here                &#125;            &#125;        ).start();    &#125;&#125;\n\nIn this example, the implementation of the Runnable interface is provided in place as anonymous class. Although there are some limitations associated（相关的） with anonymous classes, the fundamental（基本的） disadvantages（缺点） of their usage are a quite verbose（详细的） syntax constructs which Java imposes（强加） as a language. Even the simplest anonymous class which does nothing requires at least 5 lines of code to be written every time.\n在本例中，以匿名类的形式提供了 Runnable 接口的实现。虽然匿名类有一些限制，但是它们的使用的基本缺点是 Java 作为一种语言强加了相当详细的语法结构。即使最简单的匿名类什么也不做，每次至少需要编写 5 行代码。\nnew Runnable() &#123;   @Override   public void run() &#123;   &#125;&#125;\n\nLuckily, with Java 8, lambdas and functional interfaces all this boilerplate is about to gone away, finally making the Java code to look truly concise.\n幸运的是，因为有了 Java 8 的 lambdas 表达式和函数式接口，所有这些样板文件都将消失，最终使 Java 代码看起来非常简洁。\npackage com.javacodegeeks.advanced.design;public class AnonymousClass &#123;    public static void main( String[] args ) &#123;        new Thread( () -&gt; &#123; /* Implementation here */ &#125; ).start();    &#125;&#125;\n\n8、Visibility可见性\nWe have already talked a bit about Java visibility and accessibility rules in part 1 of the tutorial（教程）, How to design Classes and Interfaces. In this part we are going to get back to this subject again but in the context of subclassing\n我们已经在本教程的第 1 部分讨论了 Java 可见性和可访问性规则，以及如何设计类和接口。在这一部分中，我们将在子类化的背景下再次回到这个主题。\n\n\n\nModifier\nPackage\nSubclass\nEveryone Else\n\n\n\npublic\naccessible\naccessible\naccessible\n\n\nprotected\naccessible\naccessible\nnot accessible\n\n\n&lt;no modifier&gt;\naccessible\nnot accessible\nnot accessible\n\n\nprivate\nnot accessible\nnot accessible\nnot accessible\n\n\nDifferent visibility levels allow or disallow the classes to see other classes or interfaces (for example, if they are in different packages or nested in one another) or subclasses to see and access methods, constructors and fields of their parents.\n不同的可见性级别允许或不允许类查看其他类或接口（例如，如果它们位于不同的包中或嵌套在另一个包中）或子类，以查看和访问父类的方法、构造函数和字段。\nIn next section, Inheritance, we are going to see that in action.\n在下一节“继承”中，我们将看到它的实际应用。\n9、Inheritance继承\nInheritance is one of the key concepts of object-oriented programming, serving as a basis of building class relationships. Combined together with visibility and accessibility rules, inheritance allows designing extensible and maintainable class hierarchies.\n继承是面向对象编程的关键概念之一，是构建类关系的基础。结合可见性和可访问性规则，继承允许设计可扩展和可维护的类层次结构。\nConceptually, inheritance in Java is implemented using subclassing and the extends keyword, followed by the parent class. The subclass inherits all of the public and protected members of its parent class. Additionally, a subclass inherits the package-private members of the parent class if both reside in the same package. Having said that, it is very important no matter what you are trying to design, to keep the minimal set of the methods which class exposes publicly or to its subclasses. For example, let us take a look on a class Parent and its subclass Child to demonstrate different visibility levels and their effect:\n从概念上讲，Java 中的继承是使用子类，即 extends 关键字后加父类实现的。子类继承其父类的所有公共和受保护的成员。此外，如果两个类都驻留在同一个包中，则子类继承父类的包私有成员。尽管如此，无论你试图设计什么，保持类公开或公开其子类的方法的最小集合都是非常重要的。例如，让我们看看一个类父类及其子类，以演示不同的可见性级别及其效果：\npackage com.javacodegeeks.advanced.design;public class Parent &#123;    // Everyone can see it    public static final String CONSTANT = &quot;Constant&quot;;    // No one can access it    private String privateField;    // Only subclasses can access it    protected String protectedField;    // No one can see it    private class PrivateClass &#123;    &#125;    // Only visible to subclasses    protected interface ProtectedInterface &#123;    &#125;    // Everyone can call it    public void publicAction() &#123;    &#125;    // Only subclass can call it    protected void protectedAction() &#123;    &#125;    // No one can call it    private void privateAction() &#123;    &#125;    // Only subclasses in the same package can call it    void packageAction() &#123;    &#125;&#125;\n\npackage com.javacodegeeks.advanced.design;// Resides in the same package as parent classpublic class Child extends Parent implements Parent.ProtectedInterface &#123;    @Override    protected void protectedAction() &#123;        // Calls parent&#x27;s method implementation        super.protectedAction();    &#125;    @Override    void packageAction() &#123;        // Do nothing, no call to parent&#x27;s method implementation    &#125;    public void childAction() &#123;        this.protectedField = &quot;value&quot;;    &#125;&#125;\n\nInheritance is a very large topic by itself, with a lot of subtle details specific to Java. However, there are a couple of easy to follow rules which could help a lot to keep your class hierarchies concise. In Java, every subclass may override any inherited method of its parent unless it was declared as final (please refer to the section Final classes and methods).\n继承本身就是一个非常大的主题，有许多 Java 特有的细节。然而，有一些易于遵循的规则可以帮助你保持类层次结构的简洁。在 Java 中，每个子类都可以重写其父类的任何继承方法，除非它被声明为 final（请参阅 final 类和方法一节）。\nHowever, there is no special syntax or keyword to mark the method as being overridden which may cause a lot of confusion. That is why the @Override annotation has been introduced: whenever your intention is to override the inherited method, please always use the @Override annotation to indicate that.\n但是，没有特殊的语法或关键字将方法标记为被覆盖，这可能会导致很多混乱。这就是为什么引入了 @Override 注解：当你打算重写继承的方法时，请始终使用 @Override 注解来表示。\nAnother dilemma Java developers are often facing in design is building class hierarchies (with concrete or abstract classes) versus interface implementations. It is strongly advised to prefer interfaces to classes or abstract classes whenever possible. Interfaces are much more lightweight, easier to test (using mocks) and maintain, plus they minimize the side effects of implementation changes. Many advanced programming techniques like creating class proxies in standard Java library heavily rely on interfaces.\nJava 开发人员在设计中经常面临的另一个难题是构建类层次结构(使用具体的或抽象的类)和接口实现。强烈建议尽可能选择接口而不是类或抽象类。接口更轻量，更易于测试(使用模拟)和维护，并且它们最小化了实现更改的副作用。许多高级编程技术，如在标准 Java 库中创建类代理，严重依赖于接口。\n10、Multiple inheritance多重继承\nIn contrast to C++ and some other languages, Java does not support multiple inheritance: in Java every class has exactly one direct parent (with Object class being on top of the hierarchy as we have already known from part 2 of the tutorial, Using methods common to all objects). However, the class may implement multiple interfaces and as such, stacking interfaces is the only way to achieve (or mimic) multiple inheritance in Java.\n与 c++和其他一些语言不同的是，Java 不支持多重继承：在 Java 中，每个类都有一个直接的父类（正如我们在本教程的第 2 部分中已经知道的那样，对象类位于层次结构的顶部，使用所有对象共有的方法）。然而，类可能实现多个接口，因此，堆叠接口是在 Java 中实现（或模拟）多重继承的唯一方法。\npackage com.javacodegeeks.advanced.design;public class MultipleInterfaces implements Runnable, AutoCloseable &#123;    @Override    public void run() &#123;        // Some implementation here    &#125;    @Override    public void close() throws Exception &#123;       // Some implementation here    &#125;&#125;\n\nImplementation of multiple interfaces is in fact quite powerful, but often the need to reuse an implementation leads to deep class hierarchies as a way to overcome the absence of multiple inheritance support in Java.\n实际上，多接口的实现非常强大，但是重用实现的需求常常导致类层次结构的深入，从而克服 Java 中缺乏多继承支持的问题。\npublic class A implements Runnable &#123;    @Override    public void run() &#123;        // Some implementation here    &#125;&#125;\n\n// Class B wants to inherit the implementation of run() method from class A.public class B extends A implements AutoCloseable &#123;    @Override    public void close() throws Exception &#123;       // Some implementation here    &#125;&#125;\n\n// Class C wants to inherit the implementation of run() method from class A// and the implementation of close() method from class B.public class C extends B implements Readable &#123;    @Override    public int read(java.nio.CharBuffer cb) throws IOException &#123;       // Some implementation here    &#125;&#125;\n\nAnd so on… The recent Java 8 release somewhat addressed the problem with the introduction of default methods. Because of default methods, interfaces actually have started to provide not only contract but also implementation. Consequently, the classes which implement those interfaces are automatically inheriting these implemented methods as well. For example:\n最近的 Java 8 发行版在一定程度上解决了引入默认方法的问题。由于默认的方法，接口实际上已经开始提供契约和实现。因此，实现这些接口的类也会自动继承这些实现的方法。例如：\npackage com.javacodegeeks.advanced.design;public interface DefaultMethods extends Runnable, AutoCloseable &#123;    @Override    default void run() &#123;        // Some implementation here    &#125;    @Override    default void close() throws Exception &#123;       // Some implementation here    &#125;&#125;// Class C inherits the implementation of run() and close() methods from the// DefaultMethods interface.public class C implements DefaultMethods, Readable &#123;    @Override    public int read(java.nio.CharBuffer cb) throws IOException &#123;       // Some implementation here    &#125;&#125;\n\nBe aware that multiple inheritance is a powerful, but at the same time a dangerous tool to use. The well known “Diamond of Death” problem is often cited as the fundamental flaw of multiple inheritance implementations, so developers are urged to design class hierarchies very carefully. Unfortunately, the Java 8 interfaces with default methods are becoming the victims of those flaws as well.\n请注意，多重继承是一种强大的工具，但同时也是一种危险的工具。众所周知的“死亡钻石”问题经常被认为是多重继承实现的根本缺陷，因此开发人员需要非常仔细地设计类层次结构。不幸的是，带有默认方法的 Java 8 接口也成为这些缺陷的受害者。\ninterface A &#123;    default void performAction() &#123;    &#125;&#125;interface B extends A &#123;    @Override    default void performAction() &#123;    &#125;&#125;interface C extends A &#123;    @Override    default void performAction() &#123;    &#125;&#125;\n\nFor example, the following code snippet fails to compile:\n例如，以下代码片段编译失败：\n// E is not compilable unless it overrides performAction() as wellinterface E extends B, C &#123;&#125;\n\nAt this point it is fair to say that Java as a language always tried to escape the corner cases of object-oriented programming, but as the language evolves, some of those cases are started to pop up.\n在这一点上，可以说 Java 作为一种语言总是试图逃避面向对象编程的极端情况，但是随着语言的发展，其中一些不利情况也开始出现。\n11、Inheritance and composition继承和组合\nFortunately, inheritance is not the only way to design your classes. Another alternative, which many developers consider being better than inheritance, is composition. The idea is very simple: instead of building class hierarchies, the classes should be composed from other classes.\n幸运的是，继承并不是设计类的唯一方法。另一种选择是组合，许多开发人员认为它比继承更好。这个想法很简单：类应该由其他类组成，而不是构建类层次结构。\nLet us take a look on this example:\n让我们来看看这个例子：\npublic class Vehicle &#123;    private Engine engine;    private Wheels[] wheels;    // ...&#125;\n\nThe Vehicle class is composed out of engine and wheels (plus many other parts which are left aside for simplicity). However, one may say that Vehicle class is also an engine and so could be designed using the inheritance.\nVehicle 类由引擎和车轮组成（还有很多其他的部件，为了简单起见，都被放在一边了）。然而，有人可能会说 Vehicle 类也是一个引擎，因此可以使用继承来设计它。\npublic class Vehicle extends Engine &#123;    private Wheels[] wheels;    // ...&#125;\n\nWhich design decision is right? The general guidelines（指导方针） are known as IS-A and HAS-A principles. IS-A is the inheritance relationship: the subclass also satisfies the parent class specification and a such IS-A variation of parent class. Consequently, HAS-A is the composition relationship: the class owns (or HAS-A) the objects which belong to it. In most cases, the HAS-A principle works better then IS-A for couple of reasons:\n哪个设计决策是正确的？一般准则被称为 IS-A 和 HAS-A 原则。IS-A 是继承关系：子类也满足父类规范，这样的 IS-A 是父类的变体。因此，HAS-A 是复合关系：类拥有（或 HAS-A）属于它的对象。在大多数情况下，HAS-A 原则比 IS-A 更好，原因如下:\n\nThe design is more flexible（灵活的） in a way it could be changed\nThe model is more stable as changes are not propagating through class hierarchies\nThe class and its composites are loosely coupled compared to inheritance which tightly couples parent and its subclasses\nThe reasoning about class is simpler as all its dependencies are included in it, in one place\n\n（1）这种设计在某种程度上更加灵活，便于修改（2）由于更改不通过类层次结构传播，因此模型更加稳定（3）与父类及其子类紧密耦合的继承相比，类及其组合是松散耦合的（4）类的推理更简单，因为它的所有依赖项都包含在类中\nHowever, the inheritance has its own place, solves real design issues in different way and should not be neglected. Please keep those two alternatives in mind while designing your object-oriented models.\n然而，继承有它自己的位置，同样以不同的方式解决了真正的设计问题，不应该被忽视。在设计面向对象的模型时，请记住这两个原则。\n12、Encapsulation封装\nThe concept of encapsulation in object-oriented programming is all about hiding the implementation details (like state, internal methods, etc.) from the outside world. The benefits of encapsulation are maintainability and ease of change. The less intrinsic details classes expose, the more control the developers have over changing their internal implementation, without the fear to break the existing code (a real problem if you are developing a library or framework used by many people).\n面向对象编程中封装的概念就是将实现细节（如状态、内部方法等）对外部世界隐藏。封装的好处是可维护性和易于更改。类暴露的内部细节越少，开发人员对更改内部实现的控制就越强，无需担心破坏现有代码（如果你正在开发许多人使用的库或框架，这是一个真正的问题）。\nEncapsulation in Java is achieved using visibility and accessibility rules. It is considered a best practice in Java to never expose the fields directly, only by means of getters and setters (if the field is not declared as final). For example:\nJava 中的封装是使用可见性和可访问性规则实现的。在 Java 中，不直接公开字段被认为是一种最佳实践，只有通过 getter 和 setter（如果字段未声明为 final）才能公开字段。例如:\npackage com.javacodegeeks.advanced.design;public class Encapsulation &#123;    private final String email;    private String address;    public Encapsulation( final String email ) &#123;        this.email = email;    &#125;    public String getAddress() &#123;        return address;    &#125;    public void setAddress(String address) &#123;        this.address = address;    &#125;    public String getEmail() &#123;        return email;    &#125;&#125;\n\nThis example resembles what is being called JavaBeans in Java language: the regular Java classes written by following the set of conventions, one of those being allow the access to fields using getter and setter methods only.\n这个示例类似于 Java 语言中的 JavaBeans：常规 Java 类是按照一组约定编写的，其中之一是只允许使用 getter 和 setter 方法访问字段。\nAs we already emphasized in the Inheritance section, please always try to keep the class public contract minimal, following the encapsulation principle. Whatever should not be public, should be private instead (or protected &#x2F; package private, depending on the problem you are solving). In long run it will pay off, giving you the freedom to evolve your design without introducing breaking changes (or at least minimize them).\n正如我们在继承部分中已经强调的，请始终按照封装原则尽量减少类 public 契约。任何不应该公开的内容都应该是私有的（或者受保护&#x2F;包私有，这取决于你正在解决的问题）。从长远来看，它会给你带来回报，让你在不引入破坏性变化的情况下自由地改进你的设计（或者最小化破坏）。\n13、Final classes and methods终态类和终态方法\nIn Java, there is a way to prevent the class to be subclassed by any other class: it should be declared as final.\n在 Java 中，有一种方法可以防止该类被任何其他类子类化：它应该声明为 final。\npackage com.javacodegeeks.advanced.design;public final class FinalClass &#123;&#125;\n\nThe same final keyword in the method declaration prevents the method in question to be overridden in subclasses.\n方法声明中使用 final 关键字可防止在子类中覆盖该方法。\npackage com.javacodegeeks.advanced.design;public class FinalMethod &#123;    public final void performAction() &#123;    &#125;&#125;\n\nThere are no general rules to decide if class or method should be final or not. Final classes and methods limit the extensibility and it is very hard to think ahead if the class should or should not be subclassed, or method should or should not be overridden. This is particularly important to library developers as the design decisions like that could significantly limit the applicability of the library.\n没有通用的规则来决定类或方法是否应该是终态的。终态类和方法限制了可扩展性，很难提前考虑类应该或不应该被子类化，或者方法应该或不应该被重写。这对于库开发人员来说特别重要，因为这样的设计决策可能会极大地限制库的适用性。\nJava standard library has some examples of final classes, with most known being String class. On an early stage, the decision has been taken to proactively prevent any developer’s attempts to come up with own, “better” string implementations.\nJava 标准库中有一些终态类的例子，其中最著名的是 String 类。在早期阶段，已经采取了积极的措施，以防止任何开发人员试图提出自己的、“更好的”字符串实现。\n14、What’s next接下来是什么\nIn this part of the tutorial we have looked at object-oriented design concepts in Java. We also briefly walked through contract-based development, touched some functional concepts and saw how the language evolved over time. In next part of the tutorial we are going to meet generics and how they are changing the way we approach type-safe programming.\n在本教程的这一部分中，我们讨论了 Java 中的面向对象设计概念。我们还简要介绍了基于契约的开发，触及了一些功能概念，并看到了语言是如何随着时间而发展的。在本教程的下一部分中，我们将介绍泛型以及它们如何改变我们处理类型安全编程的方式。\n","categories":["文献翻译","java"],"tags":["未标记"]},{"title":"Java-8-中的-Streams-API-详解","url":"/4686b6a1-2bb6-11ee-879b-0b2c36f14b2e/","content":"\n\n\n\nJava 8 中的 Streams API 详解\n参考自：https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/\n\n注：本文适当调整了原文内容和结构，并修正代码错误\nJava 8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种便利、高效的聚合操作（aggregate operation），或者大批量数据操作（bulk data operation）。Stream API 借助于 Lambda 表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork&#x2F;join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。\n1 前言详细讨论之前，先展示一个排序、取值案例在 Java 8 之前版本的实现：\n// 在原文实现代码基础上添加枚举类 Transactionenum Transaction &#123;    GROCERY(0, &quot;grocery&quot;), NONE(1, &quot;none&quot;);    private final int id;    private final String value;    Transaction(int id, String value) &#123;        this.id = id;        this.value = value;    &#125;    public Object getType() &#123; return this; &#125;    public int getId() &#123; return this.id; &#125;    public String getValue() &#123; return this.value; &#125;&#125;public static void main(String[] args) &#123;    // 使用泛型初始化一个 Transaction 集合，代替原文使用的原始类型    List&lt;Transaction&gt; transactions = new ArrayList&lt;&gt;() &#123;        &#123;            add(Transaction.NONE);            add(Transaction.GROCERY);        &#125;    &#125;;    List&lt;Transaction&gt; groceryTransactions = new Arraylist&lt;&gt;();    for(Transaction t: transactions)&#123;        if(t.getType() == Transaction.GROCERY)&#123;            groceryTransactions.add(t);        &#125;    &#125;    Collections.sort(groceryTransactions, new Comparator()&#123;        public int compare(Transaction t1, Transaction t2)&#123;            return t2.getValue().compareTo(t1.getValue());        &#125;    &#125;);    List&lt;Integer&gt; transactionIds = new ArrayList&lt;&gt;();    for(Transaction t: groceryTransactions)&#123;        transactionsIds.add(t.getId());    &#125;｝\n\n在 Java 8 中使用 Stream 实现的版本更加简洁：\nList&lt;Integer&gt; transactionsIds = transactions.parallelStream().    filter(t -&gt; t.getType() == Transaction.GROCERY).    sorted(comparing(Transaction::getValue).reversed()).    map(Transaction::getId).    collect(toList());\n\n2 总览2-1 什么是流Stream 不是集合元素，它不是数据结构，并不保存数据，它与算法和计算有关，更像一个高级版本的 Iterator。原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；使用 Stream，用户只要给出需要对其包含的元素执行什么操作，比如：「过滤掉长度大于 10 的字符串」、「获取每个字符串的首字母」等，Stream 会隐式地在内部进行遍历，做出相应的数据转换。\nStream 的处理过程是单向、不可往复的，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。Stream 的另外一大特点是，数据源本身可以是无限的。\n和迭代器不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，只能读取一个 item 后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，每一段都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java 7 中引入的 Fork&#x2F;Join 框架（JSR166y）来拆分任务和加速处理过程。Java 的并行 API 演变历程概括如下：\n\n1.0-1.4 中的 java.lang.Thread\n5.0 中的 java.util.concurrent\n6.0 中的 Phasers 等\n7.0 中的 Fork&#x2F;Join 框架\n8.0 中的 Lambda\n\n2-2 流的构成当我们使用一个流的时候，通常包括三个基本步骤：\n\n获取一个数据源（source）\n数据转换\n执行操作获取想要的结果\n\n每次转换，原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道。\n2-3 生成 Stream有多种方式生成 Stream 源\n从 Collection 和数组\nCollection.stream()\nCollection.parallelStream()\nArrays.stream(T array)\nStream.of()\n\n从 BufferedReader\njava.io.BufferedReader.lines()\n\n静态工厂\njava.util.stream.IntStream.range()\njava.nio.file.Files.walk()\n\n自己构建\njava.util.Spliterator\n\n其它\nRandom.ints()\nBitSet.stream()\nPattern.splitAsStream(java.lang.CharSequence)\nJarFile.stream()\n\n3 流的操作当把一个数据结构包装成 Stream 后，就要开始对里面的元素进行各类操作了，流的操作类型分为以下几种：\n3-1 Intermediate一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射&#x2F;过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。常见的操作如下：\nmap (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered\n3-2 Terminal一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用「光」了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。常见的操作如下：\nforEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator\n在对于一个 Stream 进行多次转换操作 (Intermediate 操作)，每次都对 Stream 的每个元素进行转换，而且是执行多次，这样时间复杂度就是 N（转换次数）个 for 循环里把所有操作都做掉的总和吗？其实不是这样的，转换操作都是 lazy 的，多个转换操作只会在 Terminal 操作的时候融合起来，一次循环完成。我们可以这样简单的理解，Stream 里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在 Terminal 操作的时候循环 Stream 对应的集合，然后对每个元素执行所有的函数。\n3-3 short-circuiting还有一种操作被称为 short-circuiting（短路）。用以指：\n\n对于一个 intermediate 操作，如果它接受的是一个无限大（infinite&#x2F;unbounded）的 Stream，但返回一个有限的新 Stream。\n对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。\n\n当操作一个无限大的 Stream，而又希望在有限时间内完成操作，则在管道内拥有一个 short-circuiting 操作是必要非充分条件。常见的操作如下：\nanyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limit\n4 流的使用详解简单说，对 Stream 的使用就是实现一个 filter-map-reduce 过程，产生一个最终结果，或者导致一个副作用（side effect）。\n4-1 构造与转换下面提供最常见的几种构造 Stream 的样例。\n案例：构造流的几种常见方法\n// 1. Individual valuesStream stream = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);// 2. ArraysString [] strArray = new String[] &#123;&quot;a&quot;, &quot;b&quot;, &quot;c&quot;&#125;;stream = Stream.of(strArray);stream = Arrays.stream(strArray);// 3. CollectionsList&lt;String&gt; list = Arrays.asList(strArray);stream = list.stream();\n\n需要注意的是，对于基本数值型，目前有三种对应的包装类型 Stream：IntStream、LongStream、DoubleStream。当然我们也可以用 Stream、Stream &gt;、Stream，但是 boxing 和 unboxing 会很耗时，所以特别为这三种基本数值型提供了对应的 Stream。Java 8 中还没有提供其它数值型 Stream，因为这将导致扩增的内容较多。而常规的数值型聚合运算可以通过上面三种 Stream 进行。\n案例：数值流的构造\nIntStream.of(new int[]&#123;1, 2, 3&#125;).forEach(System.out::println);IntStream.range(1, 3).forEach(System.out::println);IntStream.rangeClosed(1, 3).forEach(System.out::println);\n\n案例：流转换为其它数据结构\n// 1. ArrayString[] strArray1 = stream.toArray(String[]::new);// 2. CollectionList&lt;String&gt; list1 = stream.collect(Collectors.toList());List&lt;String&gt; list2 = stream.collect(Collectors.toCollection(ArrayList::new));Set set1 = stream.collect(Collectors.toSet());Stack stack1 = stream.collect(Collectors.toCollection(Stack::new));// 3. StringString str = stream.collect(Collectors.joining()).toString();\n注：一个 Stream 只可以使用一次，上面的代码为了简洁而重复使用了数次。\n4-2 典型用法及案例map、flatMap我们先来看 map。如果你熟悉 scala 这类函数式语言，对这个方法应该很了解，它的作用就是把 input Stream 的每一个元素，映射成 output Stream 的另外一个元素。\n案例：这段代码把所有的单词转换为大写。\nList&lt;String&gt; output = wordList.stream()    .map(String::toUpperCase)    .collect(Collectors.toList());\n\n案例：这段代码生成一个整数 list 的平方数 {1, 4, 9, 16}。\nList&lt;Integer&gt; nums = Arrays.asList(1, 2, 3, 4);List&lt;Integer&gt; squareNums = nums.stream()    .map(n -&gt; n * n)    .collect(Collectors.toList());\n\n从上面例子可以看出，map 生成的是个 1:1 映射，每个输入元素，都按照规则转换成为另外一个元素。还有一些场景，是一对多映射关系的，这时需要 flatMap。\n案例：一对多。flatMap 把 input Stream 中的层级结构扁平化，就是将最底层元素抽出来放到一起，最终 output 的新 Stream 里面已经没有 List 了，都是直接的数字。\ntream&lt;List&lt;Integer&gt;&gt; inputStream = Stream.of(    Arrays.asList(1),    Arrays.asList(2, 3),    Arrays.asList(4, 5, 6));Stream&lt;Integer&gt; outputStream = inputStream    .flatMap((childList) -&gt; childList.stream());\n\nfilterfilter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream。\n案例：留下偶数，经过条件「被 2 整除」的 filter，剩下的数字为 {2, 4, 6}。\nInteger[] sixNums = &#123;1, 2, 3, 4, 5, 6&#125;;Integer[] evens =Stream.of(sixNums)    .filter(n -&gt; n%2 == 0)    .toArray(Integer[]::new);\n\n案例：把单词挑出来，这段代码首先把每行的单词用 flatMap 整理到新的 Stream，然后保留长度不为 0 的，就是整篇文章中的全部单词了。\nList&lt;String&gt; output = reader.lines()    .flatMap(line -&gt; Stream.of(line.split(REGEXP)))    .filter(word -&gt; word.length() &gt; 0)    .collect(Collectors.toList());\n\nforEach、peekforEach 方法接收一个 Lambda 表达式，然后在 Stream 的每一个元素上执行该表达式。\n案例：打印姓名（forEach 和 pre-java 8 的对比）\n// Java 8roster.stream()    .filter(p -&gt; p.getGender() == Person.Sex.MALE)    .forEach(p -&gt; System.out.println(p.getName()));\n\n// Pre-Java 8for (Person p : roster) &#123;    if (p.getGender() == Person.Sex.MALE) &#123;        System.out.println(p.getName());    &#125;&#125;\n\n对一个人员集合遍历，找出男性并打印姓名。可以看出来，forEach 是为 Lambda 而设计的，保持了最紧凑的风格。而且 Lambda 表达式本身是可以重用的，非常方便。当需要为多核系统优化时，可以 parallelStream().forEach()，只是此时原有元素的次序没法保证，并行的情况下将改变串行时操作的行为，此时 forEach 本身的实现不需要调整，而 Java8 以前的 for 循环 code 可能需要加入额外的多线程逻辑。\n但一般认为，forEach 和常规 for 循环的差异不涉及到性能，它们仅仅是函数式风格与传统 Java 风格的差别。\n另外一点需要注意，forEach 是 terminal 操作，因此它执行后，Stream 的元素就被「消费」掉了，你无法对一个 Stream 进行两次 terminal 运算。下面的代码是错误的：\nstream.forEach(element -&gt; doOneThing(element));stream.forEach(element -&gt; doAnotherThing(element));\n\n相反，具有相似功能的 intermediate 操作 peek 可以达到上述目的。如下是出现在该 api javadoc 上的一个示例。\n案例：使用 peek 对每个元素执行操作并返回一个新的 Stream\nStream.of(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;)    .filter(e -&gt; e.length() &gt; 3)    .peek(e -&gt; System.out.println(&quot;Filtered value: &quot; + e))    .map(String::toUpperCase)    .peek(e -&gt; System.out.println(&quot;Mapped value: &quot; + e))    .collect(Collectors.toList());\n\nforEach 不能修改自己包含的本地变量值，也不能用 break&#x2F;return 之类的关键字提前结束循环。\nfindFirst这是一个 termimal 兼 short-circuiting 操作，它总是返回 Stream 的第一个元素，或者空。这里比较重点的是它的返回值类型：Optional。这也是一个模仿 Scala 语言中的概念，作为一个容器，它可能含有某值，或者不包含。使用它的目的是尽可能避免 NullPointerException。\n案例：Optional 的两个用例\nString strA = &quot; abcd &quot;, strB = null;print(strA);print(&quot;&quot;);print(strB);getLength(strA);getLength(&quot;&quot;);getLength(strB);public static void print(String text) &#123;     // Java 8     Optional.ofNullable(text).ifPresent(System.out::println);     // Pre-Java 8     if (text != null) &#123;         System.out.println(text);     &#125; &#125;public static int getLength(String text) &#123;    // Java 8    return Optional.ofNullable(text).map(String::length).orElse(-1);    // Pre-Java 8    // return if (text != null) ? text.length() : -1;&#125;\n\n在更复杂的 if (xx !&#x3D; null) 的情况中，使用 Optional 代码的可读性更好，而且它提供的是编译时检查，能极大的降低 NPE 这种 Runtime Exception 对程序的影响，或者迫使程序员更早的在编码阶段处理空值问题，而不是留到运行时再发现和调试。\nStream 中的 findAny、max&#x2F;min、reduce 等方法等返回 Optional 值。还有例如 IntStream.average() 返回 OptionalDouble 等等。\nreduce这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。例如 Stream 的 sum 就相当于 Integer sum = integers.reduce(0, (a, b) -&gt; a+b); 或 Integer sum = integers.reduce(0, Integer::sum);。也有没有起始值的情况，这时会把 Stream 的前面两个元素组合起来，返回的是 Optional。\n案例：reduce 的使用\n// 字符串连接，concat = &quot;ABCD&quot;String concat = Stream.of(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;).reduce(&quot;&quot;, String::concat);// 求最小值，minValue = -3.0double minValue = Stream.of(-1.5, 1.0, -3.0, -2.0).reduce(Double.MAX_VALUE, Double::min);// 求和，sumValue = 10, 有起始值int sumValue = Stream.of(1, 2, 3, 4).reduce(0, Integer::sum);// 求和，sumValue = 10, 无起始值sumValue = Stream.of(1, 2, 3, 4).reduce(Integer::sum).get();// 过滤，字符串连接，concat = &quot;ace&quot;concat = Stream.of(&quot;a&quot;, &quot;B&quot;, &quot;c&quot;, &quot;D&quot;, &quot;e&quot;, &quot;F&quot;).    filter(x -&gt; x.compareTo(&quot;Z&quot;) &gt; 0).    reduce(&quot;&quot;, String::concat);\n\n上面代码例如第一个示例的 reduce()，第一个参数（空白字符）即为起始值，第二个参数（String::concat）为 BinaryOperator。这类有起始值的 reduce() 都返回具体的对象。而对于第四个示例没有起始值的 reduce()，由于可能没有足够的元素，返回的是 Optional，请留意这个区别。\nlimit、skiplimit 返回 Stream 的前面 n 个元素；skip 则是扔掉前 n 个元素（它是由一个叫 subStream 的方法改名而来）。\n案例：limit 和 skip 对运行次数的影响\n// 定义一个 Person 类private class Person &#123;    public int no;    private String name;    public Person (int no, String name) &#123;        this.no = no;        this.name = name;    &#125;    public String getName() &#123;        System.out.print(name + &quot;,&quot;);        return name;    &#125;&#125;public void testLimitAndSkip() &#123;    List&lt;Person&gt; persons = new ArrayList&lt;&gt;();    for (int i = 1; i &lt;= 10000; i++) &#123;        Person person = new Person(i, &quot;name&quot; + i);        persons.add(person);    &#125;    List&lt;String&gt; personList2 = persons.stream()        .map(Person::getName)        .limit(10).skip(3)        .collect(Collectors.toList());    System.out.println(&quot;\\n&quot; + personList2);&#125;\n\n输出结果为：\nname1,name2,name3,name4,name5,name6,name7,name8,name9,name10,[name4, name5, name6, name7, name8, name9, name10]\n\n这是一个有 10，000 个元素的 Stream，但在 short-circuiting 操作 limit 和 skip 的作用下，管道中 map 操作指定的 getName() 方法的执行次数为 limit 所限定的 10 次，而最终返回结果在跳过前 3 个元素后只有后面 7 个返回。\n有一种情况是 limit&#x2F;skip 无法达到 short-circuiting 目的的，就是把它们放在 Stream 的排序操作后，原因跟 sorted 这个 intermediate 操作有关：此时系统并不知道 Stream 排序后的次序如何，所以 sorted 中的操作看上去就像完全没有被 limit 或者 skip 一样。\n案例：limit 和 skip 对 sorted 后的运行次数无影响\nprivate class Person &#123;    public int no;    private String name;    public Person (int no, String name) &#123;        this.no = no;        this.name = name;    &#125;    public String getName() &#123; return name; &#125;    @Override    public String toString() &#123;        return &quot;&#123;no=&quot; + no + &quot;, name=&#x27;&quot; + name + &quot;&#x27;&#125;&quot;;    &#125;&#125;public void testLimitAndSkip() &#123;    Set&lt;Person&gt; persons = new HashSet&lt;&gt;();    for (int i = 1; i &lt;= 5; i++) &#123;        Person person = new Person(i, &quot;name&quot; + i);        persons.add(person);    &#125;    System.out.println(persons);    List&lt;Person&gt; personList2 = persons.stream()        .sorted((p1, p2) -&gt;p1.getName().compareTo(p2.getName()))        .limit(2)        .collect(Collectors.toList());    System.out.println(&quot;\\n&quot; + personList2);&#125;// 或优化为：public void testLimitAndSkip() &#123;    Set&lt;Person&gt; persons = new HashSet&lt;&gt;();    for (int i = 1; i &lt;= 5; i++) &#123;        Person person = new Person(i, &quot;name&quot; + i);        persons.add(person);    &#125;    System.out.println(persons);    List&lt;Person&gt; personList2 = persons.stream()        .sorted(Comparator.comparing(Person::getName))        .limit(2)        .collect(Collectors.toList());    System.out.println(&quot;\\n&quot; + personList2);&#125;\n\n上面的示例对案例做了微调，将元素容器修改为 Set，以便能清晰显示出排序效果。仅对 5 个元素的 Stream 排序，然后进行 limit 操作。输出结果为：\n[&#123;no=1, name=&#x27;name1&#x27;&#125;, &#123;no=5, name=&#x27;name5&#x27;&#125;, &#123;no=4, name=&#x27;name4&#x27;&#125;, &#123;no=3, name=&#x27;name3&#x27;&#125;, &#123;no=2, name=&#x27;name2&#x27;&#125;][&#123;no=1, name=&#x27;name1&#x27;&#125;, &#123;no=2, name=&#x27;name2&#x27;&#125;]\n\n即虽然最后的返回元素数量是 2，但整个管道中的 sorted 表达式执行次数没有像前面例子相应减少。\n最后有一点需要注意的是，对一个 parallel 的 Steam 管道来说，如果其元素是有序的，那么 limit 操作的成本会比较大，因为它的返回对象必须是前 n 个也有一样次序的元素。取而代之的策略是取消元素间的次序，或者不要用 parallel Stream。\nsorted对 Stream 的排序通过 sorted 进行，它比数组的排序更强之处在于你可以首先对 Stream 进行各类 map、filter、limit、skip 甚至 distinct 来减少元素数量后，再排序，这能帮助程序明显缩短执行时间。\n案例：排序前使用 limit 和 skip 优化\nprivate class Person &#123;    public int no;    private String name;    public Person (int no, String name) &#123;        this.no = no;        this.name = name;    &#125;    public String getName() &#123; return name; &#125;    @Override    public String toString() &#123;        return &quot;&#123;no=&quot; + no + &quot;, name=&#x27;&quot; + name + &quot;&#x27;&#125;&quot;;    &#125;&#125;public void testLimitAndSkip() &#123;    List&lt;Person&gt; persons = new ArrayList&lt;&gt;();    for (int i = 1; i &lt;= 5; i++) &#123;        Person person = new Person(i, &quot;name&quot; + i);        persons.add(person);    &#125;    System.out.println(persons);    List&lt;Person&gt; personList2 = persons.stream()        .limit(2)        .sorted((p1, p2) -&gt; p1.getName().compareTo(p2.getName()))        .collect(Collectors.toList());    System.out.println(&quot;\\n&quot; + personList2);&#125;\n\n结果会简单很多：\n[&#123;no=1, name=&#x27;name1&#x27;&#125;, &#123;no=2, name=&#x27;name2&#x27;&#125;, &#123;no=3, name=&#x27;name3&#x27;&#125;, &#123;no=4, name=&#x27;name4&#x27;&#125;, &#123;no=5, name=&#x27;name5&#x27;&#125;][&#123;no=1, name=&#x27;name1&#x27;&#125;, &#123;no=2, name=&#x27;name2&#x27;&#125;]\n\n当然，这种优化是有 business logic 上的局限性的：即不要求排序后再取值。\nmin、max、distinctmin 和 max 的功能也可以通过对 Stream 元素先排序，再 findFirst 来实现，但前者的性能会更好，为 O(n)，而 sorted 的成本是 O(n log n)。同时它们作为特殊的 reduce 方法被独立出来也是因为求最大最小值是很常见的操作。\n案例：找出最长一行的长度\nBufferedReader br = new BufferedReader(new FileReader(&quot;c:\\\\SUService.log&quot;));int longest = br.lines()    .mapToInt(String::length)    .max()    .getAsInt();br.close();System.out.println(longest);\n\n案例：使用 distinct 来找出全文不重复的单词，转小写，并排序\nList&lt;String&gt; words = br.lines()    .flatMap(line -&gt; Stream.of(line.split(&quot; &quot;)))    .filter(word -&gt; word.length() &gt; 0)    .map(String::toLowerCase)    .distinct()    .sorted()    .collect(Collectors.toList());br.close();System.out.println(words);\n\nsum案例：通过 stream() 获取当前小物件的 source，filter 和 mapToInt 是 intermediate 操作，进行数据筛选和转换，最后一个 sum() 为 terminal 操作，对符合条件的全部小物件作重量求和。\nint sum = widgets.stream()    .filter(w -&gt; w.getColor() == RED)    .mapToInt(w -&gt; w.getWeight())    .sum();\n\nMatchStream 有三个 match 方法，从语义上说：\n\nallMatch：Stream 中全部元素符合传入的 predicate，返回 true\nanyMatch：Stream 中只要有一个元素符合传入的 predicate，返回 true\nnoneMatch：Stream 中没有一个元素符合传入的 predicate，返回 true\n\n它们都不是要遍历全部元素才能返回结果。例如 allMatch 只要一个元素不满足条件，就 skip 剩下的所有元素，返回 false。对清单 13 中的 Person 类稍做修改，加入一个 age 属性和 getAge 方法。\n案例：使用 Match\nclass Person &#123;    public int no;    private String name;    private int age;    public Person(int no, String name, int age) &#123;        this.no = no;        this.name = name;        this.age = age;    &#125;    public String getName() &#123; return name; &#125;    public int getAge() &#123; return age; &#125;    @Override    public String toString() &#123;        return &quot;&#123;no=&quot; + no + &quot;, name=&#x27;&quot; + name + &quot;&#x27;&#125;&quot;;    &#125;&#125;public void testMatch() &#123;    List&lt;Person&gt; persons = new ArrayList&lt;&gt;() &#123;        &#123;            add(new Person(1, &quot;name&quot; + 1, 10));            add(new Person(2, &quot;name&quot; + 2, 21));            add(new Person(3, &quot;name&quot; + 3, 34));            add(new Person(4, &quot;name&quot; + 4, 6));            add(new Person(5, &quot;name&quot; + 5, 55));        &#125;    &#125;;    boolean isAllAdult = persons.stream()            .allMatch(p -&gt; p.getAge() &gt; 18);    System.out.println(&quot;All are adult? &quot; + isAllAdult);    boolean isThereAnyChild = persons.stream()            .anyMatch(p -&gt; p.getAge() &lt; 12);    System.out.println(&quot;Any child? &quot; + isThereAnyChild);&#125;\n\n输出结果：\nAll are adult? falseAny child? true\n\n4-3 进阶：自己生成流Stream.generate通过实现 Supplier 接口，你可以自己来控制流的生成。这种情形通常用于随机数、常量的 Stream，或者需要前后元素间维持着某种状态信息的 Stream。把 Supplier 实例传递给 Stream.generate() 生成的 Stream，默认是串行（相对 parallel 而言）但无序的（相对 ordered 而言）。由于它是无限的，在管道中，必须利用 limit 之类的操作限制 Stream 大小。\n案例：生成 10 个随机整数\nRandom seed = new Random();Supplier&lt;Integer&gt; random = seed::nextInt;Stream.generate(random)    .limit(10)    .forEach(System.out::println);//Another wayIntStream.generate(() -&gt; (int) (System.nanoTime() % 100))    .limit(10)    .forEach(System.out::println);\n\nStream.generate() 还接受自己实现的 Supplier。例如在构造海量测试数据的时候，用某种自动的规则给每一个变量赋值；或者依据公式计算 Stream 的每个元素值。这些都是维持状态信息的情形。\n案例：自实现 Supplier\nStream.generate(new PersonSupplier())    .limit(10)    .forEach(p -&gt; System.out.println(p.getName() + &quot;, &quot; + p.getAge()));private class PersonSupplier implements Supplier&lt;Person&gt; &#123;    private int index = 0;    private Random random = new Random();    @Override    public Person get() &#123;        return new Person(index++, &quot;StormTestUser&quot; + index, random.nextInt(100));    &#125;&#125;\n\n输出结果：\nStormTestUser1, 9StormTestUser2, 12StormTestUser3, 88StormTestUser4, 51StormTestUser5, 22StormTestUser6, 28StormTestUser7, 81StormTestUser8, 51StormTestUser9, 4StormTestUser10, 76\n\nStream.iterateiterate 跟 reduce 操作很像，接受一个种子值，和一个 UnaryOperator（例如 f）。然后种子值成为 Stream 的第一个元素，f(seed) 为第二个，f(f(seed)) 第三个，以此类推。\n案例：生成一个等差数列\nStream.iterate(0, n -&gt; n + 3).limit(10). forEach(x -&gt; System.out.print(x + &quot; &quot;));.\n\n输出结果：\n0 3 6 9 12 15 18 21 24 27\n\n与 Stream.generate 相仿，在 iterate 时候管道必须有 limit 这样的操作来限制 Stream 大小。\n4-4 进阶：用 Collectors 来进行 reduction 操作java.util.stream.Collectors 类的主要作用就是辅助进行各类有用的 reduction 操作，例如转变输出为 Collection，把 Stream 元素进行归组。\ngroupingBy 和 partitioningBy案例：按照年龄归组\nMap&lt;Integer, List&lt;Person&gt;&gt; personGroups = Stream.generate(new PersonSupplier())    .limit(100)    .collect(Collectors.groupingBy(Person::getAge));Iterator it = personGroups.entrySet().iterator();while (it.hasNext()) &#123;    Map.Entry&lt;Integer, List&lt;Person&gt;&gt; persons = (Map.Entry) it.next();    System.out.println(&quot;Age &quot; + persons.getKey() + &quot; = &quot; + persons.getValue().size());&#125;\n\n上面的 code，首先生成 100 人的信息，然后按照年龄归组，相同年龄的人放到同一个 list 中，可以看到如下的输出：\nAge 0 = 2Age 1 = 2Age 5 = 2Age 8 = 1Age 9 = 1Age 11 = 2……\n\n案例：按照未成年人和成年人归组\nMap&lt;Boolean, List&lt;Person&gt;&gt; children = Stream.generate(new PersonSupplier())    .limit(100)    .collect(Collectors.partitioningBy(p -&gt; p.getAge() &lt; 18));System.out.println(&quot;Children number: &quot; + children.get(true).size());System.out.println(&quot;Adult number: &quot; + children.get(false).size());\n\n输出结果：\nChildren number: 23Adult number: 77\n在使用条件「年龄小于 18」进行分组后可以看到，不到 18 岁的未成年人是一组，成年人是另外一组。partitioningBy 其实是一种特殊的 groupingBy，它依照条件测试的是否两种结果来构造返回的数据结构，get(true) 和 get(false) 能即为全部的元素对象。\n5 结束语总之，Stream 的特性可以归纳为：\n\n不是数据结构\n\n它没有内部存储，它只是用操作管道从 source（数据结构、数组、generator function、IO channel）抓取数据。\n\n它也绝不修改自己所封装的底层数据结构的数据。例如 Stream 的 filter 操作会产生一个不包含被过滤元素的新 Stream，而不是从 source 删除那些元素。\n\n所有 Stream 的操作必须以 lambda 表达式为参数\n\n不支持索引访问\n\n你可以请求第一个元素，但无法请求第二个，第三个，或最后一个。不过请参阅下一项。\n\n很容易生成数组或者 List\n\n惰性化\n\n很多 Stream 操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始。\n\nIntermediate 操作永远是惰性化的。\n\n并行能力\n\n当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的。\n\n可以是无限的。集合有固定大小，Stream 则不必。limit(n) 和 findFirst() 这类的 short-circuiting 操作可以对无限的 Stream 进行运算并很快完成。\n\n\n","categories":["文献翻译","java"],"tags":["未标记"]},{"title":"Java-Custom-Exception-Example","url":"/4686ddb0-2bb6-11ee-879b-0b2c36f14b2e/","content":"\n\n\n\nJava Custom Exception ExampleJava 自定义异常案例\n\n转译自：https://examples.javacodegeeks.com\n\nIn this example we will look briefly（短暂的） at the basics of Exception, in Java Programming Language. We will also see, how to create a custom Exception Class.\n在这个案例中，我们将使用 Java 语言来简要介绍“异常”的基础知识。我们同样也能够了解如何创建一个自定义的 Exception 类。\n1、Basics of Exception异常的基础知识As per（按照） oracle docs, An exception is an event, which occurs during the execution of a program, that disrupts（扰乱） the normal flow of the program’s instructions（指令）.\n按照 oracle 的文档介绍，异常是一个在程序运行期间发生的事件，会扰乱正常程序流程的指令。\nIn laymen（非专业人员） terms, when a condition occurs, in which the routine（程序） is not sure how to proceed in an ordinary way it creates an object of exception and hands it over to the runtime system to find an appropriate handler for the exception object. In case, the runtime system does not find an appropriate handler in the call hierarchy the runtime system terminates.\n用非专业的话来说，当满足异常发生条件时，程序不确定能以普通的方式进行时，它创建一个异常对象并递交给运行时系统，以查找处理异常对象的合适的处理程序。在这种情况下，运行时系统在运行时系统终止的调用层次结构中没有找到合适的处理程序。\nThe exceptions have java.lang.Throwable as their superclass.The three main categories of Exceptional conditions are :\n异常以 java.lang.Throwable 类作为父类。异常主要有三大类：\n（1）Error(represented by java.lang.Error and its sub-classes)\n错误（以 java.lang.Error 类及其子类表示）\n（2）Checked Exception(represented by direct subclasses of java.lang.Exception except java.lang.RuntimeException)\nChecked 异常（由 java.lang.Exception 除了 java.lang.RuntimeException 类的子类表示）\n（3）Unchecked or Runtime Exceptions (represented by java.lang.RuntimeException and its sub-classes)\nUnchecked 或运行时异常（由 java.lang.RuntimeException 类及其子类表示）\nErrors : Errors denote serious abnormal（不正常的） condition with the application like OutOfMemoryError or VirtualMachineError. Any reasonable application should not try to recover from such a condition.\n错误表示严重的异常情况，如 OutOfMemoryError（内存溢出）或 VirtualMachineError（虚拟机错误）。任何理由都不能使应用程序从这种情况中恢复过来。\nRuntime Exception&#x2F;Unchecked Exception : These types of exceptions usually indicate programming errors like NullPointerException or IllegalArgumentException. The application may or may not choose to recover from the condition.\n这些类型的异常通常表示程序错误，如 NullPointerException（空指针异常）或 IllegalArgumentException（参数异常）。应用程序可以选择从该类异常中恢复，也可以选择不恢复。\nChecked Exception : An application is supposed to catch these types of exceptions and recover reasonably from them. Examples include FileNotFoundException and ParseException.\n应用程序应该捕获这类异常并合理恢复。例如 FileNotFoundException（文件未找到异常）和 ParseException（解析异常）。\n2、Creating custom Exception创建自定义异常The first thing before creating a custom exception, the developer should be able to justify（证明） the creation（创建，n.）. As per（按照） Java Docs, You should write your own exception classes if you answer yes to any of the following questions; otherwise, you can probably use someone else’s.\n创建自定义异常前，开发者应为此（行为）找到依据。按照 Java 文档，如果你对以下任何一个问题回答 yes，你应该编写自己的异常类；否则，你（最好）用别人的。\n（1）Do you need an exception type that isn’t represented by those in the Java platform?\n你需要一个 Java 平台中没有（定义）的异常类型吗？\n（2）Would it help users if they could differentiate（区分） your exceptions from those thrown by classes written by other vendors（供应商）?\n如果用户可以将你的异常与其他供应商编写的类抛出的异常区分开来，那么这会对用户有帮助吗?\n（3）Does your code throw more than one related exception?\n你的代码是否会抛出多个相关异常？\n（4）If you use someone else’s exceptions, will users have access to those exceptions? A similar question is, should your package be independent and self-contained?\n如果你使用其他人的异常，用户是否可以访问这些异常？类似的问题是，你的包应该是独立的、自包含的吗？\nNow, that you are sure that you really do want a create a custom Exception class we will begin writing the actual program.To create a custom checked exception, we have to sub-class from the java.lang.Exception class. And that’s it! Yes, creating a custom exception in java is simple as that!\n现在，你确信确实想要创建一个自定义的异常类，我们将开始编写实际的程序。要创建一个自定义异常，我们必须从 java.lang.Exception 派生子类。是的，在 java 中创建一个自定义异常很简单！\npublic class CustomException extends Exception&#123;&#125;\n\nSometimes though, the CustomException object will have to be constructed from another exception. So its important that we create a constructor for such a scenario.\n但有时，CustomException 对象需要通过另一个异常来构造。因此，为这样的场景创建构造函数是很重要的。\nSo a more complete class would be as below :\n因此，一个更完整的类应如下所示：\nCustomException.java:\npackage com.javacodegeeks.examples.exception;public class CustomException extends Exception&#123;    private static final long serialVersionUID = 1997753363232807009L;\t\tpublic CustomException()\t\t&#123;&#125;\t\tpublic CustomException(String message)\t\t&#123;\t\t\tsuper(message);\t\t&#125;\t\tpublic CustomException(Throwable cause)\t\t&#123;\t\t\tsuper(cause);\t\t&#125;\t\tpublic CustomException(String message, Throwable cause)\t\t&#123;\t\t\tsuper(message, cause);\t\t&#125;\t\tpublic CustomException(String message, Throwable cause,                         boolean enableSuppression, boolean writableStackTrace)\t\t&#123;\t\t\tsuper(message, cause, enableSuppression, writableStackTrace);\t\t&#125;&#125;\n\n2.1、Testing the custom Exception（测试自定义异常） :CustomExceptionTest.java:\npackage com.javacodegeeks.examples.exception;public class CustomExceptionTest&#123;    public static void main(String[] args)    &#123;\ttry        &#123;\t      testException(null);        &#125;        catch (CustomException e)        &#123;\t      e.printStackTrace();        &#125;    &#125;    public static void testException(String string) throws CustomException    &#123;\t      if(string == null)\t\t    throw new CustomException(&quot;The String value is null&quot;);    &#125;&#125;\n\nSimilarly, an unchecked exception can be created by sub-classing from the java.lang.RuntimeException Class.\n类似地，unchecked 异常可以通过 java.lang.RuntimeException 的子类来创建。\npublic class CustomException extends RuntimeException&#123;...&#125;\n\n3、Points to note注意事项（1）An unchecked exception should be preferred（首选） to a checked exception. This will help programmes to be free of unnecessary try..catch blocks.\n相比一个 unchecked 异常，应首选 checked 异常。这有助于程序摆脱不必要的 try..catch 块。\n（2）Exceptions are abnormal conditions, and as such should not be used for controlling the flow of execution of the programmes(as demonstrated by example below).\n异常是异常情况，不应该用于程序的流程控制（如下面示例所示）。\ntry&#123;\tfor (int i = 0;; i++)\t&#123;\t\tSystem.out.println(args[i]);\t&#125;&#125;catch (ArrayIndexOutOfBoundsException e)&#123;\t\t// do nothing&#125;\n\n（3）A catch block should not be empty as shown in the example above. Such exceptions are very difficult to track（跟踪）, since there is no logging.\ncatch 块不应该是空的，如上面的示例所示。由于没有日志记录，因此很难跟踪这些异常。\n（4）The name of a custom exception class should end with Exception. It improves the readability of the code. Instead of naming the class InvalidSerial, the class should be named InvalidSerialException.\n自定义异常类的名称应该以 Exception 结尾。它提高了代码的可读性。类不应该命名为 InvalidSerial，而应该命名为 InvalidSerialException。\n（5）When using ARM&#x2F;try-with-resources blocks, if exception gets suppressed by the try-with-resources statement, we can use Throwable#getSuppressed() method.\n当使用 ARM&#x2F;try-with-resources 块时，如果异常被 try-with-resources 语句抑制，我们可以使用 Throwable# getrepression()方法。\n4、Closing Words结束语\nHere,we tried to understand the basics of exception and how to create a custom exception of our own. We learned the best practices while creating a custom exception class and also how to handle（处理） an exception in a reasonable manner.\n在这里，我们尝试理解异常的基本原理，以及如何创建我们自己的自定义异常。我们在创建自定义异常类时学习了最佳实践，以及如何以合理的方式处理异常。\n附录，相关资料 1可与上述转译内容互参Throwable 是所有 Java 中所有异常类的父类，有两种子类：Error和Exception\n1、Error： 表示由 JVM 所侦测到的无法预期的错误，由于这是属于 JVM 层次的严重错误，导致 JVM 无法继续执行，这是不可捕捉到的，无法采取任何恢复的操作，只能显示错误信息。Error 类体系描述了 Java 运行系统中的内部错误以及资源耗尽的情形，应用程序不应该抛出这种类型的对象（一般是由虚拟机抛出）。假如出现这种错误，除了尽力使程序安全退出外，在其他方面是无能为力的。\n2、Exception： 表示可恢复的异常，这是可捕捉到的。Java 提供了两类主要的异常：Runtime Exception 和 checked exception。\n（2-1）checked 异常是经常遇到的，如：IO 异常、SQL 异常。对于这种异常，JAVA 编译器强制要求我们对出现的这些异常进行 catch。所以，面对这种异常只能编写 catch 块去处理。这类异常一般是外部错误，例如试图从文件尾后读取数据等，这并不是程序本身的错误，而是在应用环境中出现的外部错误。\n（2-2）Runtime Exception 也称运行时异常，我们可以不处理。当出现这样的异常时，总是由虚拟机接管。比如：我们从来没有人去处理过 NullPointerException 异常，它就是运行时异常，并且 NullPointerException 还是最常见的异常之一。Runtime Exception 体系包括错误的类型转换、数组越界访问和试图访问空指针等等。如果出现 Runtime Exception，那么一定是程序员的错误。例如：可以通过检查数组下标和数组边界来避免数组越界访问异常。\n出现运行时异常后，系统会把异常一直往上层抛，一直遇到处理代码。如果到最上层还没有处理块，多线程程序就由 Thread.run()抛出，这个线程就退出；如果是单线程就被 main()抛出，整个程序也就退出了。运行时异常是 Exception 的子类，也有一般异常的特点，是可以被 catch 块处理的。只不过往往我们不对他处理罢了。如果不对运行时异常进行处理，那么出现运行时异常之后，要么是线程中止，要么是主程序终止。\n如果不想终止线程或程序，则必须捕捉所有的运行时异常，决不让这个处理线程退出。队列里面出现异常数据了，正常的处理应该是把异常数据舍弃，然后记录日志。不应该由于异常数据而影响下面对正常数据的处理。但并不代表在所有的场景你都应该如此，如果在其它场景，遇到了一些错误，如果退出程序比较好，这时你就可以不太理会运行时异常，或者是通过对异常的处理显式的控制程序退出。异常处理的目标之一就是为了把程序从异常中恢复出来。\n","categories":["文献翻译","java"],"tags":["未标记"]},{"title":"Java-SimpleDateFormat-Example","url":"/4686ddb2-2bb6-11ee-879b-0b2c36f14b2e/","content":"\n\n\n\nJava SimpleDateFormat ExampleJava SimpleDateFormat 使用案例\n\n转译自：https://examples.javacodegeeks.com/java-simpledateformat-example/\n\nIn this example we will show how to use java.text.SimpleDateFormat class so as to convert a Date into a formatted string or a string to a Date.\n在这个案例中，我们将展示如何使用 java.text.SimpleDateFormat 类将 Date 类型转化为字符串或字符串转化为 Date 类型。\nYou can make this conversion using the constructors provided by java.text.SimpleDateFormat class and some patterns, such as dd&#x2F;MM&#x2F;yyyy, dd-MM-yy and so on, so as to format the Date as you wish. We will show more examples of patterns and format symbols in the following sections.\n可以使用 java.text.SimpleDateFormat 类提供的构造方法再结合一些模板字符串来进行上述转化，例如：dd/MM/yyyy, dd-MM-yy 等等，以便按照意愿格式化 Date 类型。下面将展示更多有关模板字符串和格式符的例子。\n译注：将 pattern 及其复数形式均译作「模板字符串」\n1、SimpleDateFormat constructorsSimpleDateFormat 类的构造方法\nThere are four constructors that you can use so as to create a java.text.SimpleDateFormat.\n创建 java.text.SimpleDateFormat 对象可以使用四种构造方法。\n1.1、SimpleDateFormat()The simplest constructor which creates a java.text.SimpleDateFormat with a default pattern of date and a default locale.\n这个默认构造方法生成的 java.text.SimpleDateFormat 对象具有默认模板字符串和默认地区设置。\n1.2、SimpleDateFormat(String pattern)The constructor which creates a java.text.SimpleDateFormat with a given pattern and a default locale.\n这个构造方法生成的 java.text.SimpleDateFormat 对象具有指定模板字符串和默认地区设置。\n1.3、SimpleDateFormat(String pattern, DateFormatSymbols formatSymbols)Constructs a java.text.SimpleDateFormat with the given pattern and specific date format symbols. DateFormatSymbols is a class for encapsulating（封装） localizable date-time formatting data, such as the names of the months, the names of the days of the week, and the time zone data.\n构造一个具有指定模板字符串和具体的日期格式符的 java.text.SimpleDateFormat 对象。DateFormatSymbols 类封装了本地化的 date-time 格式数据，例如月份的名称、星期的名称和时区数据。\n1.4、SimpleDateFormat(String pattern, Locale locale)Constructs a java.text.SimpleDateFormat with the given pattern and a specific locale.\n构造一个具有指定模板字符串和具体地区设置的 java.text.SimpleDateFormat 对象。\n2、Example of SimpleDateFormatSimpleDateFormat 类的例子\nCreate a java class named SimpleDateFormatExample.java with the following code:\n创建一个名为 SimpleDateFormatExample.java 的文件，内容如下：\nimport java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.Locale;public class TestModule &#123;    @Test    public void main() &#123;        Date currentDate = new Date();        SimpleDateFormat format = new SimpleDateFormat();        String DateToStr = format.format(currentDate);        System.out.println(&quot;Default pattern: &quot; + DateToStr);        format = new SimpleDateFormat(&quot;yyyy/MM/dd&quot;);        DateToStr = format.format(currentDate);        System.out.println(DateToStr);        format = new SimpleDateFormat(&quot;dd-M-yyyy hh:mm:ss&quot;);        DateToStr = format.format(currentDate);        System.out.println(DateToStr);        format = new SimpleDateFormat(&quot;dd MMMM yyyy zzzz&quot;, Locale.CHINESE);        DateToStr = format.format(currentDate);        System.out.println(DateToStr);        format = new SimpleDateFormat(&quot;MMMM dd HH:mm:ss zzzz yyyy&quot;, Locale.CHINA);        DateToStr = format.format(currentDate);        System.out.println(DateToStr);        format = new SimpleDateFormat(&quot;E, dd MMM yyyy HH:mm:ss z&quot;);        DateToStr = format.format(currentDate);        System.out.println(DateToStr);        try &#123;            Date strToDate = format.parse(DateToStr);            System.out.println(strToDate);        &#125; catch (ParseException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\nLet’s explain the different formats of SimpleDateFormat class in the above code. Firstly, we create a Date object which is initialized with the current date and time. Then, we create different date formatters with different patterns, such as:\n让我们来解释上述代码中 SimpleDateFormat 类的不同格式。首先，我们创建了一个初始化为当前日期和时间的 Date 对象。然后，我们用不同的模板字符串创建了不同的日期格式器，例如：\nThe default pattern, which shows the date in the form of month&#x2F;day&#x2F;year and the time using the 12-hour clock.\n默认模板字符串展示日期的格式为 month/day/year，时间使用 12 小时制表示。\nyyyy&#x2F;MM&#x2F;dd, which shows the date in the form of year&#x2F;month&#x2F;day. As we can observe（观察）, the pattern for the year has 4 letters, which means that the full form of the year will be used (e.g. 2018). Otherwise（否则） a short or abbreviated（缩写） form is used if available.\nyyyy/MM/dd 将日期展示为 year/month/day，正如我们所观察到的，年份在该模板字符串下有 4 个字符，这意味着将使用一年的完整形式（例如 2018 年）。否则，可以使用简写或缩写的格式。\ndd-M-yyyy hh:mm:ss, which shows the date in the form of date-month-year (the month will be shown in the abbreviated form, as it has only one letter and not two as in the previous case) and futhermore（此外）, it shows the time (hour, minutes and seconds) while the hour is in am&#x2F;pm format.\ndd-M-yyyy hh:mm:ss 将日期展示为 date-month-year 的格式（月份将以缩写形式显示，因为它只有一个字符，而不像以前那样只有两个字符）此外，它还显示时间（小时、分钟和秒），而小时的格式是 am/pm。\ndd MMMM yyyy zzzz, which shows the date and the timezone in full format. We can observe that we also defined the locale of the date&#x2F;time: Locale.ENGLISH or Locale.ITALIAN below.\ndd MMMM yyyy zzzz 以完整格式显示日期和时区。我们可以观察到，还定义了 date/time 为英国地区，或下文中的意大利地区。\n译注：为便于查看效果，已将代码修改为 CHINESE 和 CHINA\nE, dd MMM yyyy HH:mm:ss z, which shows the date, the day name of the week and the time (we can see that the hour is in capital, which means that the hour’s values here are between 0 – 23, as we use the 24-hour clock).\nE, dd MMM yyyy HH:mm:ss z 显示了日期、星期几和时间（我们可以看到小时用大写，这意味着小时的值在 0-23 之间，因为我们使用 24 小时制）。\nYou may notice that there is a slight but basic difference to the followings:\n你可能会注意到下面这些细微但却基本的区别：\nmm: representes the minutes.\nmm：代表「分钟」\nMM: represents the Month.\nMM：代表「月份」\ndd: represents the day.\ndd：代表「日」\nDD: represents the day in year (e.g. 189 out of 365).\nDD：代表当年中的第几天（例如 365 天中的第 189 天）\nhh: represents the hour’s value using the 12-hour clock.\nhh：代表使用 12 小时制时的小时数\nHH: represents the hour’s value using the 24-hour clock.\nHH：代表使用 24 小时制时的小时数\nUsing all those formatters, we format dates as strings.\n使用所有这些格式器，可让我们将 Date 格式化为字符串。\nFinally, we show a reverse example, where we parse a string into date, using the parse() method.\n最后，我们展示了一个相反的案例，使用 parse() 方法将字符串解析为 Date。\nFor a detailed explanation of the different existing patterns you can visit the java doc SimpleDateFormat.\n对于不同现有模板字符串的详细解释，可以访问 SimpleDateFormat 类的文档。\nIf we run the above code, we will have the following results:\n如果我们运行上述代码，我们将得到以下结果:\nDefault pattern: 18-8-4 上午11:172018/08/0404-8-2018 11:17:0304 八月 2018 China Standard Time八月 04 11:17:03 中国标准时间 2018星期六, 04 八月 2018 11:17:03 CSTSat Aug 04 11:17:03 CST 2018\n","categories":["文献翻译","java"],"tags":["未标记"]},{"title":"Java-optional-parameters","url":"/468704c1-2bb6-11ee-879b-0b2c36f14b2e/","content":"\n\n\n\nJava optional parametersJava 中的可选参数\n\n转译自：https://www.javacodegeeks.com/2018/11/java-optional-parameters.html\n\nWhen you design a method in a Java class, some parameters may be optional for its execution. No matter it is inside a DTO, a fat model domain object, or a simple stateless service class, optional method parameters are common.\n在 Java 类中设计方法时，一些参数可能是可选的。无论是 DTO、胖模型域对象还是简单的无状态服务类，可选的方法参数都是常见的。\nFrom this article you will learn how to handle optional parameters in Java. We’ll focus on regular method, class constructors with optional fields, and quickly look at bad practices of the discussed topic. We’ll stop for a moment to look at Java 8 Optional and assess（vt. 评定；估价） if it fits our needs.\n从本文中，你将了解如何在 Java 中处理可选参数。 我们将重点讨论常规方法、带有可选字段的类构造函数，并快速查看所讨论主题的不良实践。我们会停下来看看 Java 8 中的 Optional 类，看看它是否符合我们的需求。\nLet’s get started.\n让我们开始吧。\n1. Optional method parameters可选的方法参数\nYou can tackle（vt. 处理；抓住） Java optional parameters in method in several different ways. I’ll walk you through from the simplest to more complex.\n你可以用几种不同的方法处理方法中的 Java 可选参数。我将引导你（理解）从最简单到更复杂的（情况）。\n1.1 @Nullable annotation@Nullable 注解\nWhy just don’t pass the null around? It’s a simple solution which doesn’t require any extra work. You don’t have any object which is required as one of method’s parameters? No problem. Just pass the null and the compiler is happy.\n为什么不传递 null 呢？这是一个简单的答案，不需要任何额外的工作。你没有需要作为方法参数之一的对象吗？没有问题。把 null 传递给编译器就好了。\nThe issue here is readability. How does the programmer who calls a method knows if he can safely pass the null? For which parameters nulls are acceptable and which are mandatory?\n这里的问题是可读性。 调用方法的程序员如何知道是否可以安全地传递 null？哪些参数是可接受 null 的，哪些是强制的？\nTo make it clear that the null is a valid input, you can use a @Nullable annotation.\n为了说明 null 是一个有效的输入，你可以使用@Nullable 注解。\nUser createUser(String name, @Nullable Email email) &#123;   // ...&#125;\n\nDon’t you agree this method declaration is self-explanatory?\n你不同意这个方法声明是不言自明的吗？\nWhile simple, the issue with null passing approach is that it can easily get out of control. The team may quickly start overusing it and make the code base hard to maintain with plenty of null check conditions.\n虽然很简单，但是 null 传递方法的问题是它很容易失控。团队可能很快就会开始 过度使用它，并在大量的 null 检查条件下使代码库难以维护。\nThere are other options, though.\n不过，还有其他选择。\n1.2. Optional listsInstead of null, we can sometime create an empty representation（n. 代表；表现） of a class. Think about Java collections. If a method accepts a list or a map, you should never use nulls as the input.\n有时我们可以创建一个类的空表示，而不是 null。想想 Java 集合。如果方法接受 List 或 Map（作为参数），则永远不应该使用 null 作为（参数）输入。\nAn empty collection is always better than null because in majority of cases it doesn’t require any special treatment.\n空集合总是比 null 好，因为在大多数情况下，它不需要任何特殊处理。\nYou may wonder why you should waste memory to create empty collections. After all, null doesn’t cost you anything.\n你可能想知道为什么要浪费内存来创建空集合。毕竟，null 不需要任何代价。\nYour doubts are justified. Fortunately, there’s a simple solution.\n你的怀疑是有道理的。幸运的是，有一个简单的解决方案。\nYou shouldn’t create a new instance of a collection whenever you need an empty representative. Reuse the same instance across the code base.\n在需要空代表时，不应该创建集合的新实例。在代码库中重复使用相同的实例。\nAnd you know what? Java already has empty instances of all collections which you can use. You’ll find them in the Collections utility class.\n你知道吗？Java 已经有了可以使用的所有集合的空实例。你可以在 Collections 实用程序类中找到它们。\nUser createUser(String name, List&lt;Rights&gt; rights) &#123;   // ...&#125;\n\nimport java.util.Collections;// ...create(&quot;bob&quot;, Collections.emptyList());\n\n1.3. Null object patternNull 对象模式\nThe concept of empty collections also applies to other classes. An empty collection is just a regular collection with zero elements. By the same token, you can think about other objects in your applications.\n空集合的概念也适用于其他类。空集合只是一个包含零元素的常规集合。同样，你可以考虑应用程序中的其他对象。\nThe Null object is a special instance of a class which represents missing value. If some method expects an object as a parameter, you can always pass the Null object representation without worry it will cause an unexpected exception at the runtime.\nNull 对象是表示缺失值的类的特殊实例。 如果某些方法希望将对象作为参数，那么总是可以传递 Null 对象表示，而不用担心这会在运行时导致意外异常。\nYou can implement the Null object pattern in two ways.\n你可以通过两种方式实现 Null 对象模式。\nFor simple value objects, a default instance with predefined values assigned to properties is enough. Usually, you expose this Null object as a constant so you can reuse it multiple times. For instance:\n对于简单的值对象，为属性指定预定义值的默认实例就足够了。通常，你将这个 Null 对象作为常量公开，以便可以多次重用它。例如：\npublic class User &#123;   public static final User EMPTY = new User(&quot;&quot;, Collections.emptyList());   private final String name;   private final List&lt;Rights&gt; rights;   public User(String name, List&lt;Rights&gt; rights) &#123;       Objects.requireNonNull(name);       Objects.requireNonNull(rights);       this.name = name;       this.rights = rights;   &#125;   // ...&#125;\n\nIf your Null object also needs to mimic some behavior exposed via methods, a simple instance may not work. In that case, you should extend the class and override such methods.\n如果你的 Null 对象也需要模仿一些通过方法暴露的行为，那么简单的实例就不会起作用了。在这种情况下，你应该扩展类并覆盖这些方法。\nHere is an example which extends the previous one:\n下面是对上一个例子的扩展：\npublic class AnonymousUser extends User &#123;   public static final AnonymousUser INSTANCE = new AnonymousUser();   private AnonymousUser() &#123;      super(&quot;&quot;, Collections.emptyList());   &#125;   @Override   public void changeName(String newName) &#123;       throw new AuthenticationException(&quot;Only authenticated user can change the name&quot;);   &#125;&#125;\n\nA dedicated Null object class allows you to put many corner cases in a single place which makes maintenance much more pleasant.\n一个专用的 Null 对象类允许你将许多偏僻个案放在一个地方，这使得维护更加愉快。\n1.4. Method overloading方法重载\nIf your design a method with optional parameters, you can expose（vt. 揭露，揭发；使曝光；显示） overloaded versions of that method. Each method should accept only parameters which are required.\n如果你设计的方法具有可选参数，则可以公开该方法的重载版本。每个方法只能接受需要的参数。\nWith this approach, you don’t have to expect that the caller will provide default values for optional parameters. You pass the defaults on your own inside overloaded method. In other words, you hide the default values for optional parameters from method’s callers.\n使用这种方法，你不必期望调用方会为可选参数提供默认值。你可以在重载方法中自行传递默认值。换句话说，对方法调用者隐藏可选参数的默认值。\nUser createUser(String name) &#123;   this.createUser(name, Email.EMPTY);&#125;User createUser(String name, Email email) &#123;   Objects.requireNonNull(name);   Objects.requireNonNull(rights);   // ...&#125;\n\nThe overloaded methods can call each other but it’s not mandatory. You can implement each method independently if it’s more convenient. However, usually you validate all parameters and put the logic inside the method with the longest parameter list.\n重载的方法可以相互调用，但不是强制的。如果方便的话，可以单独实现每个方法。但是，通常你要验证所有参数，并将逻辑放在具有最长参数列表的方法中。\nIt’s worth mentioning that method overloading is widely used inside the standard Java library. When you learn how to design APIs, learn from people with greater experience.\n值得一提的是，方法重载在标准 Java 库中被广泛使用。当你学习如何设计 API 时，请向具有更丰富经验的人学习。\n1.5. Parameter Object pattern参数对象模式\nThe majority of developers agree that when the list of method parameters grows too long it become hard to read. Usually, you handle the issue with the Parameter Object pattern. The parameter object is a named container class which groups all method parameters.\n大多数开发人员都同意，当方法参数列表增长得太长时，就会变得难以读取。通常，你使用参数对象模式来处理这个问题。参数对象是一个命名容器类，它对所有方法参数进行分组。\nDoes it solve the problem of optional method parameters?\n是否解决了方法参数可选的问题?\nNo. It doesn’t.\n不。它不是。\nIt just moves the problem to the constructor of the parameter object.\n它只是将问题移动到参数对象的构造函数中。\nLet’s see how do we solve this more general problem with …\n让我们看看如何解决这个更普遍的问题。\n2. Optional constructor parameters可选的构造函数参数\nIn the perspective（n. 观点） of the problem with optional parameters, simple constructors don’t differ from regular member methods. You can successfully use all the techniques we’ve already discussed also with constructors.\n对于可选参数的问题，简单构造函数与常规成员方法没有区别。你可以成功地使用我们已经与构造函数讨论过的所有技术。\nHowever, when the list of constructor parameters is getting longer and many of them are optional parameters, applying constructor overloading may seem cumbersome.\n然而，当构造函数参数的列表越来越长，而且其中许多参数是可选参数时，应用构造函数重载可能看起来很麻烦。\nIf you agree, you should check out the Builder pattern.\n如果你同意，你应该检查构建器模式。\n2.1. Builder pattern构建器模式\nLet’s consider a class with multiple optional fields:\n让我们考虑一个具有多个可选字段的类：\nclass ProgrammerProfile &#123;   // required field   private final String name;   // optional fields   private final String blogUrl;   private final String twitterHandler;   private final String githubUrl;   public ProgrammerProfile(String name) &#123;       Objects.requireNonNull(name);       this.name = name;       // other fields assignment...   &#125;   // getters&#125;\n\nIf you created a constructors to cover all possible combination with optional parameters, you would end up with a quite overwhelming list.\n如果你创建了一个构造函数来涵盖所有可能的与可选参数的组合，那么你将得到一个相当庞大的列表。\nHow to avoid multiple constructors? Use a builder class.\n如何避免多个构造函数？使用构建器类。\n译注：关于构建器的内容，可以参考《Effective-Java-3rd-edition》，Item-2: Consider-a-builder-when-faced-with-many-constructor-parameters（Item-2）\nYou usually implement the builder as an inner class of the class it suppose to build. That way, both classes have access to their private members.\n你通常将构建器实现为它要构建的类的内部类。这样，两个类都可以访问它们的私有成员。\nTake a look at a builder for the class from the previous example:\n看看前面例子中类的构建器：\nclass ProgrammerProfile &#123;   // fields, getters, ...   private ProgrammerProfile(Builder builder) &#123;       Objects.requireNonNull(builder.name);       name = builder.name;       blogUrl = builder.blogUrl;       twitterHandler = builder.twitterHandler;       githubUrl = builder.githubUrl;   &#125;   public static Builder newBuilder() &#123;       return new Builder();   &#125;   static final class Builder &#123;       private String name;       private String blogUrl;       private String twitterHandler;       private String githubUrl;       private Builder() &#123;&#125;       public Builder withName(String val) &#123;           name = val;           return this;       &#125;       public Builder withBlogUrl(String val) &#123;           blogUrl = val;           return this;       &#125;       public Builder withTwitterHandler(String val) &#123;           twitterHandler = val;           return this;       &#125;       public Builder withGithubUrl(String val) &#123;           githubUrl = val;           return this;       &#125;       public ProgrammerProfile build() &#123;           return new ProgrammerProfile(this);       &#125;   &#125;&#125;\n\nInstead of a public constructor, we only expose one single static factory method for the inner builder class. The private constructor (which the builder calls in the build() method) uses a builder instance to assign all fields and verifies if all required values are present.\n我们只为内部构建器类公开一个静态工厂方法，而不是一个公共构造函数。私有构造函数(构建器在 build()方法中调用)使用一个构建器实例来分配所有字段，并验证是否存在所有需要的值。\nIt’s a pretty simple technique once you think about it.\n这是一个非常简单的技巧。\nThe client code of that builder which sets only a selected optional parameter may look as follows:\n该生成器的客户端代码只设置一个选定的可选参数，其代码如下:\nProgrammerProfile.newBuilder()       .withName(&quot;Daniel&quot;)       .withBlogUrl(&quot;www.dolszewski.com/blog/&quot;)       .build();\n\nWith the builder, you can create all possible combinations with optional parameters of the object.\n使用构建器，你可以使用对象的可选参数创建所有可能的组合。\n2.2. Compile time safe class builder编译时安全类构建器\nUnfortunately, just by look at the methods of the builder from the previous paragraph you can’t really tell which parameters are optional and which are required. What is more, without knowing you can omit the required parameters by accident.\n不幸的是，仅通过查看前一段中构建器的方法，你无法真正判断哪些参数是可选的，哪些是必需的。更重要的是，如果不知道你可以意外地忽略所需的参数。\nCheck out the following example of the incorrectly used builder:\n查看以下错误使用的构建器示例：\nProgrammerProfile.newBuilder()       .withBlogUrl(&quot;www.dolszewski.com/blog/&quot;)       .withTwitterHandler(&quot;daolszewski&quot;)       .build();\n\nThe compiler won’t report any error. You’ll realize the problem with the missing required parameter only at the runtime.\n编译器不会报告任何错误。只有在运行时，你才会意识到缺少必需参数的问题。\nSo how do you tackle the issue?\n那么如何解决这个问题呢？\nYou need to slightly modify the builder factory method so that you can call it only with required parameters and left builder methods only for optional parameters.\n你需要稍微修改 builder factory 方法，以便只能使用必需的参数调用它，而仅对可选参数使用 left builder 方法。\nHere’s all you have to change:\n以下是你需要改动的：\nclass ProgrammerProfile &#123;   // ...   public static Builder newBuilder(String name) &#123;      return new Builder(name);   &#125;   public static final class Builder &#123;      private final String name;      // ...      private Builder(String name) &#123;          this.name = name;      &#125;      // ...   &#125;&#125;\n\n2.3. Builder class generation构建器类生成\nYou may think that builders require hell of a lot of code.\n你可能认为构建器需要大量的代码。\nDon’t worry.\n不必担心。\nYou don’t have to type all that code on your own. All popular Java IDEs have plugins which allow to generate class builders. IntelliJ users can check the InnerBuilder plugin, while Eclipse fans can take a look at Spart Builder Generator. You can also find alternative plugins in the official repositories.\n你不需要自己输入所有的代码。所有流行的 Java IDE 都有允许生成类构建器的插件。IntelliJ 用户可以查看 InnerBuilder 插件，而 Eclipse 的粉丝可以查看 Spart Builder 生成器。你还可以在官方存储库中找到其他插件。\nIf you use the project Lombok, it also simplify working with class builders. You can check this short introduction to Lombok builders if you need a place to start.\n如果你使用 Project Lombok，它还可以简化与类构建器的工作。如果你需要一个开始的地方，可以查看 Lombok 构建器的简短介绍。\n3. Java optional parameters anti-patternsJava 可选参数的反模式\nWhile browsing the web in search for approaches to work with Java optional parameters, you can find a few additional suggestions than we already covered. Let me explain why you should consider them as wrong approaches.\n在浏览 web 以寻找使用 Java 可选参数的方法时，你可以找到一些我们已经介绍过的其他建议。让我解释一下为什么你应该认为它们是错误的方法。\n3.1. MapsTechnically speaking, method’s input is a set of key-value pairs. In Java, we have a standard built-in data structure which matches this description – the Map.\n从技术上讲，方法的输入是一组 key-value 对。在 Java 中，我们有一个标准的内置数据结构来匹配这个描述，它就是 Map。\nThe compile won’t prevent you from using HashMap&lt;String, Object&gt; as a container for all optional method parameters but your common sense should.\n编译器不会阻止你使用 HashMap&lt;String, Object&gt;作为所有可选方法参数的容器，这也是你应该具备的常识。\nAlthough you can put anything in such HashMap, it’s wrong idea. This approach is hard to understand, unreadable and will quickly become your maintenance nightmare.\n尽管你可以将任何内容放入这样的 HashMap 中，但这种想法是错误的。这种方法很难理解、不可读，并且很快就会成为你的维护噩梦。\nStill not convinced（v. 使确信）?\n还不相信吗？\nYou should definitely consider switching your career to a JavaScript developer. It’s much easier to cry in the company.\n你绝对应该考虑转行到 JavaScript 开发人员。（和这个相比），在公司里哭要容易得多。\n3.2. Java varargsJava 可变参数\nJust to be clear, there’s absolutely nothing wrong in using Java varargs. If you don’t know with how many arguments your method will be called, varargs is a perfect fit.\n需要明确的是，使用 Java 的可变参数绝对没有什么错。如果不知道方法将被调用多少个参数，那么可变参数非常适合。\nBut using varargs as a container for a single value, which might be present or not, is a misuse. Such declaration allows to call a method with more optional values than expected. We discussed much more descriptive approaches for handling a single optional parameters.\n但是使用可变参数作为单个值的容器（可能存在也可能不存在）是一种误用。这样的声明允许调用一个方法比预期更多的可选值。我们讨论了更多的描述方法来处理单一的可选参数。\n3.3. Why not Optional as method argument?为什么不将 Optional 对象作为方法参数呢?\nFinally, the most controversial approach – Java 8 Optional as a method input. I’ve already written a post about Optional use cases in which I also covered method parameters. Let me extend what you can find there.\n最后，最具争议的方法就是将 Java 8 的 Optional 对象作为方法输入。我已经写了一篇关于 Optional 用例的文章，其中也涉及了方法参数。我把你能找到的扩展一下。\nMemory usage内存使用情况\nWhen you create an instance of the Optional class, you have to allocate the memory for it. While the empty optional instance accessed with Optional.empty() is a reusable singleton (just like empty collections we’ve already discussed), non empty instances will occupy the operating memory.\n当你创建 Optional 类的实例时，你必须为它分配内存。虽然使用 Optional.empty()访问的空 Optional 实例是可重用的单例（就像我们已经讨论过的空集合一样），但是非空实例将占用操作内存。\nWrapping objects using Optional factory methods just for the purpose of calling a method which will immediately unwrap them doesn’t make sense if you compare this approach with other possibilities.\n如果你将这种方法与其他可能的方法进行比较，那么仅为了调用将立即展开它们的方法而使用可选工厂方法包装对象是没有意义的。\nYet, nowadays Garbage Collectors handle short-lived objects very well. The memory allocation isn’t a big deal. Do we have any other cons?\n然而，现在垃圾收集器可以很好地处理短期对象。内存分配不是什么大问题。我们还有其他缺点吗?\nCoding with reader in mind为读者编写代码\nWhat about code readability?\n那么代码可读性呢?\ncreateProfile(&quot;Daniel&quot;, Optional.of(&quot;www.dolszewski.com/blog/&quot;),       Optional.of(&quot;daolszewski&quot;), Optional.of(&quot;https://github.com/danielolszewski&quot;));\n\nMaybe it’s just a matter of personal preference but for many developers multiple Optional factory calls are distracting. The noise in the code for the reader. But again, it’s just a matter of taste. Let’s find something more convincing.\n也许这只是个人喜好的问题，但是对于许多开发人员来说，多个 Optional 工厂调用会分散他们的注意力。代码中的噪声是为读者准备的。但这只是品味的问题。让我们找些更有说服力的。\nJava language architect opinionJava 语言架构师看法\n译注：原文的 language 拼写错误\nBrian Goetz, who is Java language architect at Oracle once stated that Optional was added to the standard library with methods’ results in mind, not their inputs.\nOracle 的 Java 语言架构师 Brian Goetz 曾经说过，将 Optional 添加到标准库时考虑的是方法的结果，而不是方法的输入。\nBut software developers are rebels and don’t like listening to authorities. This argument may also seems weak. We have to go deeper.\n但软件开发者是叛逆者，不喜欢听当局的。这一论点似乎也站不住脚。我们必须更深入。\nDoes Optional solve optional parameter problem?可选是否解决可选参数问题？\nIf you have a method declaration like this:\n如果你有这样的方法声明：\ndoSomethingWith(Optional&lt;Object&gt; parameter);\n\nHow many possible inputs should you expect?\n你应该期望多少可能的输入？\nThe parameter can be either a wrapped value or the empty optional instance. So the answer is 2, right?\n参数可以是包装类的值，也可以是空的 Optional 实例。所以答案是 2，对吧？\nWrong.\n错。\nThe real answer is 3 because you can also pass the null as the argument. You should have a limited trust to inputs when you don’t know who will be the caller of your API.\n真正的答案是 3，因为你也可以传递 null 作为参数。当你不知道谁将是 API 的调用者时，你应该对输入具有有限的信任。\nIn that case, before processing the parameter you should check if the Optional isn’t equal to the null and then if the value is present. Quite complicated, don’t you agree?\n在这种情况下，在处理参数之前，你应该检查 Optional 是否等于 null，然后检查值是否存在。相当复杂，你同意吗?\nI pretty sure I have not exhausted the topic yet. As this is one of potential holy wars of Java programming, you should form your own opinion. If you want to add something to the list of arguments against Optional as a method parameter, please share your thoughts in the comments. It’s more than welcome.\n我敢肯定我还没有穷尽这个话题。由于这是 Java 编程的潜在圣战之一，你应该形成自己的观点。如果你想在可选参数的参数列表中添加一些内容，请在评论中分享你的想法。非常欢迎。\nConclusion结论\nLet’s recap what we’ve learned. Java doesn’t have a possibility to set a default value to method parameters. The language provides us we many other alternatives for handling optional parameters.\n让我们回顾一下我们所学到的。Java 不可能为方法参数设置默认值。该语言为我们提供了许多处理可选参数的其他选择。\nThese alternatives include the @Nullable annotation, null objects, method overloading, and the Parameter Object pattern. We also familiarize with class builders for objects with multiple optional fields. Lastly, we reviewed common bad practices and potential misuses.\n这些替代方法包括@Nullable 注释、null 对象、方法重载和参数对象模式。我们还熟悉具有多个可选字段的对象的类构建器。最后，我们回顾了常见的不良实践和潜在的误用。\nIf you find the article helpful, I’ll be grateful for sharing it with your followers. I’d also love to know your thoughts, all comments are welcome.\n如果你觉得这篇文章对你有帮助，我会很感激与你的追随者分享它。我也想知道你的想法，欢迎所有的意见。\n","categories":["文献翻译","java"],"tags":["未标记"]},{"title":"volatile-变量使用指南","url":"/468704c0-2bb6-11ee-879b-0b2c36f14b2e/","content":"\n\n\n\nGuidelines for using volatile variablesvolatile 变量使用指南\n\n原文：https://www.ibm.com/developerworks/java/library/j-jtp06197/index.html\n\n\n参考翻译：https://www.ibm.com/developerworks/cn/java/j-jtp06197.html\n\nVolatile variables in the Java language can be thought of as “synchronized lite”; they require less coding to use than synchronized blocks and often have less runtime overhead, but they can only be used to do a subset of the things that synchronized can. This article presents some patterns for using volatile variables effectively – and some warnings about when not to use them.\nJava 语言中的 volatile 变量可以被看作是一种「程度较轻的 synchronized」；与 synchronized 块相比，volatile 变量所需的编码较少，并且运行时开销也较少，但是它所能实现的功能也仅是 synchronized 的一部分。本文介绍几种有效使用 volatile 变量的模式，并强调几种不适合使用 volatile 变量的情形。\nLocks offer two primary features: mutual exclusion and visibility. Mutual exclusion means that only one thread at a time may hold a given lock, and this property can be used to implement protocols for coordinating access to shared data such that only one thread at a time will be using the shared data. Visibility is more subtle and has to do with ensuring that changes made to shared data prior to releasing a lock are made visible to another thread that subsequently acquires that lock – without the visibility guarantees provided by synchronization, threads could see stale or inconsistent values for shared variables, which could cause a host of serious problems.\n锁提供了两种主要特性：互斥和可见性。互斥一次只允许一个线程持有某个特定的锁，因此可使用该特性实现对共享数据的协调访问协议，一次就只有一个线程能够使用该共享数据。可见性要更加复杂一些，它必须确保释放锁之前对共享数据做出的更改对于随后获得该锁的另一个线程是可见的：如果没有同步机制提供的这种可见性保证，线程看到的共享变量可能是修改前的值或不一致的值，这将引发许多严重问题。\nVolatile variablesVolatile 变量\nVolatile variables share the visibility features of synchronized, but none of the atomicity features. This means that threads will automatically see the most up-to-date value for volatile variables. They can be used to provide thread safety, but only in a very restricted set of cases: those that do not impose constraints between multiple variables or between a variable’s current value and its future values. So volatile alone is not strong enough to implement a counter, a mutex, or any class that has invariants that relate multiple variables (such as “start &lt;&#x3D;end”).\nVolatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。这就是说线程能够自动发现 volatile 变量的最新值。Volatile 变量可用于提供线程安全，但是只能应用于非常有限的场景：多个变量之间或者某个变量的当前值与修改后值之间没有约束。因此，单独使用 volatile 还不足以实现计数器、互斥锁或任何具有与多个变量相关的不变式（Invariants）的类（例如「start &lt;&#x3D; end」）。\nYou might prefer to use volatile variables instead of locks for one of two principal reasons: simplicity or scalability. Some idioms are easier to code and read when they use volatile variables instead of locks. In addition, volatile variables (unlike locks) cannot cause a thread to block, so they are less likely to cause scalability problems. In situations where reads greatly outnumber writes, volatile variables may also provide a performance advantage over locking.\n出于简易性或可伸缩性的考虑，你可能倾向于使用 volatile 变量而不是锁。当使用 volatile 变量而非锁时，某些习惯用法（idiom）更加易于编码和阅读。此外，volatile 变量不会像锁那样造成线程阻塞，因此也很少造成可伸缩性问题。在某些情况下，如果读操作远远大于写操作，volatile 变量还可以提供优于锁的性能优势。\nConditions for correct use of volatile正确使用 volatile 变量的条件\nYou can use volatile variables instead of locks only under a restricted set of circumstances. Both of the following criteria must be met for volatile variables to provide the desired thread-safety:\n你只能在有限的一些情形下使用 volatile 变量替代锁。要使 volatile 变量提供理想的线程安全，必须同时满足下面两个条件：\n\nWrites to the variable do not depend on its current value.\n\n对变量的写操作不依赖于当前值。\n\nThe variable does not participate in invariants with other variables.\n\n该变量没有包含在具有其他变量的不变式中。\nBasically, these conditions state that the set of valid values that can be written to a volatile variable is independent of any other program state, including the variable’s current state.\n实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。\nThe first condition disqualifies volatile variables from being used as thread-safe counters. While the increment operation (x++) may look like a single operation, it is really a compound read-modify-write sequence of operations that must execute atomically – and volatile does not provide the necessary atomicity. Correct operation would require that the value of x stay unchanged for the duration of the operation, which cannot be achieved using volatile variables. (However, if you can arrange that the value is only ever written from a single thread, then you can ignore the first condition.)\n第一个条件的限制使 volatile 变量不能用作线程安全计数器。虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由读取、修改、写入操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。实现正确的操作需要使 x 的值在操作期间保持不变，而 volatile 变量无法实现这点。（然而，如果将值调整为只从单个线程写入，那么可以忽略第一个条件。）\nMost programming situations will fall afoul of either the first or second condition, making volatile variables a less commonly applicable approach to achieving thread-safety than synchronized. Listing 1 shows a non-thread-safe number range class. It contains an invariant – that the lower bound is always less than or equal to the upper bound.\n大多数编程情形都会与这两个条件的其中之一冲突，使得 volatile 变量不能像 synchronized 那样普遍适用于实现线程安全。清单 1 显示了一个非线程安全的数值范围类。它包含了一个不变式：下界总是小于或等于上界。\nListing 1. Non-thread-safe number range class\n清单 1. 非线程安全的数值范围类\n@NotThreadSafepublic class NumberRange &#123;    private int lower, upper;    public int getLower() &#123; return lower; &#125;    public int getUpper() &#123; return upper; &#125;    public void setLower(int value) &#123;        if (value &gt; upper)            throw new IllegalArgumentException(...);        lower = value;    &#125;    public void setUpper(int value) &#123;        if (value &lt; lower)            throw new IllegalArgumentException(...);        upper = value;    &#125;&#125;\n\nBecause the state variables of the range are constrained in this manner, making the lower and upper fields volatile would not be sufficient to make the class thread-safe; synchronization would still be needed. Otherwise, with some unlucky timing, two threads executing setLower and setUpper with inconsistent values could leave the range in an inconsistent state. For example, if the initial state is (0, 5), and thread A calls setLower(4) at the same time that thread B calls setUpper(3), and the operations are interleaved just wrong, both could pass the checks that are supposed to protect the invariant and end up with the range holding (4, 3) – an invalid value. We need to make the setLower() and setUpper() operations atomic with respect to other operations on the range – and making the fields volatile can’t do this for us.\n这种方式限制了范围的状态变量，因此将 lower 和 upper 字段定义为 volatile 类型不能够充分实现类的线程安全；从而仍然需要使用同步。否则，如果凑巧两个线程在同一时间使用不一致的值执行 setLower 和 setUpper 的话，则会使范围处于不一致的状态。例如，如果初始状态是 (0, 5)，同一时间内，线程 A 调用 setLower(4) 并且线程 B 调用 setUpper(3)，显然这两个操作交叉存入的值是不符合条件的，那么两个线程都会通过用于保护不变式的检查，使得最后的范围值是 (4, 3)：一个无效值。至于针对范围的其他操作，我们需要使 setLower() 和 setUpper() 操作原子化：而将字段定义为 volatile 类型是无法实现这一目的的。\nPerformance considerations性能考虑\nThe primary motivation for using volatile variables is simplicity: In some situations, using a volatile variable is just simpler than using the corresponding locking. A secondary motivation for using volatile variables is performance: In some situations, volatile variables may be a better-performing synchronization mechanism than locking.\n使用 volatile 变量的主要原因是其简易性：在某些情形下，使用 volatile 变量要比使用相应的锁简单得多。使用 volatile 变量次要原因是其性能：某些情况下，volatile 变量同步机制的性能要优于锁。\nIt is exceedingly difficult to make accurate, general statements of the form “X is always faster than Y,” especially when it comes to intrinsic JVM operations. (For example, the VM may be able to remove locking entirely in some situations, which makes it hard to talk about the relative cost of volatile vs. synchronized in the abstract.) That said, on most current processor architectures, volatile reads are cheap – nearly as cheap as nonvolatile reads. Volatile writes are considerably more expensive than nonvolatile writes because of the memory fencing required to guarantee visibility but still generally cheaper than lock acquisition.\n很难做出准确、全面的评价，例如「X 总是比 Y 快」，尤其是对 JVM 内在的操作而言。（例如，某些情况下 VM 也许能够完全删除锁机制，这使得我们难以抽象地比较 volatile 和 synchronized 的开销。）就是说，在目前大多数的处理器架构上，volatile 读操作开销非常低：几乎和非 volatile 读操作一样。而 volatile 写操作的开销要比非 volatile 写操作多很多，因为要保证可见性需要实现内存界定（Memory Fence），即便如此，volatile 的总开销仍然要比锁获取低。\nUnlike locking, volatile operations will never block, so volatiles offer some scalability advantages over locking in the cases where they can be used safely. In cases where reads greatly outnumber writes, volatile variables can often reduce the performance cost of synchronization compared to locking.\nvolatile 操作不会像锁一样造成阻塞，因此，在能够安全使用 volatile 的情况下，volatile 可以提供一些优于锁的可伸缩特性。如果读操作的次数要远远超过写操作，与锁相比，volatile 变量通常能够减少同步的性能开销。\nPatterns for using volatile correctly正确使用 volatile 的模式\nMany concurrency experts tend to guide users away from using volatile variables at all, because they are harder to use correctly than locks. However, some well-defined patterns exist, which, if you follow them carefully, can be used safely in a wide variety of situations. Always keep in mind the rules about the limits of where volatile can be used – only use volatile for state that is truly independent of everything else in your program – and this should keep you from trying to extend these patterns into dangerous territory.\n很多并发性专家事实上往往引导用户远离 volatile 变量，因为使用它们要比使用锁更加容易出错。然而，如果谨慎地遵循一些良好定义的模式，就能够在很多场合内安全地使用 volatile 变量。要始终牢记使用 volatile 的限制：只有在状态真正独立于程序内其他内容时才能使用 volatile，这条规则能够避免将这些模式扩展到不安全的用例。\nPattern #1: status flags模式 #1：状态标志\nPerhaps the canonical use of volatile variables is simple boolean status flags, indicating that an important one-time life-cycle event has happened, such as initialization has completed or shutdown has been requested.\n也许实现 volatile 变量的规范使用仅仅是使用一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。\nMany applications include a control construct of the form, “While we’re not ready to shut down, do more work,” as shown in Listing 2:\n很多应用程序包含了一种控制结构，形式为「在还没有准备好停止程序时再执行一些工作」，如清单 2 所示：\nListing 2. Using a volatile variable as a status flag\n清单 2. 将 volatile 变量作为状态标志使用\nvolatile boolean shutdownRequested;……public void shutdown() &#123; shutdownRequested = true; &#125;public void doWork() &#123;    while (!shutdownRequested) &#123;        // do stuff    &#125;&#125;\n\nIt is likely that the shutdown() method is going to be called from somewhere outside the loop – in another thread – and as such, some form of synchronization is required to ensure the proper visibility of the shutdownRequested variable. (It might be called from a JMX listener, an action listener in the GUI event thread, through RMI, through a Web service, and so on.) However, coding the loop with synchronized blocks would be much more cumbersome than coding it with a volatile status flag as in Listing 2. Because volatile simplifies the coding, and the status flag does not depend on any other state in the program, this is a good use for volatile.\n很可能会从循环外部调用 shutdown() 方法：即在另一个线程中。因此，需要执行某种同步来确保正确实现 shutdownRequested 变量的可见性。（可能会从 JMX 侦听程序、GUI 事件线程中的操作侦听程序、通过 RMI 、通过一个 Web 服务等调用）。然而，使用 synchronized 块编写循环要比使用清单 2 所示的 volatile 状态标志编写麻烦很多。由于 volatile 简化了编码，并且状态标志并不依赖于程序内任何其他状态，因此此处非常适合使用 volatile。\nOne common characteristic of status flags of this type is that there is typically only one state transition; the shutdownRequested flag goes from false to true and then the program shuts down. This pattern can be extended to state flags that can change back and forth, but only if it is acceptable for a transition cycle (from false to true to false) to go undetected. Otherwise, some sort of atomic state transition mechanism is needed, such as atomic variables.\n这种类型的状态标记的一个公共特性是：通常只有一种状态转换；shutdownRequested 标志从 false 转换为 true，然后程序停止。这种模式可以扩展到来回转换的状态标志，但是只有在转换周期不被察觉的情况下才能扩展（从 false 到 true，再转换到 false）。此外，还需要某些原子状态转换机制，例如原子变量。\nPattern #2: one-time safe publication模式 #2：一次性安全发布\nThe visibility failures that are possible in the absence of synchronization can get even trickier to reason about when writing to object references instead of primitive values. In the absence of synchronization, it is possible to see an up-to-date value for an object reference that was written by another thread and still see stale values for that object’s state. (This hazard is the root of the problem with the infamous double-checked-locking idiom, where an object reference is read without synchronization, and the risk is that you could see an up-to-date reference but still observe a partially constructed object through that reference.)\n缺乏同步会导致无法实现可见性，这使得确定何时写入对象引用而不是原语值变得更加困难。在缺乏同步的情况下，可能会遇到某个对象引用的更新值（由另一个线程写入）和该对象状态的旧值同时存在。（这就是造成著名的双重检查锁定（double-checked-locking）问题的根源，其中对象引用在没有同步的情况下进行读操作，产生的问题是你可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象）。\nOne technique for safely publishing an object is to make the object reference volatile. Listing 3 shows an example where during startup, a background thread loads some data from a database. Other code, when it might be able to make use of this data, checks to see if it has been published before trying to use it.\n实现安全发布对象的一种技术就是将对象引用定义为 volatile 类型。清单 3 展示了一个示例，其中后台线程在启动阶段从数据库加载一些数据。其他代码在能够利用这些数据时，在使用之前将检查这些数据是否曾经发布过。\nListing 3. Using a volatile variable for safe one-time publication\n清单 3. 将 volatile 变量用于一次性安全发布\npublic class BackgroundFloobleLoader &#123;    public volatile Flooble theFlooble;    public void initInBackground() &#123;        // do lots of stuff        theFlooble = new Flooble();  // this is the only write to theFlooble    &#125;&#125;public class SomeOtherClass &#123;    public void doWork() &#123;        while (true) &#123;            // do some stuff...            // use the Flooble, but only if it is ready            if (floobleLoader.theFlooble != null)                doSomething(floobleLoader.theFlooble);        &#125;    &#125;&#125;\n\nWithout the theFlooble reference being volatile, the code in doWork() would be at risk for seeing a partially constructed Flooble as it dereferences the theFlooble reference.\n如果 theFlooble 引用不是 volatile 类型，doWork() 中的代码在解除对 theFlooble 的引用时，将会得到一个不完全构造的 Flooble。\nA key requirement for this pattern is that the object being published must either be thread-safe or effectively immutable (effectively immutable means that its state is never modified after its publication). The volatile reference may guarantee the visibility of the object in its as-published form, but if the state of the object is going to change after publication, then additional synchronization is required.\n该模式的一个必要条件是：被发布的对象必须是线程安全的，或者是有效的不可变对象（有效不可变意味着对象的状态在发布之后永远不会被修改）。volatile 类型的引用可以确保对象的发布形式的可见性，但是如果对象的状态在发布后将发生更改，那么就需要额外的同步。\nPattern #3: independent observations模式 #3：独立观察\nAnother simple pattern for safely using volatile is when observations are periodically “published” for consumption within the program. For example, say there is an environmental sensor that senses the current temperature. A background thread might read this sensor every few seconds and update a volatile variable containing the current temperature. Then, other threads can read this variable knowing that they will always see the most up-to-date value.\n安全使用 volatile 的另一种简单模式是：定期「发布」 观察结果供程序内部使用。例如，假设有一种环境传感器能够感觉环境温度。一个后台线程可能会每隔几秒读取一次该传感器，并更新包含当前文档的 volatile 变量。然后，其他线程可以读取这个变量，从而随时能够看到最新的温度值。\nAnother application for this pattern is gathering statistics about the program. Listing 4 shows how an authentication mechanism might remember the name of the last user to have logged on. The lastUser reference will be repeatedly used to publish a value for consumption by the rest of the program.\n使用该模式的另一种应用程序就是收集程序的统计信息。清单 4 展示了身份验证机制如何记忆最近一次登录的用户的名字。将反复使用 lastUser 引用来发布值，以供程序的其他部分使用。\nListing 4. Using a volatile variable for multiple publications of independent observations\n清单 4. 将 volatile 变量用于多个独立观察结果的发布\npublic class UserManager &#123;    public volatile String lastUser;    public boolean authenticate(String user, String password) &#123;        boolean valid = passwordIsValid(user, password);        if (valid) &#123;            User u = new User();            activeUsers.add(u);            lastUser = user;        &#125;        return valid;    &#125;&#125;\n\nThis pattern is an extension of the previous one; a value is being published for use elsewhere within the program, but instead of publication being a one-time event, it is a series of independent events. This pattern requires that the value being published be effectively immutable – that its state not change after publication. Code consuming the value should be aware that it might change at any time.\n该模式是前面模式的扩展；将某个值发布以在程序内的其他地方使用，但是与一次性事件的发布不同，这是一系列独立事件。这个模式要求被发布的值是有效不可变的 —— 即值的状态在发布后不会更改。使用该值的代码需要清楚该值可能随时发生变化。\nPattern #4: the “volatile bean” pattern模式 #4：「volatile bean」 模式\nThe volatile bean pattern is applicable in frameworks that use JavaBeans as “glorified structs.” In the volatile bean pattern, a JavaBean is used as a container for a group of independent properties with getters and&#x2F;or setters. The rationale for the volatile bean pattern is that many frameworks provide containers for mutable data holders (for instance, HttpSession), but the objects placed in those containers must be thread safe.\nvolatile bean 模式适用于将 JavaBeans 作为「荣誉结构」使用的框架。在 volatile bean 模式中，JavaBean 被用作一组具有 getter 和&#x2F;或 setter 方法 的独立属性的容器。volatile bean 模式的基本原理是：很多框架为易变数据的持有者（例如 HttpSession）提供了容器，但是放入这些容器中的对象必须是线程安全的。\nIn the volatile bean pattern, all the data members of the JavaBean are volatile, and the getters and setters must be trivial – they must contain no logic other than getting or setting the appropriate property. Further, for data members that are object references, the referred-to objects must be effectively immutable. (This prohibits having array-valued properties, as when an array reference is declared volatile, only the reference, not the elements themselves, have volatile semantics.) As with any volatile variable, there may be no invariants or constraints involving the properties of the JavaBean. An example of a JavaBean obeying the volatile bean pattern is shown in Listing 5:\n在 volatile bean 模式中，JavaBean 的所有数据成员都是 volatile 类型的，并且 getter 和 setter 方法必须非常普通 —— 除了获取或设置相应的属性外，不能包含任何逻辑。此外，对于对象引用的数据成员，引用的对象必须是有效不可变的。（这将禁止具有数组值的属性，因为当数组引用被声明为 volatile 时，只有引用而不是数组本身具有 volatile 语义）。对于任何 volatile 变量，不变式或约束都不能包含 JavaBean 属性。清单 5 中的示例展示了遵守 volatile bean 模式的 JavaBean：\nListing 5. A Person object obeying the volatile bean pattern\n清单 5. 遵守 volatile bean 模式的 Person 对象\n@ThreadSafepublic class Person &#123;    private volatile String firstName;    private volatile String lastName;    private volatile int age;    public String getFirstName() &#123; return firstName; &#125;    public String getLastName() &#123; return lastName; &#125;    public int getAge() &#123; return age; &#125;    public void setFirstName(String firstName) &#123;        this.firstName = firstName;    &#125;    public void setLastName(String lastName) &#123;        this.lastName = lastName;    &#125;    public void setAge(int age) &#123;        this.age = age;    &#125;&#125;\n\nAdvanced patterns for volatilevolatile 的高级模式\nThe patterns in the previous section cover most of the basic cases where the use of volatile is sensible and straightforward. This section looks at a more advanced pattern where volatile might offer a performance or scalability benefit.\n前面几节介绍的模式涵盖了大部分的基本用例，在这些模式中使用 volatile 非常有用并且简单。这一节将介绍一种更加高级的模式，在该模式中，volatile 将提供性能或可伸缩性优势。\nThe more advanced patterns for using volatile can be extremely fragile. It is critical that your assumptions be carefully documented and these patterns strongly encapsulated because very small changes can break your code! Also, given that the primary motivation for the more advanced volatile use cases is performance, be sure that you actually have a demonstrated need for the purported performance gain before you start applying them. These patterns are trade-offs that give up readability or maintainability in exchange for a possible performance boost – if you don’t need the performance boost (or can’t prove you need it through a rigorous measurement program), then it is probably a bad trade because you’re giving up something of value and getting something of lesser value in return.\nvolatile 应用的的高级模式非常脆弱。因此，必须对假设的条件仔细证明，并且这些模式被严格地封装了起来，因为即使非常小的更改也会损坏你的代码！同样，使用更高级的 volatile 用例的原因是它能够提升性能，确保在开始应用高级模式之前，真正确定需要实现这种性能获益。需要对这些模式进行权衡，放弃可读性或可维护性来换取可能的性能收益：如果你不需要提升性能（或者不能够通过一个严格的测试程序证明你需要它），那么这很可能是一次糟糕的交易，因为你很可能会得不偿失，换来的东西要比放弃的东西价值更低。\nPattern #5: The cheap read-write lock trick模式 #5：开销较低的读－写锁策略\nBy now, it should be well-known that volatile is not strong enough to implement a counter. Because ++x is really shorthand for three operations (read, add, store), with some unlucky timing it is possible for updates to be lost if multiple threads tried to increment a volatile counter at once.\n目前为止，你应该了解了 volatile 的功能还不足以实现计数器。因为 ++x 实际上是三种操作（读、添加、存储）的简单组合，如果多个线程凑巧试图同时对 volatile 计数器执行增量操作，那么它的更新值有可能会丢失。\nHowever, if reads greatly outnumber modifications, you can combine intrinsic locking and volatile variables to reduce the cost on the common code path. Listing 6 shows a thread-safe counter that uses synchronized to ensure that the increment operation is atomic and uses volatile to guarantee the visibility of the current result. If updates are infrequent, this approach may perform better as the overhead on the read path is only a volatile read, which is generally cheaper than an uncontended lock acquisition.\n然而，如果读操作远远超过写操作，你可以结合使用内部锁和 volatile 变量来减少公共代码路径的开销。清单 6 中显示的线程安全的计数器使用 synchronized 确保增量操作是原子的，并使用 volatile 保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及 volatile 读操作，这通常要优于一个无竞争的锁获取的开销。\nListing 6. Combining volatile and synchronized to form a “cheap read-write lock”\n清单 6. 结合使用 volatile 和 synchronized 实现「开销较低的读写锁」\n@ThreadSafepublic class CheesyCounter &#123;    // Employs the cheap read-write lock trick    // All mutative operations MUST be done with the &#x27;this&#x27; lock held    @GuardedBy(&quot;this&quot;) private volatile int value;    public int getValue() &#123; return value; &#125;    public synchronized int increment() &#123;        return value++;    &#125;&#125;\n\nThe reason this technique is called the “cheap read-write lock” is that you are using different synchronization mechanisms for reads and writes. Because the writes in this case violate the first condition for using volatile, you cannot use volatile to safely implement the counter – you must use locking. However, you can use volatile to ensure the visibility of the current value when reading, so you use locking for all mutative operations and volatile for read-only operations. Where locks only allow one thread to access a value at once, volatile reads allow more than one, so when you use volatile to guard the read code path, you get a higher degree of sharing than you would were you to use locking for all code paths – just like a read-write lock. However, bear in mind the fragility of this pattern: With two competing synchronization mechanisms, this can get very tricky if you branch out beyond the most basic application of this pattern.\n之所以将这种技术称之为「开销较低的读－写锁」 是因为你使用了不同的同步机制进行读写操作。因为本例中的写操作违反了使用 volatile 的第一个条件，因此不能使用 volatile 安全地实现计数器，你必须使用锁。然而，你可以在读操作中使用 volatile 确保当前值的可见性，因此可以使用锁进行所有变化的操作，使用 volatile 进行只读操作。其中，锁一次只允许一个线程访问值，volatile 允许多个线程执行读操作，因此当使用 volatile 保证读代码路径时，要比使用锁执行全部代码路径获得更高的共享度，就像读写操作一样。然而，要随时牢记这种模式的弱点：如果超越了该模式的最基本应用，结合这两个竞争的同步机制将变得非常困难。\nSummary结束语\nVolatile variables are a simpler – but weaker – form of synchronization than locking, which in some cases offers better performance or scalability than intrinsic locking. If you follow the conditions for using volatile safely – that the variable is truly independent of both other variables and its own prior values – you can sometimes simplify code by using volatile instead of synchronized. However, code using volatile is often more fragile than code using locking. The patterns offered here cover the most common cases where volatile is a sensible alternative to synchronized. Following these patterns – taking care not to push them beyond their limits – should help you safely cover the majority of cases where volatile variables are a win.\n与锁相比，Volatile 变量是一种非常简单但同时又非常脆弱的同步机制，它在某些情况下将提供优于锁的性能和伸缩性。如果严格遵循 volatile 的使用条件，即变量真正独立于其他变量和自己以前的值，在某些情况下可以使用 volatile 代替 synchronized 来简化代码。然而，使用 volatile 的代码往往比使用锁的代码更加容易出错。本文介绍的模式涵盖了可以使用 volatile 代替 synchronized 的最常见的一些用例。遵循这些模式（注意使用时不要超过各自的限制）可以帮助你安全地实现大多数用例，使用 volatile 变量获得更佳性能。\n","categories":["文献翻译","java"],"tags":["未标记"]},{"title":"DataGrip-2018.3.4-数据导出配置案例","url":"/58859900-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n官方文档：https://www.jetbrains.com/help/datagrip ，该文档默认是最新版本，可手动选择旧版本。\n1 数据导出DataGrip 导出整个数据库或单个表均支持两种方式，Dump Data to File(s) 以及 Dump with ‘mysqldump’。以下例子均采用 MySQL\n1.1 Dump Data to File(s)导出整个数据库的菜单选项如下所示。导出单个表的菜单选项减少了 Overwrite Existing Files 和 Single File，其余相同。\n\n注：如果数据库只有一个表，菜单与导出单个表的相同\n\n----------------------------------|【导出格式】SQL InsertsSQL UpdatesHTML Table----------------------------------|【导出格式】Tab-separated (TSV)Comma-separated (CSV)----------------------------------|【导出格式】HTML-Groovy.html.groovyHTML-JavaScript.html.jsSQL-Insert-Statements.sql.groovyXML-Groovy.xml,groovyCSV-Groovy.csv.groovyJSON-Groovy.json.groovy----------------------------------|【行为】Skip Computed Columns (SQL)【不添加计算列】Skip Generated Columns (SQL)【不添加自动生成的列，如自动增长列】Add Table Definition (SQL)【添加表定义】Overwrite Existing Files【导出整个数据库时可用。若出现重名，不勾选时生成文件名后有序号，勾选则覆盖】Single File【导出整个数据库时可用。将各个表的 sql 合并到一个文件，否则每个表分别生成一个文件。勾选 Single File 后，Overwrite Existing Files 失效，无论是否勾选。此时若出现重名，将弹出对话框提示是否覆盖或改名】----------------------------------|Configure CSV Formats...Go to Scripts Directory----------------------------------|\n\n创建数据库 onlytest，包含两个结构类似的表 employee、manager，其中 employee 包含计算列。创建 sql 如下：\ncreate table onlytest.employee(  ID       bigint auto_increment    primary key,  name     tinytext not null,  age      int      not null,  tenyears int as ((`age` + 10)));create table onlytest.manager(  ID   bigint auto_increment    primary key,  name tinytext not null,  age  int      not null);\n\n1.1.1 Add Table Definition (SQL)若勾选 Add Table Definition (SQL)、Single File，导出格式选择 SQL Inserts，则在添加数据前创建表时的定义（SQL Updates 结果以此类推）：\n\n注意：该选项仅对 SQL Inserts、SQL Updates 有效。\n\ncreate table employee(  ID       bigint auto_increment    primary key,  name     tinytext not null,  age      int      not null,  tenyears int as ((`age` + 10)));INSERT INTO onlytest.employee (ID, name, age, tenyears) VALUES (1, &#x27;one&#x27;, 22, 32);INSERT INTO onlytest.employee (ID, name, age, tenyears) VALUES (2, &#x27;two&#x27;, 17, 27);INSERT INTO onlytest.employee (ID, name, age, tenyears) VALUES (3, &#x27;three&#x27;, 20, 30);create table manager(  ID   bigint auto_increment    primary key,  name tinytext not null,  age  int      not null);INSERT INTO onlytest.manager (ID, name, age) VALUES (1, &#x27;one&#x27;, 35);INSERT INTO onlytest.manager (ID, name, age) VALUES (2, &#x27;two&#x27;, 36);\n\n不勾选则仅生成 insert（SQL Updates 结果以此类推）：\nINSERT INTO onlytest.employee (ID, name, age, tenyears) VALUES (1, &#x27;one&#x27;, 22, 32);INSERT INTO onlytest.employee (ID, name, age, tenyears) VALUES (2, &#x27;two&#x27;, 17, 27);INSERT INTO onlytest.employee (ID, name, age, tenyears) VALUES (3, &#x27;three&#x27;, 20, 30);INSERT INTO onlytest.manager (ID, name, age) VALUES (1, &#x27;one&#x27;, 35);INSERT INTO onlytest.manager (ID, name, age) VALUES (2, &#x27;two&#x27;, 36);\n\n1.1.2 Skip Generated Columns (SQL)若勾选 Skip Generated Columns (SQL)、Single File，不勾选 Add Table Definition (SQL)，导出格式选择 SQL Inserts，则没有自动增长的 ID 列，（SQL Updates 结果以此类推）：\n\n注意：该选项仅对 SQL Inserts、SQL Updates 有效。\n\nINSERT INTO onlytest.employee (name, age, tenyears) VALUES (&#x27;one&#x27;, 22, 32);INSERT INTO onlytest.employee (name, age, tenyears) VALUES (&#x27;two&#x27;, 17, 27);INSERT INTO onlytest.employee (name, age, tenyears) VALUES (&#x27;three&#x27;, 20, 30);INSERT INTO onlytest.manager (name, age) VALUES (&#x27;one&#x27;, 35);INSERT INTO onlytest.manager (name, age) VALUES (&#x27;two&#x27;, 36);\n\n1.1.3 Skip Computed Columns (SQL)若勾选 Skip Computed Columns (SQL)、Single File，不勾选 Add Table Definition (SQL)，导出格式选择 SQL Inserts，则没有 tenyears 列，（SQL Updates 结果以此类推）：\n\n注意：该选项仅对 SQL Inserts、SQL Updates 有效。\n\nINSERT INTO onlytest.employee (ID, name, age) VALUES (1, &#x27;one&#x27;, 22);INSERT INTO onlytest.employee (ID, name, age) VALUES (2, &#x27;two&#x27;, 17);INSERT INTO onlytest.employee (ID, name, age) VALUES (3, &#x27;three&#x27;, 20);INSERT INTO onlytest.manager (ID, name, age) VALUES (1, &#x27;one&#x27;, 35);INSERT INTO onlytest.manager (ID, name, age) VALUES (2, &#x27;two&#x27;, 36);\n\n1.2 Dump with ‘mysqldump’经过实测发现，当数据量较大时，使用 Dump Data to File(s) 方式导出的 sql 文件与 Dump with ‘mysqldump’ 方式相比会大很多，可能是由于前者重复字符量大以及换行多导致。因此推荐优先使用后者导出。\n导出整个数据库和单个表的菜单选项相同，故合并讨论。Dump with ‘mysqldump’ 有如下菜单选项：\n\nMultiple rows inserts【将 insert 语句合并为一行】\nAdd drop table【增加判断条件，若表存在则删除】\nDisable keys【禁用索引】\nDelay inserts【提示错误 mysqldump: [ERROR] unknown option &#39;--delayed-insert&#39;.，无输出结果】\nMySQL create table options【若不勾选，暂时未发现有明显差异】\nLock tables【锁表，可能是防止有新数据在导出时进入】\nAdd locks【导入时，在执行 insert 前添加 write 锁，完成后解除】\nAdd drop trigger【导入时，删除对方的触发器】\n\n案例 1勾选 Multiple rows inserts、Add drop table、MySQL create table options、Add drop trigger，生成结果如下：\n-- MySQL dump 10.13  Distrib 8.0.18, for osx10.14 (x86_64)---- Host: 127.0.0.1    Database: onlytest-- -------------------------------------------------------- Server version\t8.0.18/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;/*!50503 SET NAMES utf8mb4 */;/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;/*!40103 SET TIME_ZONE=&#x27;+00:00&#x27; */;/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE=&#x27;NO_AUTO_VALUE_ON_ZERO&#x27; */;/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;---- Table structure for table `employee`--DROP TABLE IF EXISTS `employee`;/*!40101 SET @saved_cs_client     = @@character_set_client */;/*!50503 SET character_set_client = utf8mb4 */;CREATE TABLE `employee` (  `ID` bigint(20) NOT NULL AUTO_INCREMENT,  `name` tinytext COLLATE utf8mb4_general_ci NOT NULL,  `age` int(11) NOT NULL,  `tenyears` int(11) GENERATED ALWAYS AS ((`age` + 10)) VIRTUAL,  PRIMARY KEY (`ID`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `employee`--INSERT INTO `employee` (`ID`, `name`, `age`) VALUES (1,&#x27;one&#x27;,22),(2,&#x27;two&#x27;,17),(3,&#x27;three&#x27;,20);---- Table structure for table `manager`--DROP TABLE IF EXISTS `manager`;/*!40101 SET @saved_cs_client     = @@character_set_client */;/*!50503 SET character_set_client = utf8mb4 */;CREATE TABLE `manager` (  `ID` bigint(20) NOT NULL AUTO_INCREMENT,  `name` tinytext COLLATE utf8mb4_general_ci NOT NULL,  `age` int(11) NOT NULL,  PRIMARY KEY (`ID`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `manager`--INSERT INTO `manager` VALUES (1,&#x27;one&#x27;,35),(2,&#x27;two&#x27;,36);/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;-- Dump completed on 2020-02-19 20:43:57\n\n案例 2若增加勾选 Disable keys，禁用索引，在大批量导入时先禁用索引，在完全导入后，再开启索引。\n.../*!40000 ALTER TABLE `employee` DISABLE KEYS */;INSERT INTO `employee` (`ID`, `name`, `age`) VALUES (1,&#x27;one&#x27;,22),(2,&#x27;two&#x27;,17),(3,&#x27;three&#x27;,20);/*!40000 ALTER TABLE `employee` ENABLE KEYS */;.../*!40000 ALTER TABLE `manager` DISABLE KEYS */;INSERT INTO `manager` VALUES (1,&#x27;one&#x27;,35),(2,&#x27;two&#x27;,36);/*!40000 ALTER TABLE `manager` ENABLE KEYS */;...\n\n案例 3勾选 Add locks，添加了 write 锁\n...LOCK TABLES `employee` WRITE;INSERT INTO `employee` (`ID`, `name`, `age`) VALUES (1,&#x27;one&#x27;,22),(2,&#x27;two&#x27;,17),(3,&#x27;three&#x27;,20);UNLOCK TABLES;...LOCK TABLES `manager` WRITE;INSERT INTO `manager` VALUES (1,&#x27;one&#x27;,35),(2,&#x27;two&#x27;,36);UNLOCK TABLES;...\n\n其他 mysqldump 参数（待定）\n\n\n参数\n描述\n\n\n\nxxx\nxxx\n\n\n2 查看创建脚本右键 SQL Script 选择 SQL Generator\n3 执行 SQL右键 New 选择 Console，\n","categories":["系统和工具配置"],"tags":["datagrip"]},{"title":"IntelliJ-IDEA-快捷键及常用配置","url":"/5885c010-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n\n\n\n\n\n\nmacOS IDEA 默认常用快捷键\n删除行 ⌘Y\n查看实现当前接口全部类或当前类的全部子类（Type hierarchy） ⌃H\n查看所有方法 ⌘7\n从当前行切换到下一行 ⇧↩︎\n全局搜索（Search everywhere） Double⇧\n格式化代码（Reformat Code） ⌥⌘L\n往上移动代码块或行 ⇧⌘↑\n往下移动代码块或行 ⇧⌘↓\n\n格式化 Java 代码时让注释不在行首Preference → Editor → Code Style → Java，取消「Line comment at first column」和「Block comment at first column」复选即可。\nJava 代码自动导入依赖Preference → Editor → General → Auto Import，「Insert imports on paste」选择「All」即可。\n自动完成关键字时不区分大小写Preference → Editor → General → Code Completion，取消「Match case」复选即可。\n","categories":["系统和工具配置"],"tags":["intelliJ"]},{"title":"MacOS-或-Win-环境下问题杂烩及备忘","url":"/5885c011-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\nmacOS 10.14.6 运行应用时提示「无法打开“xxxxx”，因为 Apple 无法检查其是否包含恶意软件。」该提示与「“xxxxx”已损坏，打不开。您应该将它移到废纸娄。」解决方案相同，需要开启「允许安装软件来自任何来源」。打开终端，输入命令：sudo spctl --master-disable，输入密码后生效。\nmacOS 查看隐藏文件⌘+⇧+.\nwin10 使用 ssh 连接远程服务器\n依次进入：开始菜单 → 设置 → 应用 → 应用和功能，选择「管理可选功能」\n进入添加功能，添加「OpenSSH 服务端」\n从开始菜单打开 Windows PowerShell 即可使用\n\nVSCode 利用正则删除全部空行^\\s*(?=\\r?$)\\n 匹配所有空行，替换为无字符即可\nmacOS 每次开机通过 ssh-add 自动添加私钥打开自动操作，类型选择「应用程序」\n选择「运行 shell 脚本」，双击，在右侧设置「名称」，输入如下命令行（参考）\nssh-add ~/.ssh/id_rsa\n\n进入「偏好设置」，进入「用户与群组」，进入「登陆项」，选择之前命名的应用即可\n","categories":["系统和工具配置"],"tags":["macos","win"]},{"title":"VSCode-常用插件及配置","url":"/58860e30-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\nPrettier - Code formatter代码格式化插件，支持的语言有：JavaScript、TypeScript、Flow、JSX、JSON、CSS、SCSS、Less、HTML、Vue、Angular、GraphQL、Markdown、YAML\nPrettier 使用 cosmiconfig 来支持配置文件。这意味着你可以通过以下方式配置 prettier（按优先级顺序）：\n\n在 package.json 文件中建立 &quot;prettier&quot; 键\n新建一个内容是 JSON 或 YAML 格式的 .prettierrc 文件，扩展名可选：.json/.yaml/.yml，不带扩展名的优先级最高。\n使用 .prettierrc.js 或 prettier.config.js 文件导出对象\n使用 .prettierrc.toml 文件，格式是 TOML，（ .toml 扩展名是必须的）\n\n配置文件将从正在格式化的文件的位置开始解析，并在文件树中搜索，直到找到（或没有找到）配置文件。配置文件的选项与 API 选项相同。JSON 格式的配置文件示例如下：\n&#123;  &quot;trailingComma&quot;: &quot;es5&quot;,  &quot;tabWidth&quot;: 4,  &quot;semi&quot;: false,  &quot;singleQuote&quot;: true&#125;\n\n配置项jsxBracketSameLine将多行 JSX 元素的 &gt; 放在最后一行的末尾，而不是单独放在下一行（不应用于自关闭元素）。默认值为 false。\narrowParens箭头函数的单个参数周围包含圆括号。可选值为：&quot;always&quot; 和 &quot;avoid&quot;，默认值为 &quot;avoid&quot;，即单个参数周围默认不包含圆括号。\nhttps://prettier.io/docs/en/options.html#bracket-spacing更多说明及示例可参看文档：https://prettier.io/docs/en/configuration.html\n","categories":["系统和工具配置"],"tags":["vscode"]},{"title":"win11 右键菜单风格修改","url":"/94ecb270-3c38-11ef-bf49-874d1d199c67/","content":"\n\n\n\n1、将 win11 模式修改成旧模式1）win+R 调出运行栏，写入 reg add &quot;HKCU\\Software\\Classes\\CLSID\\&#123;86ca1aa0-34aa-4e8b-a509-50c905bae2a2&#125;\\InprocServer32&quot; /f /ve\n2）确定\n3）进入任务管理器，找到 Windows 资源管理器，右键选择重新启动\n或新建注册表文件，执行如下内容：\nWindows Registry Editor Version 5.00[HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;86ca1aa0-34aa-4e8b-a509-50c905bae2a2&#125;\\InprocServer32]@=&quot;&quot;\n\n2、恢复 win11 模式1）同上步骤，执行变成 reg delete &quot;HKCU\\Software\\Classes\\CLSID\\&#123;86ca1aa0-34aa-4e8b-a509-50c905bae2a2&#125;&quot; /f\n","categories":["系统和工具配置"],"tags":["win"]},{"title":"修改-host-表开启-gist","url":"/58865c52-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n解决方案win 10 的 hosts 文件路径如下：\nC:\\Windows\\System32\\drivers\\etc\\hosts.ics\n\nmacOS 10.14.6 的 hosts 文件直接通过终端进入：\n$ sudo vi /etc/hosts\n\n在文件末尾添加以下内容：\n192.30.253.118 gist.github.com192.30.253.119 gist.github.com\n\n注：该地址可能会变动，可进入 https://ipchaxun.com/gist.github.com/ 查询地址，目前最新的地址如下：\n140.82.112.4140.82.114.4 ","categories":["系统和工具配置"],"tags":["github"]},{"title":"修改-macOS-的-MAC-地址","url":"/ef127fe0-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n1、操作步骤1）打开终端，输入openssl rand -hex 6 | sed &#39;s/\\(..\\)/\\1:/g; s/.$//&#39;生成一个 MAC 地址\n2）断开网卡连接，会要求输入密码。\nsudo /System/Library/PrivateFrameworks/Apple80211.framework/Resources/airport -z\n3）修改网卡地址，例如 en0：sudo ifconfig en0 ether xx:xx:xx:xx:xx:xx\n4）重连网卡，可能会要求输入密码：networksetup -detectnewhardware\n5）验证 MAC 地址是否修改成功：ifconfig\n","categories":["系统和工具配置"],"tags":["macos"]},{"title":"将-VSCode-添加到右键菜单","url":"/58868360-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n问题描述Windows 10 或 macOS 10.14 下安装 VSCode 后，右键快速打开选项并没有快捷启动。\nWindows 10 解决方案通过注册表添加三个位置的快速打开选项：文件、目录、桌面（目录内）的空白位置。\n1、添加至文件的右键菜单定位注册表中如下位置：\nHKEY_CLASSES_ROOT\\*\\shell\n\n参考以下结构，在 shell 下新建一个项 Open with VSCode\n├── Open with VSCode    ├── (默认)（在右键菜单显示的名称）    ├── Icon（在右键菜单显示的图标路径）    └── command        └── (默认)（执行的命令行及应用路径）\n\n添加相应字符串值即可实现点击文件的右键菜单进入 VSCode。导出内容如下：\nWindows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\\*\\shell\\Open with VSCode]&quot;Icon&quot;=&quot;C:\\\\MyProject\\\\Microsoft VS Code\\\\Code.exe&quot;@=&quot;Open with VSCode&quot;[HKEY_CLASSES_ROOT\\*\\shell\\Open with VSCode\\command]@=&quot;\\&quot;C:\\\\MyProject\\\\Microsoft VS Code\\\\Code.exe\\&quot; \\&quot;%1\\&quot;&quot;\n\n2、添加至目录的右键菜单定位至 HKEY_CLASSES_ROOT\\Directory\\shell，按照相同结构设置即可实现点击目录的右键菜单进入 VSCode。导出内容如下：\nWindows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\\Directory\\shell\\VSCode]&quot;Icon&quot;=&quot;C:\\\\MyProject\\\\Microsoft VS Code\\\\Code.exe&quot;@=&quot;Open Folder as VSCode Project&quot;[HKEY_CLASSES_ROOT\\Directory\\shell\\VSCode\\command]@=&quot;\\&quot;C:\\\\MyProject\\\\Microsoft VS Code\\\\Code.exe\\&quot; \\&quot;%1\\&quot;&quot;\n\n3、添加至桌面（目录内）的空白位置的右键菜单定位至 HKEY_CLASSES_ROOT\\Directory\\Background\\shell，按照相同结构设置即可实现点击桌面（目录内）的空白位置的右键菜单进入 VSCode。导出内容如下：\nWindows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\VSCode]&quot;Icon&quot;=&quot;C:\\\\MyProject\\\\Microsoft VS Code\\\\Code.exe&quot;@=&quot;Open Folder as VSCode Project&quot;[HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\VSCode\\command]@=&quot;\\&quot;C:\\\\MyProject\\\\Microsoft VS Code\\\\Code.exe\\&quot; \\&quot;%V\\&quot;&quot;\n\nmacOS 10.14 解决方案通过快速操作添加两个位置的快速打开选项：文件、目录。\n1、打开自动操作，文稿类型选取 快速操作\n\n2、左侧资源库选择 文件和文件夹，对应其右侧子菜单栏双击 打开访达项目，3、在 工作流程收到当前 选择 文件或文件夹，位于 选择 访达4、在 打开方式 找到 Visual Studio Code.app\n\n5、完成以上设置后，cmd+S 将该快速操作保存为 Open with VSCode 即可","categories":["系统和工具配置"],"tags":["vscode"]},{"title":"彻底关闭Win10自动更新","url":"/undefined/","content":"\n\n\n\n1、禁用服务1）调出运行栏输入 services.msc\n2）找到 Windows Update，在“常规”选项卡停止服务后禁用\n3）在“恢复”选项卡改为“无操作”\n2、组策略配置1）调出运行栏输入 gpedit.msc\n2）依次展开：计算机配置-&gt;管理模板-&gt;Windows 组件-&gt;Windows 更新\n3）右侧找到“配置自动更新”，选择“已禁用”\n4）右侧找到“删除使用所有 Windows 更新功能的访问权限”，选择“已启用”\n3、任务计划配置1）调出运行栏输入 taskschd.msc\n2）依次展开：任务计划程序库-&gt;Microsoft-&gt;Windows-&gt;WindowsUpdate\n3）禁用 Scheduled Start\n4、注册表配置1）调出运行栏输入 regedit\n2）定位 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\UsoSvc，右侧 Start 值改成 16 进制，值改为 4\n3）继续找到 FailureActions，修改下图所示部位为 0\n\n","categories":["系统和工具配置"],"tags":["win"]},{"title":"微软输入法直接输出方括号等标点符号","url":"/e176eb10-4179-11ef-95e8-1935eab13c7a/","content":"\n\n\n\n操作步骤以直角引号 「」 为例：\n1）确定 u模式 开启：设置 → 时间和语言 → 语言和区域 → 中文(简体, 中国) → 语言选项 → 键盘 → 微软拼音 → 键盘选项 → 高级 → U 模式输入\n2）在中文状态下键入 uu，此时弹出提示框内容如下：\nU模式输入。支持符号(uudw:单位，uuxh:序号，uuts:特殊，uubd:标点，uusx:数学，uujh:几何，uuzm:字母)输入。\n\n3）根据提示继续输入 bd 构成 uubd，即可进入选择，翻页找到直角引号 「」\n","categories":["系统和工具配置"],"tags":["win"]},{"title":"GitHub 中使用 issues 模版和 pull request 模版","url":"/2d5fb050-cd69-11ee-be69-4dedf56c58bd/","content":"\n\n\n\n1、issues 模版1）默认模版\n\n在代码库新建目录：.github\n在 .github 目录下添加 ISSUE_TEMPLATE.md 文件作为 issues 默认模版。当创建 issue 时，若未建立多模版或选择了 Open a regular issue 时，系统会引用该模版。\n\n\n2）多模版\n\n在代码库新建目录：.github/ISSUE_TEMPLATE\n该目录下可添加多个 .md 文件作为 issues 模版。当创建 issue 时，系统会展示这些模版供选择。\n.md 文件参考格式如下：\n\n---name: 该模版的名称（创建 issue 时，系统展示模版列表时会显示该名称）about: 该模版的描述（创建 issue 时，系统展示模版列表时会显示该描述）---正文内容……\n\n3）注意事项\n\nissues 的默认模版和多模版可同时存在。\n关于 issues 模版的描述可详见帮助文档：https://help.github.com/articles/manually-creating-a-single-issue-template-for-your-repository/\n\n2、pull request 模版1）默认模版\n\n在代码库新建目录：.github\n在 .github 目录下添加 PULL_REQUEST_TEMPLATE.md 文件作为 pull request 默认模版。当创建不带参数的 pull request 时，系统会引用该模版。\n\n2）多模版\n\n在代码库新建目录：.github/PULL_REQUEST_TEMPLATE\n该目录下可添加多个 .md 文件作为 pull request 模版。\npull request 模版要通过查询参数来调用。例如，要使用 pr-template-1.md 这个模版，可使用如下查询：\n\nhttps://github.com/用户名/代码库名称/compare/分支名称?expand=1&amp;template=pr-template-1.md\n\n或参考 GitHub 帮助文档的格式，如下。两者效果相同。\nhttps://github.com/用户名/代码库名称/compare/master...分支名称?expand=1&amp;template=pr-template-1.md\n\n\n可选查询参数\nexpand=1，直接跳转到 pull request 界面。如果不带此参数会先到 compare 界面，需手动进入 pull request 界面。\ntemplate=pr-template-1.md，调用名为 pr-template-1.md 的模版。如果不带此参数，则调用默认模版。\ntitle=New+bug+report（或者 title=New%20bug%20report），指定 pull request 的标题为 New bug report\n其他参数可详见帮助文档：https://help.github.com/articles/about-automation-for-issues-and-pull-requests-with-query-parameters/\n\n\n\n3）注意事项\n\npull request 的默认模版和多模版可同时存在。\n关于 pull request 模版的描述可详见帮助文档：https://help.github.com/articles/creating-a-pull-request-template-for-your-repository/\n\n","categories":["通用技术"],"tags":["github"]},{"title":"GitHub-中独立仓库与组织的权限","url":"/5886aa71-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n一、独立仓库（公开或私有）独立仓库包含 仓库拥有者和外部协作者 两种角色，相关权限如下表\n\n\n\n\n直接写入\nissue 操作[删除、隐藏、修改]\n添加标签\n分支操作[删除、创建]\n邀请校对\n被邀请校对\n校对操作[同意、驳回、重校]\n强制合并\nSetting 菜单可见\n\n\n\n仓库拥有者\n√\n√\n√\n√\n√\n√\n√\n√\n√\n\n\n外部协作者\n√\n√\n√\n√\n√\n√\n√\n×\n×\n\n\n注：Setting 菜单是否可见决定了是否具备删库、设置分支规则、邀请外部协作者、密钥设置等高级权限。\n二、组织组织包含 组织拥有者、成员、外部协作者 三种角色，以及 Read、Write、Admin 三种权限。\n1、Base permissions（基本权限）Base permissions to the organization’s repositories apply to all members and excludes outside collaborators. Since organization members can have permissions from multiple sources, members and collaborators who have been granted a higher level of access than the base permissions will retain their higher permission privileges.\n组织存储库的基本权限适用于所有成员（不含外部协作者）。由于组织成员可以拥有多个库的自定义权限，因此被授予比基本权限更高级别访问权限时，成员和协作者将保留更高的权限。\n基本权限包含如下几种：\n\nNone，Members will only be able to clone and pull public repositories. To give a member additional access, you’ll need to add them to teams or make them collaborators on individual repositories.\n\n成员只能对公共库实施 clone 和 pull 操作。要为成员提供额外的访问权限，需要将它们添加到团队中，或者让它们成为各个存储库的外部协作者。\n\nRead，Members will be able to clone and pull all repositories.\n\n成员可以对所有库实施 clone 和 pull 操作。\n\nWrite，Members will be able to clone, pull, and push all repositories.\n\n成员可以对所有库实施 clone、pull 和 push 操作。\n\nAdmin，Members will be able to clone, pull, push, and add new collaborators to all repositories.\n\n成员可以对所有库实施 clone、pull、push 和添加外部协作者的操作。\n2、组织角色\nOwner，Has full administrative access to the entire organization.\n\n对整个组织具有完全的管理访问权限。组织角色为 Owner 时，对于组织中每一个库而言，默认权限都是 Admin。\n\nMember，Can see every member and non-secret team in the organization, and can create new repositories.\n\n可以查看组织中的每个成员和非机密团队，并可以创建新的存储库。组织角色为 Member 时，对于组织中每一个库而言，默认权限都与基本权限相同。\n3、库权限Read、Write、Admin，详见基本权限的描述。如果需要在某一个库中授予某个成员高于基本权限的权限，需要将其添加为外部协作者。\n4、组织权限总结如下\n\n\n\n直接写入\nissue 操作[删除、隐藏、修改]\n添加标签\n分支操作[删除、创建]\n邀请校对\n被邀请校对\n校对操作[同意、驳回、重校]\n强制合并\n库 Setting 菜单可见\n组织 Setting 菜单可见\n\n\n\n组织拥有者\n√\n√\n√\n√\n√\n√\n√\n√\n√\n√\n\n\nRead\n×\n×\n×\n×\n×\n√\n×\n×\n×\n×\n\n\nWrite\n√\n√\n√\n√\n√\n√\n√\n×\n×\n×\n\n\nAdmin\n√\n√\n√\n√\n√\n√\n√\n√\n√\n×\n\n\n","categories":["通用技术"],"tags":["github"]},{"title":"conda-依赖管理","url":"/58860e31-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n基本操作创建一个新环境：conda create -n &lt;env_name&gt; &lt;python=version&gt; &lt;package_list&gt;\n\n例子：conda create -n env python=3.10 numpy pandas，创建名为env的环境，python 版本为 3.10，同时安装 numpy 和 pandas。\n\n进入环境：conda activate &lt;env_name&gt;\n退出环境：conda deavtivate\n查看所有环境：conda env list\n复制环境：conda create --name &lt;new_env_name&gt; --clone &lt;old_env_name&gt;\n精确查找依赖：conda search --full-name &lt;package_full_name&gt;\n模糊查找依赖：conda search &lt;依赖名称包含的字符串&gt;\n查看已经安装的依赖：conda list\n安装依赖：conda install --name &lt;env_name&gt; &lt;package_name&gt;\n在当前环境安装依赖：conda install &lt;package_name&gt;\n卸载依赖：conda remove --name &lt;env_name&gt; &lt;package_name&gt;\n在当前环境卸载依赖：conda remove &lt;package_name&gt;\n更新全部依赖：conda update --all\n更新指定依赖：conda update &lt;package_name&gt;\n环境依赖的导出和恢复导出当前环境依赖：conda env export &gt; environment.yaml\n恢复依赖：conda env create -f environment.yml -n &lt;envname&gt;\n\n注意：environment.yaml文件name属性是导出时环境的名称或绝对路径，恢复时为防止冲突，最好使用-n参数显示指定新名称，此时恢复的环境会出现在env目录下，直接按新名称引用即可。\n\n\nvscode：ctrl+shift+p -&gt; Select Interpreter\npycharm：Settings -&gt; Project -&gt; Python Interpreter -&gt; Add Python Interpreter -&gt; Conda Environment\n\n删除环境常规命令：conda remove --name &lt;env_name&gt; --all，按「Y」确认后执行删除，但env目录下有残余，手动清除即可；若环境没有名称，如下所示。按目前使用经验，用 vscode 插件生成的 conda 环境会出现这种情况，在源码目录下以.conda出现。直接删除即可，再次查看环境列表会消失。\nbase                     C:\\Users\\pro\\anaconda3new                   *  C:\\Users\\pro\\anaconda3\\envs\\newpython                   C:\\Users\\pro\\anaconda3\\envs\\pythontestq                    C:\\Users\\pro\\anaconda3\\envs\\testqtestx                    C:\\Users\\pro\\anaconda3\\envs\\testx                         c:\\Users\\Desktop\\py_mod\\.conda                         c:\\Users\\Desktop\\test38\\.conda\n\n其他管理方式管理依赖树：pip install pipdeptree，可查看每个依赖引用的其他依赖。\n整体删除依赖及其引用：pip install pip-autoremove，防止遗漏。\n","categories":["通用技术"],"tags":["python"]},{"title":"git-常用命令","url":"/5886aa72-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n\n\ngit 常用命令目录\n初始化仓库\n全局配置用户名和邮箱地址\n删除全局配置的用户名和邮箱地址\n对当前仓库配置用户名和邮箱地址\n查看全局配置的用户名和邮箱\n查看当前仓库的用户名和邮箱\n生成-SSH-公钥\n关联远程仓库\n把本地库的所有内容推送到远程库\n从远程仓库克隆\n将修改的文件提交到暂存区\n将文件从暂存区提交到版本库\n修改-commit-的注释信息\n查看当前提交状态\n查看文件具体变更内容\n查看提交的历史版本\n查看操作命令历史记录\n版本回退\n撤销修改或提交\n删除文件\n分支操作\n对比两个分支差异\n保存工作现场\n查看已经保存工作现场\n恢复工作现场\n获取远程仓库最新提交到本地\n打标签\n查看所有标签\n补标签\n查看标签信息\n删除标签\n将标签推送到远程\n清空缓存\n\n初始化仓库$ git init\n\n全局配置用户名和邮箱地址$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email email@example.com\n\n注意：如果一台机器需要使用多个 ssh 公钥的方式，不应使用全局配置，而是每个仓库独立配置。否则提交时，远程仓库的 commit 记录会显示是全局用户做的提交操作。\n删除全局配置的用户名和邮箱地址$ git config --global --unset user.name$ git config --global --unset user.email\n\n对当前仓库配置用户名和邮箱地址$ git config user.name &quot;Your Name&quot;$ git config user.email email@example.com\n\n查看全局配置的用户名和邮箱$ git config --global user.name$ git config --global user.email\n\n查看当前仓库的用户名和邮箱$ git config user.name$ git config user.email\n\n生成-SSH-公钥1、为 git@example.com 用户生成 SSH 公钥 id_rsa 文件，并保存在默认目录 ~/.ssh 下\n$ ssh-keygen -t rsa -C &quot;git@example.com &quot; -f ~/.ssh/id_rsa\n\n2、测试 username （默认用户名为 git）的 SSH 链接是否正常\n$ ssh –T &lt;username&gt;\n\n关联远程仓库添加名称为 origin 的关联信息\n$ git remote add origin git@github.com:username/name.git\n\n或\n$ git remote add origin https://github.com/username/name.git\n\n查看全部关联的详细信息\n$ git remote -v\n\n把本地库的所有内容推送到远程库1、通常添加参数 -u，简化提交远程库流程。例如：把本地的 master 分支和远程的 master 分支关联：\n$ git push -u origin master\n\n2、使用参数 -u 关联后，推送最新修改命令简化为：\n$ git push\n\n从远程仓库克隆1、默认方式，克隆全部分支，并指定本地文件夹名称为 dirName\n$ git clone git@github.com:username/repositoryname.git dirName\n\n2、克隆指定分支\n$ git clone -b branchname https://github.com/username/repositoryname.git\n\ngit 支持多种协议，包括 https，但通过 ssh 支持的原生 git 协议速度最快。\n将修改的文件提交到暂存区$ git add &lt;filename.xxx&gt; [-u][.][-A]\n\n-u 参数：提交被修改（modified）和被删除（deleted）文件，不包括新文件（new）\n.参数：提交新文件（new）和被修改（modified）文件，不包括被删除（deleted）文件\n-A参数：提交所有变化，包括新文件（new）、被修改（modified）文件、被删除（deleted）文件\n将文件从暂存区提交到版本库$ git commit -m &quot;create new file&quot;\n\n修改 commit 的注释信息$ git commit --amend\n\n查看当前提交状态可以查看是否存在变更，但不能查看具体变更了什么内容\n$ git status\n\n查看文件具体变更内容git diff &lt;fileName.xxx&gt;\n\n查看提交的历史版本默认情况下显示的信息冗长，使用时通常 --pretty=oneline 参数。例子：仅显示提交的最近 3 条提交历史版本号，只能显示 head 指向的当前版本和之前的版本信息\n1、本地仓库\n$ git log --pretty=oneline -3或$ git log --oneline -3\n\n2、远程仓库\n$ git log origin/master --pretty=oneline -3或$ git log origin/master --oneline -3\n\n查看操作命令历史记录使用该命令可以某版本在执行回退后再次返回某版本，前提是不退出当前命令行窗口\n$ git reflog\n\n版本回退1、回退到上一个版本：$ git reset --hard HEAD^\n2、回退到上上一个版本：$ git reset --hard HEAD^^\n3、回退到上 50 个版本：$ git reset --hard HEAD~50\n4、根据版本号回退，版本号不必输入完全，可区别即可：$ git reset --hard &lt;versionCode&gt;\n撤销修改或提交1、修改后还没有被放到暂存区\ngit checkout -- &lt;fileName.xxx&gt;\n\n2、修改后已经放到暂存区\n$ git reset HEAD &lt;fileName.xxx&gt;\n\n3、修改后已经提交到版本库。此时，使用版本回退，回退到指定版本\n删除文件1、从暂存区删除文件\n$ git rm &lt;fileName.xxx&gt;\n\n2、从暂存区恢复文件，只能恢复文件到最新版本，并丢失最近一次提交后修改的内容。\n$ git checkout -- &lt;fileName.xxx&gt;\n\n分支操作1、本地分支\n\n创建本地分支：$ git branch feature-local\n切换到本地分支：$ git checkout feature-local\n创建并同时切换到本地分支：$ git checkout –b feature-local\n\n2、远程分支\n\n在远程开好分支 feature-branch，本地获取：$ git checkout -b feature-local origin/feature-branch\n本地创建名为 dev 的远程分支：$ git checkout -b dev origin/dev\n指定推送本地的 feature-local 分支到远程 origin 的 feature-branch 分支，若远程不存在该分支则新建：\n\n$  git push origin feature-local:feature-branch\n\n3、查看所有分支（本地分支和远程分支）:$ git branch -a\n4、合并分支\n要合并 dev 分支到 master 主分支。先切换到 master 分支后，执行命令：$ git merge dev\n注：通常合并分支时 git 会用 Fast forward 模式，但这种模式下，删除分支后，会丢掉分支信息。如果要强制禁用 Fast forward 模式，git 就会在 merge 时生成一个新的 commit，这样，从分支历史上就可以看出分支信息：$ git merge --no-ff -m &quot;merge with no-ff&quot; dev\n5、查看分支历史：$ git log --graph --pretty=oneline --abbrev-commit，若内容过多，可仅显示前 10 条：$ git log --oneline -10\n6、删除分支\n$ git branch -d &lt;branchName&gt;\n\n如果分支还没有合并，使用上条命令会出现提示阻止删除，此时需要强行删除\n$ git branch -D &lt;branchName&gt;\n\n7、合并远程分支到本地\n\n在本地新建一个 temp 分支，并将远程 origin 仓库的 master 分支代码下载到本地 temp 分支：git fetch origin master:tmp\n比较本地代码与刚刚从远程下载下来的代码的区别：git diff tmp\n合并 temp 分支到本地的 master 分支：git merge tmp\n如果不想保留 temp 分支 可以用这步删除：git branch -d temp\n\n注意：若提交历史不同，无法合并，参见「合并两个不同提交历史的分支」。\n8、合并两个不同提交历史的分支\n\n将远程仓库的更新获取到本地分支 temp：git fetch origin master:temp\n此时若直接合并，因为提交历史不同，出现 fatal: refusing to merge unrelated histories 错误，需要增加参数，强制合并即可。：git merge temp --allow-unrelated-histories\n\n9、切换分支时出现 “error: The following untracked working tree files……”\nerror: The following untracked working tree files would be overwritten by checkout:        ……（涉及的文件列表）Please move or remove them before you switch branches.Aborting\n\n解决方式：删除上述涉及的文件即可。执行如下命令\ngit clean -d -fx\n\ngit clean 参数\n\n-n 显示将要删除的文件和目录；\n-x 删除忽略文件已经对 git 来说不识别的文件\n-d 删除未被添加到 git 的路径中的文件\n-f 强制运行\n\n对比两个分支差异有 2 个分支：master、dev。\n1、查看 dev 有，而 master 中没有的：\ngit log dev ^master\n\n2、查看 dev 中比 master 中多提交了哪些内容：\ngit log master..dev\n\n3、只比较两个分支有什么不一样：\ngit log dev...master\n\n在上述情况下，再显示出每个提交是在哪个分支上：git log --left-right dev...master\n根据 –left-right dev…master 的顺序，左箭头 &lt; 表示是 dev 分支提交；右箭头 &gt; 表示 master 分支提交\n保存工作现场$ git stash\n\n注意：要提交到暂存区才可以执行 stash，可以执行多次 stash\n查看已经保存工作现场$ git stash list\n\n恢复工作现场\n使用 git stash apply 恢复：$ git stash apply stash@&#123;0&#125;，但这种方式恢复后 stash 内容并不删除，需要用 git stash drop 来删除：$ git stash drop stash@&#123;0&#125;\n\n另一种方式是用 git stash pop，恢复的同时把 stash 内容也删了：$ git stash pop stash@&#123;0&#125;\n\n\n获取远程仓库最新提交到本地$ git pull\n\n如果 git pull 提示 no tracking information，则说明本地分支和远程分支的链接关系没有创建，执行命令：\ngit branch --set-upstream-to &lt;branch-name&gt; origin/&lt;branch-name&gt;\n\n抓取远程分支最新提交到本地分支\ngit pull origin 远端分支名:本地分支名\n\n打标签切换到需要打标签的分支上执行命令：$ git tag v1.0\n查看所有标签$ git tag\n\n补标签查看历史提交，找到需要补标签的提交的 id，执行命令：$ git tag v0.9 &lt;commitId&gt;，也可以为标签添加说明，用 -a 指定标签名，-m 指定说明文字：$ git tag -a v0.1 -m &quot;version 0.1&quot; &lt;commitId&gt;\n注：标签不是按时间顺序列出，而是按字母排序的\n查看标签信息$ git show &lt;tagName&gt;\n\n删除标签\n删除本地标签\n\n$ git tag -d v0.1\n\n\n删除远程标签，要先删除本地标签，再 push\n\n$ git tag -d v0.9$ git push origin :refs/tags/v0.9\n\n将标签推送到远程$ git push origin v1.0\n\n一次性推送全部尚未推送到远程的本地标签：$ git push origin –-tags\n清空缓存git rm -r --cached .\n\n例如，当 ignore 文件更新时，如果不清空缓存，则不生效。\n命令行创建空白 .gitignore 文件进入库目录，命令行执行 touch .gitignore 即可。\n","categories":["通用技术"],"tags":["git"]},{"title":"git-问题备忘","url":"/5886d180-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\ngit 删除远程仓库文件问题描述git 提交到远程仓库后发现有遗漏的文件未添加到 .ignore 文件中\n解决方案例如不需要提交 target 目录，可执行 git rm -r --cached target，重新 commit 和 push 即可\n说明：\n\n删除工作区文件，并且将这次删除放入暂存区，git rm [file1] [file2] ...\n\n停止追踪指定文件，但该文件会保留在工作区，git rm --cached [file]\n\n\ngit 提交时出现警告 LF-will-be-replaced-by-CRLF-in问题描述提交时出现警告：warning: LF will be replaced by CRLF ，但是不影响提交。\n解决方案\n配置选项修改，把 core.autocrlf 设置成 false。其他选项如下：\ngit config –global core.autocrlf true #默认值\ngit config –global core.autocrlf input #从库中迁出代码不转换\ngit config –global core.autocrlf false  #不转换\n\n\n\ngit 提交时中文文件名显示的解决方案问题描述git 提交时中文显示为乱码，有碍观瞻\n117 files changed, 11670 insertions(+), 5 deletions(-) create mode 100644 &quot;content/Excel/SUMIFS \\345\\207\\275\\346\\225\\260.md&quot; create mode 100644 &quot;content/Excel/VBA \\344\\275\\277\\347\\224\\250 ReDim \\345\\256\\236\\347\\216\\260\\344\\272\\214\\347\\273\\264\\345\\212\\250\\346\\200\\201\\346\\225\\260\\347\\273\\204.md&quot; create mode 100644 &quot;content/Excel/VBA \\345\\210\\240\\351\\231\\244\\346\\211\\200\\346\\234\\211\\345\\267\\245\\344\\275\\234\\350\\241\\250\\347\\232\\204\\347\\251\\272\\350\\241\\214.md&quot;\n\n解决方案执行 git config --global core.quotepath false 即可，上述提交的文件名已经可以辨认\n117 files changed, 11670 insertions(+), 5 deletions(-) create mode 100644 content/Excel/SUMIFS 函数.md create mode 100644 content/Excel/VBA 使用 ReDim 实现二维动态数组.md create mode 100644 content/Excel/VBA 删除所有工作表的空行.md\n\n","categories":["通用技术"],"tags":["git"]},{"title":"gitignore-文件通用参考版本","url":"/5886d181-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n案例一\n/mtk/，过滤整个文件夹\n*.zip，过滤所有.zip 文件\n/mtk/do.c，过滤某个具体文件\n\n案例二只需要管理 /mtk/ 目录中的 one.txt 文件，这个目录中的其他文件都不需要管理：\n/mtk/!/mtk/one.txt\n\n\n注意：\n\n\ngit 对于 .ignore 配置文件是按行从上到下进行规则匹配的，如果前面的规则匹配的范围更大，则后面的规则将不会生效。\n如果在创建 .gitignore 文件之前 push，即使在 .gitignore 文件中写入新的过滤规则，这些规则也不会起作用，Git 仍然会对所有文件进行版本管理。\n\n# See https://help.github.com/articles/ignoring-files/ for more about ignoring files..gradle!gradle/wrapper/gradle-wrapper.jar!**/src/main/**/build/!**/src/test/**/build/HELP.md# STS.apt_generated.classpath.factorypath.project.settings.springBeans.sts4-cache# IntelliJ IDEA.idea*.iws*.iml*.iprout/!**/src/main/**/out/!**/src/test/**/out/# NetBeans/nbproject/private//nbbuild//dist//nbdist//.nb-gradle/# VS Code.vscode/# dependencies/node_modules/.pnp.pnp.js# testing/coverage# production/build# misc.DS_Store.env.local.env.development.local.env.test.local.env.production.localnpm-debug.log*yarn-debug.log*yarn-error.log*\n","categories":["通用技术"],"tags":["git"]},{"title":"gradle-问题备忘","url":"/58860e32-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n一、安装\n下载\n解压\n配置系统变量 %GRADLE_HOME% 指向解压路径，配置 path 变量，添加 %GRADLE_HOME%\\bin。\n测试，输入命令 gradle -v 提示版本说明配置成功。\n\n\n环境变量也可以不配置，在 IDE 中（如 Idea）指定路径即可。\n\n二、异常及报错的解决方案汇总⭐ 本地仓库配置参考repositories &#123;    mavenLocal()    maven &#123; url &quot;http://maven.aliyun.com/nexus/content/groups/public/&quot; &#125;    mavenCentral()    jcenter()&#125;\n\n⭐ 指定编译版本可选，在 Idea 中可独立配置。\nsourceCompatibility = 1.8targetCompatibility = 1.8\n\n⭐ 显示指定依赖版本configurations.all &#123;    resolutionStrategy &#123;        force &#x27;org.apache.tomcat.embed:tomcat-embed-core:8.5.39&#x27;    &#125;&#125;\n\n⭐ 如果使用了中文注释，编译时报错添加 withType，编译时用 UTF-8 处理。\ntasks.withType(JavaCompile) &#123;    options.encoding = &quot;UTF-8&quot;&#125;\n\nGradle 强制刷新依赖问题描述旧项目更换环境时由于 gradle 版本不一致导致项目初始化失败。\n解决方案强制刷新依赖，步骤如下：\n1、删除 .gradle 目录，其中包含了旧版本的文件。\n2、修改 gradle-wrapper.properties 文件的版本号，内容如下。例如旧环境使用 6.0.1，新环境使用 6.7.1\ndistributionBase=GRADLE_USER_HOMEdistributionPath=wrapper/distsdistributionUrl=https\\://services.gradle.org/distributions/gradle-6.7.1-bin.zipzipStoreBase=GRADLE_USER_HOMEzipStorePath=wrapper/dists\n\n\n注意：仅修改版本即可，其他内容不变。\n\n3、项目目录下执行如下命令\n\nmacOS：./gradlew build --refresh-dependencies\n\nwindows：gradlew build --refresh-dependencies\n\n\n$ ./gradlew build --refresh-dependenciesWelcome to Gradle 6.7.1!Here are the highlights of this release: - File system watching is ready for production use - Declare the version of Java your build requires - Java 15 supportFor more details see https://docs.gradle.org/6.7.1/release-notes.html&gt; Task :test2021-01-21 04:03:10.262  INFO 633 --- [extShutdownHook] org.quartz.core.QuartzScheduler          : Scheduler quartzScheduler_$_NON_CLUSTERED paused.2021-01-21 04:03:10.263  INFO 633 --- [extShutdownHook] o.s.s.quartz.SchedulerFactoryBean        : Shutting down Quartz Scheduler2021-01-21 04:03:10.263  INFO 633 --- [extShutdownHook] org.quartz.core.QuartzScheduler          : Scheduler quartzScheduler_$_NON_CLUSTERED shutting down.2021-01-21 04:03:10.263  INFO 633 --- [extShutdownHook] org.quartz.core.QuartzScheduler          : Scheduler quartzScheduler_$_NON_CLUSTERED paused.2021-01-21 04:03:10.263  INFO 633 --- [extShutdownHook] org.quartz.core.QuartzScheduler          : Scheduler quartzScheduler_$_NON_CLUSTERED shutdown complete.2021-01-21 04:03:10.264  INFO 633 --- [extShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService &#x27;applicationTaskExecutor&#x27;BUILD SUCCESSFUL in 1m 18s6 actionable tasks: 6 executed\n\n扩展gradlew -? 或 -h 或 --help，显示帮助信息，即会打印可选参数及参数说明信息；\ngradlew --version，版本号（会打印工程用的 Gradle 的版本号、Kotlin、Groovy、Ant、JVM、OS 等的版本号）；\ngradlew tasks --all，查看所有任务，包括缓存任务等；\ngradlew clean，清除工程目录下的 build 文件夹；\ngradlew build， 检查依赖并编译打包，debug、release 环境的包都会打出来；\ngradlew assemble**_，编译指定的包，如 Debug 包（gradlew assembleDebug）、Release 包（gradlew assembleRelease）、渠道包（gradlew assembleOemRelease&#x2F;assembleOemDebug）、定制的版本等等；\ngradlew install_**，编译并安装指定的包，如 Debug 包（gradlew installDebug）、Release 包（gradlew installOemRelease&#x2F;installOemDebug）、定制的版本等等；\ngradlew uninstall\\*\\*，卸载已安装的指定模式的包，如 Debug 包（gradlew uninstallDebug）、Release 包（gradlew uninstallRelease）、渠道包（gradlew uninstallOemRelease&#x2F;uninstallOemDebug）、定制的版本等等；\ngradlew :模块名称:dependencies，查看包依赖关系，如 gradlew :app:dependencies；\ngradlew build -i 或 --info -d 或 --debug -s 或 --stacktrace，编译（build）并打印 debug 模式和 info 等级的日志及所用异常的堆栈信息（–stacktrace）；\ngradlew --refresh-dependencies，强制刷新依赖，即检查依赖是否有更新比如动态版本、SHA1 进行本地 cache 和远程仓库散列码的对比等，有更新则下载更新进行构建；使用这种方式可以避免手动删除 cache；\ngradlew clean build --refresh-dependencies，组合指令，清除构建（gradlew clean）并重新构建（gradlew build），同时强制刷新依赖（gradlew –refresh-dependencies）；\ngradlew --offline，离线模式，即让 Gradle 只使用本地 cache 里的依赖，如果 cache 中没有也不会更新依赖，而是提示编译失败；\n--info，打印堆栈信息；\ngradlew --daemon，守护进程，使用 Gradle 的守护进程构建，能够提高构建效率，如果守护进程没启动或现有的都处于忙碌状态，就启动一个守护进程；\ngradlew --no-daemon，如果你已经配置为使用守护进程构建，可以使用该选项本次不用守护进程构建；\ngradlew --continuous，连续构建，即任务队列中即使某个任务失败，不会终止执行，而是会继续执行下一个任务；\ngradlew --parallel --parallel-threads=N，并行编译；\ngradlew --configure-on-demand，按需编译。\n其他gradlew 的指令有简写的方式：\ngradlew --versio n 可以用简写方式 gradlew -v 代替\ngradlew --hel p 可以用简写方式 gradlew - h 或 gradlew -? 代替\ngradlew --no-rebuil d 可以用简写方式 gradlew - a 代替\ngradlew --debu g 可以用简写方式 gradlew - d 代替\ngradlew --stacktrac e 可以用简写方式 gradlew -s 代替\n可以发现简写的指令只需要一个减号（-）开头，没有简写的指令需要用两个减号（即 --）开头。\n","categories":["通用技术"],"tags":["gradle"]},{"title":"使用-orphan-参数创建独立空白分支","url":"/58865c50-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n创建一个文件夹 testbranch，添加一个文件 main.txt。执行 git init 初始化，执行提交。此时 master 分支有了第一个提交记录：\nmacName:testbranch userName$ git init已初始化空的 Git 仓库于 /Users/userName/Desktop/testbranch/.git/macName:testbranch userName$ git status位于分支 master尚无提交未跟踪的文件:  （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）\tmain.txt提交为空，但是存在尚未跟踪的文件（使用 &quot;git add&quot; 建立跟踪）macName:testbranch userName$ git add .macName:testbranch userName$ git commit -m &quot;init&quot;[master（根提交） cd00bbe] init 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 main.txt\n\n随意修改一下文件内容，再作一次提交。此时查看 master 的提交状态，可以看到有两次提交：\nmacName:testbranch userName$ git add .macName:testbranch userName$ git commit -m &quot;again&quot;[master 9d01aa3] again 1 file changed, 1 insertion(+)macName:testbranch userName$ git log --pretty=oneline -39d01aa3ed29dc9caa1b67175e1e2c7ce4db21712 (HEAD -&gt; master) againcd00bbe75405be350fd7c4cc06d4b304ababe8c5 init\n\n此时新建一个分支，other-normal。使用 git branch -a 后可立刻看到新建的分支。再查看提交，发现与 master 是一致的：\nmacName:testbranch userName$ git checkout -b other-normal切换到一个新分支 &#x27;other-normal&#x27;macName:testbranch userName$ git branch -a  master* other-normalmacName:testbranch userName$ git log --pretty=oneline -39d01aa3ed29dc9caa1b67175e1e2c7ce4db21712 (HEAD -&gt; other-normal, master) againcd00bbe75405be350fd7c4cc06d4b304ababe8c5 init\n\n返回 master，使用 git checkout --orphan other-orphan 新建并切换到分支 other-orphan。再次使用 git branch -a，发现不能看到新建的分支。使用 git log 查看提交情况，发现当前确实在 other-orphan 分支上。\n\n注意：使用 –orphan 参数建立的分支必须要有提交后，才真正创建。\n\nmacName:testbranch userName$ git checkout master切换到分支 &#x27;master&#x27;macName:testbranch userName$ git checkout --orphan other-orphan切换到一个新分支 &#x27;other-orphan&#x27;macName:testbranch userName$ git branch -a  master  other-normalmacName:testbranch userName$ git logfatal: 您的当前分支 &#x27;other-orphan&#x27; 尚无任何提交\n\n将 other-orphan 分支的 main.txt 文件改名为 orphan.txt 并提交，再次查看全部分支，已经可以看到 other-orphan，而且提交情况也是独立的，与 master 分支无关。\nmacName:testbranch userName$ git status位于分支 other-orphan尚无提交要提交的变更：  （使用 &quot;git rm --cached &lt;文件&gt;...&quot; 以取消暂存）\t新文件：   main.txt尚未暂存以备提交的变更：  （使用 &quot;git add/rm &lt;文件&gt;...&quot; 更新要提交的内容）  （使用 &quot;git restore &lt;文件&gt;...&quot; 丢弃工作区的改动）\t删除：     main.txt未跟踪的文件:  （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）\torphan.txtmacName:testbranch userName$ git add .macName:testbranch userName$ git commit -m &quot;orphan init&quot;[other-orphan（根提交） c2533ce] orphan init 1 file changed, 1 insertion(+) create mode 100644 orphan.txtmacName:testbranch userName$ git branch -a  master  other-normal* other-orphanmacName:testbranch userName$ git log --pretty=oneline -3c2533cec5738396e99510ff8566f002547e5e000 (HEAD -&gt; other-orphan) orphan init\n","categories":["通用技术"],"tags":["git"]},{"title":"使用-push-提交到远程仓库出现-The-requested-URL-returned-error-403-错误","url":"/58865c51-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n问题描述曾用过一个 github 账号进行项目提交，现在使用另一个帐号在同一台机器进行提交时出现错误：\nremote: Permission to userName/repositorieName.git denied to OldUserName.fatal: unable to access &#x27;https://github.com/userName/repositorieName.git/&#x27;: The requested URL returned error: 403\n\n问题原因使用第一个账号提交时，系统保存了该账号的用户信息。在使用新帐号提交时，与已保存的用户信息不一致，所以报错。\nwin10 解决方案\n打开 cmd，输入命令：rundll32.exe keymgr.dll,KRShowKeyMgr，出现「存储的用户名和密码」窗口；\n将 github 相关的条目删除；\n重新执行提交命令，按提示输入账户名及密码后，即可提交成功。\n\nmacOS 解决方案\n进入钥匙串，在「登录」下找到「github.com」条目并删除；\n重新执行提交命令，按提示输入账户名及密码后，即可提交成功。\n\n通用解决方案进入库目录，找到 .git&#x2F;config 文件（macOS 可用终端执行 vi .git/config 直接进入修改），参考内容如下：\n[core]\trepositoryformatversion = 0\tfilemode = true\tbare = false\tlogallrefupdates = true\tignorecase = true\tprecomposeunicode = true[remote &quot;origin&quot;]\turl = https://github.com/userName/repositorieName.git\tfetch = +refs/heads/*:refs/remotes/origin/*[branch &quot;other&quot;]\tremote = origin\tmerge = refs/heads/other\n\n将用户名加入 [remote “origin”] 中的 url，最终修改为 url = https://userName@github.com/userName/repositorieName.git，接下来在提交项目时会要求输入密码。此后，系统将保存密码信息，以后这个库的提交将不再要求输入密码，也不会出现 403 错误。\n通用终极解决方案在 clone 项目时就将用户名加入路径，原路径如下：\ngit clone -b other https://github.com/userName/repositoryName.git\n\n添加 userName@，该路径修改为：\ngit clone -b other https://userName@github.com/userName/repositoryName.git\n\n接下来在提交项目时会要求输入密码。此后，系统将保存密码信息，以后这个库的提交将不再要求输入密码，也不会出现 403 错误。\n","categories":["通用技术"],"tags":["github","git"]},{"title":"使用多个-SSH-公钥连接多个-GitHub-远程仓库","url":"/58865c53-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n需求机器 A 一直使用账户 user1 的 SSH 公钥连接 github。现在新建账户 user2，希望在机器 A 也能够以 SSH 方式连接到 github\n问题描述默认情况下，即机器 A 一直使用账户 user1。此时使用命令 $ git remote -v 可以查看当前的远程仓库关联如下：\norigin  git@github.com:user1/repositorieName1.git (fetch)origin  git@github.com:user1/repositorieName1.git (push)\n\n如果 user2 新建一个名为 repositorieName2 的仓库，此时想在机器 A 上使用命令 $ git push -u origin master 提交到远程仓库，会出现如下的错误。\nERROR: Permission to user2/repositorieName2.git denied to user2.fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists.\n\n问题原因机器 A 当前的公钥是 user1 的，user2 没有权限使用；想在 user2 的 github 账户中添加 user1 的公钥？也是不可能的，会提示公钥已经被使用。\n解决方案\n在 user2 的项目目录中打开命令行，执行命令：ssh-keygen -t ed25519 -C &quot;second@email.com&quot; -f ~/.ssh/id_rsa_for_user2，生成专属 user2 的密钥对，再进入 user2 的 github 账户配置公钥。\n\n\n使用 ed25519 是参考了 github 相关文档\n\n\n在 ~/.ssh/ 目录下新建 config 文件，写入以下内容：\n\n\nwin10 路径：C:\\Users\\Admin\\.ssh\n\n\nmacOS 路径：~/user/.ssh\n\n#Default GitHubHost user1HostName github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/user1_publickeyHost user2HostName github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/user2_publickey\n\n\n回到命令行，执行命令：$ git remote set-url origin git@user1:user1/repositorieName1.git，修改默认的关联。也可以把原有的默认关联删除，重新添加。\n再继续执行命令：$ git remote add origin2 git@user2:user2/repositorieName2.git，新添加一个 user2 的关联。\n此时执行命令：$ git remote -v，应是以下结果：\n\n\n如果 clone 用户名 user1 的远程仓库，命令要相应修改为 git clone -b main git@user1:user1/repositorieName1.git\n\norigin2  git@user2:user2/repositorieName2.git (fetch)origin2  git@user2:user2/repositorieName2.git (push)origin  git@user1:user1/repositorieName1.git (fetch)origin  git@user1:user1/repositorieName1.git (push)\n\n\n验证。可分别执行命令：$ ssh -T git@user1、$ ssh -T git@user2，均出现连接成功提示。至此，实现了多个 SSH 公钥连接多个 github 远程仓库的需求。\n\n\n要加 git@ 前缀，否则提示 Permission denied (publickey)（win10 环境，macOS 未实测）\n\nHi user1! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.\n\nHi user2! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.\n\n\n注：github 添加的是如果是 deploy key，会显示库名称，如：username&#x2F;xxx\n\n","categories":["通用技术"],"tags":["github","git"]},{"title":"修复 idea 使用 gradle 构建出错时乱码","url":"/d2d3cb00-ef58-11ee-9bca-69dcfb906dc3/","content":"\n\n\n\n依次进入：菜单栏「Help」 -&gt;「Edit Custom VM Options」 -&gt; 追加 -Dfile.encoding=UTF-8 到末尾 -&gt; 重启 IDEA\n","categories":["通用技术"],"tags":["gradle","idea"]},{"title":"有关-Payload-在维基百科的释义","url":"/58868361-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\nPayload (computing)In computing and telecommunications, the payload is the part of transmitted data that is the actual intended message. Headers and metadata are sent only to enable payload delivery.\n在计算和通信中，有效载荷是传输数据的一部分，是实际要发送的消息。报头和元数据仅用于支持有效载荷的传递。\nIn the context of a computer virus or worm, the payload is the portion of the malware which performs malicious action.\n在计算机病毒或蠕虫的上下文中，有效载荷是执行恶意行为的恶意软件的一部分。\nThe term is borrowed from transportation, where payload refers to the part of the load that pays for transportation.\n这个术语是从「运输」一词借用而来的，「有效载荷」指的是支付运输费用的那部分载荷。\nSecurityIn computer security, the payload is the part of the private user text which could also contain malware such as worms or viruses which performs the malicious action; deleting data, sending spam or encrypting data.[3] In addition to the payload, such malware also typically has overhead code aimed at simply spreading itself, or avoiding detection.\n在计算机安全中，有效载荷是私人用户文本的一部分，它也可能包含恶意软件，如蠕虫或执行恶意行为的病毒；删除数据、发送垃圾邮件或加密数据。除了有效载荷，这种恶意软件通常也有一些开销代码，目的是简单地传播自己，或者避免检测。\nProgrammingIn computer programming, the most common usage of the term is in the context of message protocols, to differentiate the protocol overhead from the actual data. For example, a JSON web service response might be:\n在计算机编程中，该术语最常见的用法是在消息协议上下文中使用，以将协议开销与实际数据区分开来。例如，JSON web 服务响应可能是：\n&#123;  &quot;data&quot;: &#123;    &quot;message&quot;: &quot;Hello, world!&quot;  &#125;&#125;\n\nThe string Hello, world! is the payload, while the rest is protocol overhead.\n字符串 Hello, world! 为有效负载，其余为协议开销。\nNetworkingIn the computer networking, data to be transmitted is the payload, but is almost always encapsulated in some type of a frame composed of framing bits and a frame check sequence.[4][5] Examples are Ethernet frames, Point-to-Point Protocol (PPP) frames, Fibre Channel frames, and V.42 modem frames.\n在计算机网络中，要传输的数据是有效载荷，但几乎总是封装在由帧位和帧检查序列组成的某种类型的帧中。[4][5]的例子是以太网帧、点对点协议（PPP）帧、光纤通道帧和 V.42 调制解调器帧。\n","categories":["通用技术"],"tags":["payload"]},{"title":"Maven-配置阿里云中央仓库和自定义本地仓库","url":"/5885e721-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n问题描述在国内访问 Maven 仓库的速度太慢，导致使用 IDEA 建立 Maven 项目会出现没有 src 目录结构的情况。\n解决方案中央仓库配置在 Maven 安装目录下的 settings.xml 文件中的增加以下内容，使用阿里云的中央仓库。\n&lt;mirrors&gt;\t&lt;mirror&gt;          &lt;id&gt;alimaven&lt;/id&gt;          &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;          &lt;name&gt;aliyun maven&lt;/name&gt;          &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt;    &lt;/mirror&gt;&lt;/mirrors&gt;\n\n自定义本地仓库配置在 Maven 安装目录下的 settings.xml 文件中设置本地仓库。\n&lt;localRepository&gt;D:\\myProgram\\apache-maven-3.5.2\\repositoryx&lt;/localRepository&gt;\n","categories":["部署和安装"],"tags":["maven"]},{"title":"Nginx-配置文件的结构详解及案例","url":"/5885e720-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n相关链接\nnginx 源码：https://trac.nginx.org/nginx/browser\nnginx 官网：http://www.nginx.org/\n\n配置文件结构...              #全局块events &#123;         #events块   ...&#125;http      #http块&#123;    ...   #http全局块    server        #server块1    &#123;        ...       #server全局块        location [PATTERN]   #location块1        &#123;            ...        &#125;        location [PATTERN]   #location块2        &#123;            ...        &#125;    &#125;    server        #server块2    &#123;      ...    &#125;&#125;\n\n\n全局块：配置影响 nginx 全局的指令。一般有运行 nginx 服务器的用户组，nginx 进程 pid 存放路径，日志存放路径，配置文件引入，允许生成 worker process 数等。\nevents 块：配置影响 nginx 服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。\nhttp 块：配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type 定义，日志自定义，是否使用 sendfile 传输文件，连接超时时间，单连接请求数等。\nserver 块：配置虚拟主机的相关参数，一个 http 中可以有多个 server。\nlocation 块：配置请求的路由，以及各种页面的处理情况。\n\n配置文件细节#配置用户或者组，默认为nobody nobodyuser administrator administrators;#允许生成的进程数，默认为1，也可以设置为auto，这个数值简单一点可以设置为cpu的核数grep ^processor /proc/cpuinfo | wc -l，也是auto值，如果开启了ssl和gzip更应该设置成与逻辑CPU数量一样甚至为2倍，可以减少I/O操作。如果nginx服务器还有其它服务，可以考虑适当减少。worker_processes 2;#默认是没有设置，可以限制为操作系统最大的限制65535。worker_rlimit_nofile 10240#指定nginx进程运行文件存放地址pid /nginx/pid/nginx.pid;#设置日志路径和级别。这个设置可以放入全局块，http块，server块，可选级别：debug|info|notice|warn|error|crit|alert|emergerror_log log/error.log;error_log log/error.log notice;error_log log/error.log debug;events &#123;  #设置网路连接序列化，防止惊群现象发生，默认为on，惊群现象：一个网路连接到来，多个睡眠的进程被同时叫醒，但只有一个进程能获得链接，这样会影响系统性能。  accept_mutex on;  #设置一个进程是否同时接受多个网络连接，默认为off  multi_accept on;  #事件驱动模型，可选：select|poll|kqueue|epoll|resig|/dev/poll|eventport，在Linux操作系统下，nginx默认使用epoll事件模型，得益于此，nginx在Linux操作系统下效率相当高。同时Nginx在OpenBSD或FreeBSD操作系统上采用类似于epoll的高效事件模型kqueue。在操作系统不支持这些高效模型时才使用select。  use epoll;  #最大连接数，默认为512，每一个worker进程能并发处理（发起）的最大连接数（包含与客户端或后端被代理服务器间等所有连接数）  #nginx作为反向代理服务器，计算公式最大连接数 = worker_processes * worker_connections/4，所以这里客户端最大连接数是1024，这个可以增到到8192都没关系，看情况而定，但不能超过后面的worker_rlimit_nofile。当nginx作为http服务器时，计算公式里面是除以2。  worker_connections  1024;&#125;http &#123;  #文件扩展名与文件类型映射表  include mime.types;  #默认文件类型，默认为text/plain  default_type  application/octet-stream;  #取消服务日志  #access_log off;  #自定义格式  log_format myFormat &#x27;$remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for&#x27;;  #自定义格式含义  #$remote_addr与$http_x_forwarded_for，记录客户端的ip地址  #$remote_user，记录客户端用户名称  #$time_local，记录访问时间与时区  #$request，记录请求的url与http协议  #$status，记录请求状态；成功是200  #$body_bytes_s ent，记录发送给客户端文件主体内容大小  #$http_referer，记录从那个页面链接访问过来的  #$http_user_agent，记录客户端浏览器的相关信息  #combined为日志格式的默认值  access_log log/access.log myFormat;  #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块，开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，减少用户空间到内核空间的上下文切换。对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。  sendfile on;  #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限  sendfile_max_chunk 100k;  #连接超时时间，默认为75s，可以在http，server，location块，长连接超时时间，单位是秒，这个参数很敏感，涉及浏览器的种类、后端服务器的超时设置、操作系统的设置。长连接请求大量小文件的时候，可以减少重建连接的开销，但假如有大文件上传，65s内没上传完成会导致失败。如果设置时间过长，用户又多，长时间保持连接会占用大量资源。  keepalive_timeout 65;  #http_proxy 设置  #允许客户端请求的最大单文件字节数。如果有上传较大文件，请设置它的限制值  client_max_body_size  10m;  #缓冲区代理缓冲用户端请求的最大字节数  client_body_buffer_size 128k;  proxy_connect_timeout 75;  proxy_send_timeout  75;  proxy_read_timeout  75;  proxy_buffer_size 4k;  proxy_buffers 4 32k;  proxy_busy_buffers_size 64k;  proxy_temp_file_write_size  64k;  proxy_temp_path   /usr/local/nginx/proxy_temp 1 2;  #设定实际的服务器列表  #这个模块通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡，upstream后接负载均衡器的名字，后端realserver以host:port options; 方式组织在 &#123;&#125; 中。如果后端被代理的只有一台，也可以直接写在  upstream mysvr &#123;       server 127.0.0.1:7878;    #热备    server 192.168.10.121:3333 backup;  &#125;  #错误页，若该配置要生效，还需要配置proxy_intercept_errors  error_page 404 https://www.baidu.com;  server &#123;      #单连接请求上限次数      keepalive_requests  120;      #监听端口，默认80，小于1024的要以root启动。可以为listen *:80、listen 127.0.0.1:80等形式。      listen  4545;      #监听地址，可以通过正则匹配。        server_name 127.0.0.1;      #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。      location  ~*^.+$ &#123;        #根目录        #root path;        #设置默认页        #index vv.txt;        #反向代理的路径（和upstream绑定），location 后面设置映射的路径        proxy_pass  http://mysvr;        #拒绝的ip        deny  127.0.0.1;        #允许的ip        allow 172.18.5.54;      &#125;  &#125;  server &#123;      listen  80;      server_name  itoatest.example.com;      root   /apps/oaapp;      charset utf-8;      access_log  logs/host.access.log  main;      #对/所有做负载均衡+反向代理      location / &#123;          root   /apps/oaapp;          index  index.jsp index.html index.htm;          proxy_pass  http://backend;          proxy_redirect off;          # 后端的Web服务器可以通过X-Forwarded-For获取用户真实IP          proxy_set_header  Host  $host;          proxy_set_header  X-Real-IP  $remote_addr;          proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;          proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;      &#125;      #静态文件，nginx自己处理，不去backend请求tomcat      location  ~* /download/ &#123;          root /apps/oa/fs;          #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。          expires 30d;      &#125;      location ~ .*\\.(gif|jpg|jpeg|bmp|png|ico|txt|js|css)$      &#123;             root /apps/oaapp;          expires 7d;      &#125;      location /nginx_status &#123;          stub_status on;          access_log off;          allow 192.168.10.0/24;          deny all;      &#125;      location ~ ^/(WEB-INF)/ &#123;          deny all;      &#125;      #error_page  404  /404.html;      # redirect server error pages to the static page /50x.html      error_page   500 502 503 504  /50x.html;      location = /50x.html &#123;          root   html;      &#125;  &#125;&#125;\n\n宝塔Linux面板默认配置（Nginx 1.8）user  www www;worker_processes auto;error_log  /www/wwwlogs/nginx_error.log  crit;pid        /www/server/nginx/logs/nginx.pid;worker_rlimit_nofile 51200;events  &#123;        use epoll;        worker_connections 51200;        multi_accept on;    &#125;http  &#123;        include       mime.types;    \t\t#include luawaf.conf;    \t\tinclude proxy.conf;        default_type  application/octet-stream;        server_names_hash_bucket_size 512;        client_header_buffer_size 32k;        large_client_header_buffers 4 32k;        client_max_body_size 50m;        sendfile   on;        tcp_nopush on;        keepalive_timeout 60;        tcp_nodelay on;        fastcgi_connect_timeout 300;        fastcgi_send_timeout 300;        fastcgi_read_timeout 300;        fastcgi_buffer_size 64k;        fastcgi_buffers 4 64k;        fastcgi_busy_buffers_size 128k;        fastcgi_temp_file_write_size 256k;    \t\tfastcgi_intercept_errors on;        gzip on;        gzip_min_length  1k;        gzip_buffers     4 16k;        gzip_http_version 1.1;        gzip_comp_level 2;        gzip_types     text/plain application/javascript application/x-javascript text/javascript text/css application/xml;        gzip_vary on;        gzip_proxied   expired no-cache no-store private auth;        gzip_disable   &quot;MSIE [1-6]\\.&quot;;        limit_conn_zone $binary_remote_addr zone=perip:10m;    \t\tlimit_conn_zone $server_name zone=perserver:10m;        server_tokens off;        access_log off;server  &#123;        listen 888;        server_name www.bt.cn;        index index.html index.htm index.php;        root  /www/server/phpmyadmin;        #error_page   404   /404.html;        include enable-php.conf;        location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$        &#123;            expires      30d;        &#125;        location ~ .*\\.(js|css)?$        &#123;            expires      12h;        &#125;        location ~ /\\.        &#123;            deny all;        &#125;        access_log  /www/wwwlogs/access.log;    &#125;include /www/server/panel/vhost/nginx/*.conf;&#125;\n\nhttp反向代理配置案例#运行用户#user www;#启动进程,通常设置成和cpu的数量相等worker_processes  1;#全局错误日志error_log  /www/server/logs/error.log;error_log  /www/server/logs/notice.log  notice;error_log  /www/server/logs/info.log  info;#PID文件，记录当前启动的nginx的进程IDpid        /www/server/logs/nginx.pid;#工作模式及连接数上限events &#123;    worker_connections 1024;    #单个后台worker process进程的最大并发链接数&#125;#设定http服务器，利用它的反向代理功能提供负载均衡支持http &#123;    #设定mime类型(邮件支持类型),类型由mime.types文件定义    include       /www/server/conf/mime.types;    default_type  application/octet-stream;    #设定日志    log_format  main  &#x27;[$remote_addr] - [$remote_user] [$time_local] &quot;$request&quot; &#x27;                      &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;                      &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    access_log    /www/server/logs/access.log main;    rewrite_log     on;    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，    #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.    sendfile        on;    #tcp_nopush     on;    #连接超时时间    keepalive_timeout  120;    tcp_nodelay        on;    #gzip压缩开关    #gzip  on;    #设定实际的服务器列表    upstream server_list&#123;        server 127.0.0.1:8089;    &#125;    #HTTP服务器    server &#123;        listen  80;        server_name  www.test.cn;        index index.html        root /www/server/test;        #编码格式        charset utf-8;        #代理配置参数        proxy_connect_timeout 180;        proxy_send_timeout 180;        proxy_read_timeout 180;        proxy_set_header Host $host;        proxy_set_header X-Forwarder-For $remote_addr;        #反向代理的路径        location / &#123;            proxy_pass http://server_list;        &#125;        #设置静态文件映射的路径        location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123;            root /www/server/views;            #过期时限30天，若变动较少，可适当增加天数；反之减少。            expires 30d;        &#125;        #设定查看Nginx状态的地址        location /NginxStatus &#123;            stub_status           on;            access_log            on;            auth_basic            &quot;NginxStatus&quot;;            auth_basic_user_file  conf/htpasswd;        &#125;        #禁止访问.htxxx文件        location ~ /\\.ht &#123;            deny all;        &#125;        #错误处理页面（可选）        #error_page   404              /404.html;        #error_page   500 502 503 504  /50x.html;        #location = /50x.html &#123;        #    root   html;        #&#125;    &#125;&#125;\n\nhttps反向代理配置案例安全性要求比较高的站点，可能会使用 HTTPS协议。HTTPS的固定端口号为443，使用SSL标准需要引入安全证书，所以在nginx.conf中需要指定证书和对应的key，其他设置和http反向代理一样，只是在Server部分配置有些不同。\n#HTTP服务器  server &#123;      #监听443端口      listen  443 ssl;      #定义www.test.cn      server_name  www.test.cn;      #ssl证书文件位置(常见证书文件格式为：crt/pem)      ssl_certificate      cert.pem;      #ssl证书key位置      ssl_certificate_key  cert.key;      #ssl配置参数（可选）      ssl_session_cache    shared:SSL:1m;      ssl_session_timeout  5m;      #数字签名，此处使用MD5      ssl_ciphers  HIGH:!aNULL:!MD5;      ssl_prefer_server_ciphers  on;      location / &#123;          root   /root;          index  index.html index.htm;      &#125;  &#125;\n\n负载均衡案例有如下应用场景：\n\n应用分别部署在192.168.1.10:80、192.168.1.11:80、192.168.1.12:80三台linux环境的服务器上。\n网站域名为：www.test.cn，公网IP为192.168.1.10\n在公网IP所在的服务器上部署nginx，对所有请求做负载均衡处理\n\nhttp &#123;    #设定mime类型,类型由mime.type文件定义    include       /etc/nginx/mime.types;    default_type  application/octet-stream;    #设定日志格式    access_log    /var/log/nginx/access.log;    #设定负载均衡的服务器列表    upstream server_list &#123;        #weigth参数表示权值，权值越高被分配到的几率越大        server 192.168.1.10:80   weight=1;        server 192.168.1.11:80   weight=3;        server 192.168.1.12:80   weight=7;    &#125;   #HTTP服务器   server &#123;        listen  80;        server_name  www.test.cn;        #对所有请求进行负载均衡请求        location / &#123;            #定义服务器的默认网站根目录位置            root        /root;            #定义首页索引文件的名称            index       index.html index.htm;            #请求转向load_balance_server 定义的服务器列表            proxy_pass  http://server_list;            #其他反向代理的配置(可选)            #proxy_redirect off;            proxy_set_header Host $host;            proxy_set_header X-Real-IP $remote_addr;            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP            proxy_set_header X-Forwarded-For $remote_addr;            proxy_connect_timeout 90;          #nginx跟后端服务器连接超时时间(代理连接超时)            proxy_send_timeout 90;             #后端服务器数据回传时间(代理发送超时)            proxy_read_timeout 90;             #连接成功后，后端服务器响应时间(代理接收超时)            proxy_buffer_size 4k;              #设置代理服务器（nginx）保存用户头信息的缓冲区大小            proxy_buffers 4 32k;               #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置            proxy_busy_buffers_size 64k;       #高负荷下缓冲大小（proxy_buffers*2）            proxy_temp_file_write_size 64k;    #设定缓存文件夹大小，大于这个值，将从upstream服务器传            client_max_body_size 10m;          #允许客户端请求的最大单文件字节数            client_body_buffer_size 128k;      #缓冲区代理缓冲用户端请求的最大字节数        &#125;    &#125;&#125;\n\n多个webapp的配置案例将网站中一些功能相对独立的模块抽离出来，独立维护\n\nwww.test.cn拆分出：A、B、C三个模块\n访问上述模块的方式通过上下文(context)来进行区分:\nwww.test.cn/A/\nwww.test.cn/B/\nwww.test.cn/C/\n\n\n这三个应用需要分别绑定不同的端口号。那么用户在实际访问站点时，访问不同模块时为了避免带端口号访问，需要用到反向代理。\n\nhttp &#123;    upstream A_server&#123;        server www.test.cn:8081;    &#125;    upstream B_server&#123;        server www.test.cn:8082;    &#125;    upstream C_server&#123;        server www.test.cn:8083;    &#125;    server &#123;        #默认指向A        location / &#123;            proxy_pass http://A_server;        &#125;        location /A/&#123;            proxy_pass http://A_server;        &#125;        location /B/ &#123;            proxy_pass http://B_server;        &#125;        location /C/ &#123;            proxy_pass http://C_server;        &#125;    &#125;&#125;\n\n静态站点配置案例网站静态资源都放在了&#x2F;app&#x2F;dist目录下，此时要在nginx.conf中指定首页以及这个站点的host即可。\nworker_processes  1;events &#123;    worker_connections  1024;&#125;http &#123;    include       mime.types;    default_type  application/octet-stream;    sendfile        on;    keepalive_timeout  65;    gzip on;    gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/javascript image/jpeg image/gif image/png;    gzip_vary on;    server &#123;        listen       80;        server_name  static.zp.cn;        location / &#123;            #转发任何请求到index.html            index index.html;            root /app/dist;        &#125;    &#125;&#125;\n\n跨域案例解决跨域问题一般有两种思路：\n\njsonp。把后端根据请求，构造json数据并返回，前端用jsonp跨域。\nCORS。在后端服务器设置http响应头，把需要运行访问的域名加入加入Access-Control-Allow-Origin中。nginx 根据这个思路，提供了一种解决跨域的解决方案。举例：www.test.cn是由一个前端app，一个后端app组成的。前端端口号为9000，后端端口号为8080。前端和后端如果使用http进行交互时，请求会被拒绝，因为存在跨域问题。此时，在 enable-cors.conf 文件中设置 cors：\n\n# allow origin listset $ACAO &#x27;*&#x27;;# set single originif ($http_origin ~* (www.test.cn)$) &#123;  set $ACAO $http_origin;&#125;if ($cors = &quot;trueget&quot;) &#123;    add_header &#x27;Access-Control-Allow-Origin&#x27; &quot;$http_origin&quot;;    add_header &#x27;Access-Control-Allow-Credentials&#x27; &#x27;true&#x27;;    add_header &#x27;Access-Control-Allow-Methods&#x27; &#x27;GET, POST, OPTIONS&#x27;;    add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type&#x27;;&#125;if ($request_method = &#x27;OPTIONS&#x27;) &#123;  set $cors &quot;$&#123;cors&#125;options&quot;;&#125;if ($request_method = &#x27;GET&#x27;) &#123;  set $cors &quot;$&#123;cors&#125;get&quot;;&#125;if ($request_method = &#x27;POST&#x27;) &#123;  set $cors &quot;$&#123;cors&#125;post&quot;;&#125;\n\n在服务器中include enable-cors.conf，即引入跨域配置：\n# 可直接在 nginx config 中 include（推荐）# www.test.cn域名需配合 dns hosts 进行配置# 其中，api 开启了 cors，需配合本目录下另一份配置文件upstream front_server&#123;  server www.test.cn:9000;&#125;upstream api_server&#123;  server www.test.cn:8080;&#125;server &#123;  listen       80;  server_name  www.test.cn;  location ~ ^/api/ &#123;    include enable-cors.conf;    proxy_pass http://api_server;    rewrite &quot;^/api/(.*)$&quot; /$1 break;  &#125;  location ~ ^/ &#123;    proxy_pass http://front_server;  &#125;&#125;\n\nupstream的几种配置方式第一种：轮询\nupstream test&#123;server 192.168.0.1:3000;server 192.168.0.1:3001;&#125;\n\n第二种：权重\nupstream test&#123;server 192.168.0.1 weight=2;server 192.168.0.2 weight=3;&#125;\n这种模式可解决服务器性能不等的情况下轮询比率的调配\n第三种：ip_hash\nupstream test&#123;ip_hash;server 192.168.0.1;server 192.168.0.2;&#125;\n这种模式会根据来源IP和后端配置来做hash分配，确保固定IP只访问一个后端\n第四种：fair需要安装Upstream Fair Balancer Module\nupstream test&#123;server 192.168.0.1;server 192.168.0.2;fair;&#125;\n这种模式会根据后端服务的响应时间来分配，响应时间短的后端优先分配\n第五种：自定义hash需要安装Upstream Hash Module\nupstream test&#123;server 192.168.0.1;server 192.168.0.2;hash $request_uri;&#125;\n这种模式可以根据给定的字符串进行Hash分配\n具体应用：\nserver&#123;  listen 80;  server_name .test.com;  charset utf-8;  location / &#123;    proxy_pass http://test/;  &#125;&#125;\n\nupstream每个地址可设置参数为：\n\ndown: 表示此台server暂时不参与负载。\nweight: 默认为1，weight越大，负载的权重就越大。\nmax_fails: 允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误。\nfail_timeout: max_fails次失败后，暂停的时间。\nbackup: 其它所有的非backup机器down或者忙的时候，请求backup机器，应急措施。\n\n","categories":["部署和安装"],"tags":["nginx"]},{"title":"VMware15 安装 win11","url":"/302e9b10-debd-11ee-bdc4-19fdf0ccb3e7/","content":"\n\n\n\n1、安装要求官网地址：System requirements\nSystem requirements\nThese are the minimum system requirements for installing Windows 11 on a PC. If your device does not meet these requirements, you may not be able to install Windows 11 on your device and might want to consider purchasing a new PC. If you are unsure whether your PC meets these requirements, you can check with your PC Original Equipment Manufacturer (OEM) or, if your device is already running Windows 10, you can use the PC Health Check app to assess compatibility. Note that this app does not check for graphics card or display, as most compatible devices will meet those requirements listed below.\n\n\n\n\n项目\n要求\n\n\n\n1\nProcessor\n1 gigahertz (GHz) or faster with 2 or more cores on a compatible 64-bit processor or System on a Chip (SoC).\n\n\n2\nRAM\n4 gigabyte (GB).\n\n\n3\nStorage\n64 GB or larger storage device Note: See below under “More information on storage space to keep Windows 11 up-to-date” for more details.\n\n\n4\nSystem firmware\nUEFI, Secure Boot capable. Check here for information on how your PC might be able to meet this requirement.\n\n\n5\nTPM\nTrusted Platform Module (TPM) version 2.0. Check here for instructions on how your PC might be enabled to meet this requirement.\n\n\n6\nGraphics card\nCompatible with DirectX 12 or later with WDDM 2.0 driver.\n\n\n7\nDisplay\nHigh definition (720p) display that is greater than 9” diagonally, 8 bits per color channel.\n\n\n8\nInternet connection and Microsoft account\nFor all Windows 11 editions, internet access is required to perform updates and to download and take advantage of some features. A Microsoft account is required for some features.\n\n\n\n内存和 TPM 是需要重点设置的部分，否则提示「这台电脑无法运行 Windows 11，这台电脑不符合安装此版本的 Windows 所需的最低系统要求。」\n\n2、主要安装流程1）进入官网下载 win11 镜像：Windows 11 磁盘映像 (ISO)，选择「Windows 11 (multi-edition ISO)」，点击「下载」，「选择产品语言」后「确认」开始下载镜像；\n2）在 VMware15 新建虚拟机，在向导中选择「稍后安装操作系统」，先修改配置。磁盘大小、CPU 内核等配置均可以使用默认；特别注意内存至少为 4G\n3）设置 TPM：依次进入「编辑虚拟机设置」→「访问控制」→「加密」设置密码；回到「硬件」选项卡，点击「添加」→ 选择「可信平台模块」\n4）选择镜像，正常安装即可。\n3、其他问题1）安装时如果不登陆微软账户，可在添加账户界面选择「注册工作或学校账户」，点击「登陆选项」→「改为域加入」，设置名字后即可跳过登录账号步骤\n2）VMware17下载，官方地址，在「Try Workstation 17 Pro」下载试用版\n","categories":["部署和安装"],"tags":["win"]},{"title":"Windows 环境下压缩版 MySQL 安装（8.0.15 版本）","url":"/ef12a6f0-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n\n1、下载，解压压缩包至目标位置\n2、配置环境变量\n3、初始化。进入 bin 目录，用管理员权限打开 cmd 命令行，执行 mysqld --initialize --console，出现的随机密码 ,sDmQfi:f9u#。如下所示：\nD:\\mysql8.0.15\\bin&gt;mysqld --initialize --console2019-03-27T01:01:24.504964Z 0 [System] [MY-013169] [Server] D:\\mysql8.0.15\\bin\\mysqld.exe (mysqld 8.0.15) initializing of server in progress as process 111202019-03-27T01:01:50.726845Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: ,sDmQfi:f9u#2019-03-27T01:02:01.062899Z 0 [System] [MY-013170] [Server] D:\\mysql8.0.15\\bin\\mysqld.exe (mysqld 8.0.15) initializing of server has completed\n\n4、安装 mysql 服务，运行命令 net start mysql\n附加内容：执行 net start mysql 时提示：\n服务名无效。请键入 NET HELPMSG 2185 以获得更多的帮助。\n\n此时重新安装服务即可：mysqld -install\n5、登录，命令 mysql -u root -p，输入之前的随机密码\n6、修改密码命令：alter user &#39;root&#39;@&#39;localhost&#39; Identified by &#39;新密码&#39;;\n","categories":["部署和安装"],"tags":["mysql"]},{"title":"docker 下配置 Oracle Database Server 12c R2","url":"/2d5fd760-cd69-11ee-be69-4dedf56c58bd/","content":"\n\n\n\n1、下载镜像1）https://hub.docker.com/_/oracle-database-enterprise-edition\n2）填写一些信息，命令行输入 docker login 登陆后下载镜像。\n2、修改源（可选）采用阿里云提供的国内源，Docker Desktop 依次进入 Settings→Docker Engine，在 registry-mirrors 属性下添加地址（仅供参考）：\n&#123;  &quot;registry-mirrors&quot;: [&quot;https://67ewp9up.mirror.aliyuncs.com&quot;],  &quot;insecure-registries&quot;: [],  &quot;debug&quot;: false,  &quot;experimental&quot;: false,  &quot;features&quot;: &#123;    &quot;buildkit&quot;: true  &#125;&#125;\n\n3、执行镜像以 win10 为例。根据文档 Oracle Database Server Docker Image Documentation（Oracle 数据库服务端 Docker 镜像文档）其中 Reusing existing database 小节内容，将本地 D:\\oracledata 挂载到 /ORCL，参考命令行如下：\ndocker run --name oracle -d -p 1521:1521 --restart=always -v D:/oracledata:/ORCL 12a359cd0528\n\n4、登录使用 Docker Desktop 进入容器命令行，执行 source /home/oracle/.bashrc 激活环境变量，再执行 sqlplus /nolog，否则提示找不到命令。\n\n或按照文档提示，直接执行 $ docker exec -it &lt;Oracle-DB&gt; bash -c &quot;source /home/oracle/.bashrc; sqlplus /nolog&quot;，效果相同；或执行 docker exec -it oracle /bin/bash 进入正在运行容器的命令行，执行 sqlplus / as sysdba 登入，这种方式不用激活环境变量。\n\n.bashrc 内容如下：\n# .bashrc# Source global definitionsif [ -f /etc/bashrc ]; then        . /etc/bashrcfi# Uncomment the following line if you don&#x27;t like systemctl&#x27;s auto-paging feature:# export SYSTEMD_PAGER=# User specific aliases and functionsexport ORACLE_HOME=/u01/app/oracle/product/12.2.0/dbhome_1export OH=/u01/app/oracle/product/12.2.0/dbhome_1export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/u01/app/oracle/product/12.2.0/dbhome_1/binexport TNS_ADMIN=/u01/app/oracle/product/12.2.0/dbhome_1/admin/ORCLCDBexport ORACLE_SID=ORCLCDB;\n\n进入后连接至 SYS 账户 connect / as sysdba\n5、修改密码（可选）alter user sys identified by oracle;alter user system identified by oracle;\n\n之后可在命令行输入 sqlplus，用上述用户登录即可\n\n注：SYS 账户必需以 dba 权限登录，应输入用户名 sys as sysdba\n\n6、CDB 和 PDBOracle 12c 引入了 CDB 与 PDB，在 ORACLE 12c 数据库引入的多租用户环境（Multitenant Environment）中，允许一个数据库容器（CDB）承载多个可插拔数据库（PDB）。CDB 全称为 Container Database，翻译为数据库容器，PDB 全称为 Pluggable Database，即可插拔数据库。在 ORACLE 12c 之前，实例与数据库是一对一或多对一关系（RAC），即一个实例只能与一个数据库相关联，数据库可以被多个实例所加载。而实例与数据库不可能是一对多的关系。当进入 ORACLE 12c 后，实例与数据库可以是一对多的关系。\nCDB 相当于操作系统，调用并管理各个 PDB。PDB 相当于真正提供业务需求的数据库实例。ORACLE 12c 安装后只创建了 CBD，需要自己生成相应的 PDB。平时的数据库操作大多数和 PDB 相关。\n\n注：数据库创建完成后默认带有一个名为 ORCLPDB1 的 PDB\n\n相关命令：\n\nselect name,open_mode from v$pdbs; 用来查看当前 CDB 容器中包含的 PDB 容器\nshow pdbs; 查看全部目前的 PDB\nshow con_name; 查看当前所在是 CDB 还是 PDB\n\n7、用户分类Oracle 12c 的用户分为公共用户和本地用户\n公共用户：可以为 CDB 管理员创建，公共用户是在所有的 PDB 中都可以使用的用户，公共用户的信息存在 CDB$ROOT 中，并且存在于所有的 PDB 中。公共用户需要连到 CDB 进行创建和管理。在 CDB 中创建的用户默认就是公共用户，可以省略 container&#x3D;all，在 CDB 中只能创建公共用户，不能创建本地用户。\n本地用户：本地用户只会存储在对应的 PDB 中，在 PDB 中创建的用户默认就是本地用户，可以省略 container&#x3D;current，在 PDB 中只能创建本地用户，不能创建公共用户。\n为了区分公共用和本地用户，引进了新的参数 common_user_perfix，表示公共用户的前缀，默认为 c##，也就是说如果创建了一个公共用户，必须带上前缀，如果不加 c##，则会提示错误 ORA-65096：公用用户名或角色名无效。此前缀是可以进行修改的，但是建议不要修改。执行以下命令查看前缀：\nshow parameter common_user;\n\n创建用户并授权\ncreate user C##test identified by 123456;grant connect,source,dba to C##test;\n\n8、切换至 PDB注意：使用这个命令需要的 sysdba 级别的权限，否则无法执行。切换后才可使用当前 PDB 的私有用户进行操作，12c 数据库创建完成后，默认情况下，使用 sqlplus / as sysdba 登录连接的是 CDB\n执行 show con_name;，当前在 CDB 容器中\nCON_NAME------------------------------CDB$ROOT\n\n使用 show pdbs; 查询目前现有的 PDB 容器\n    CON_ID CON_NAME                       OPEN MODE  RESTRICTED---------- ------------------------------ ---------- ----------         2 PDB$SEED                       READ ONLY  NO         3 ORCLPDB1                       READ WRITE NO\n\n使用下列命令切换\nSQL&gt; alter session set container=ORCLPDB1;\n\n执行 show con_name; 验证：\nCON_NAME------------------------------ORCLPDB1\n\n说明切换成功，此时就可以创建本地用户并授权：\nSQL&gt; create user test identified by 123456;SQL&gt; grant dba to test;\n\n9、切换至 CDB如果要切换回 CDB 容器只需将容器名换为 CDB 容器的名字即可，一个 CDB 只有一个根\nSQL&gt; alter session set container=CDB$ROOT;\n\n10、登陆或连接使用 DataGrip 登录 PDB 使用 serviceName 登录，默认为实例名称后加 localdomain（例如 ORCLPDB1.localdomain），可通过 tnsnames.ora 查看。查找文件所在路径：\nfind / -name tnsnames.ora/u01/app/oracle/product/12.2.0/dbhome_1/network/admin/samples/tnsnames.ora/u01/app/oracle/product/12.2.0/dbhome_1/admin/ORCLCDB/tnsnames.ora\n\n观察环境变量 export TNS_ADMIN=/u01/app/oracle/product/12.2.0/dbhome_1/admin/ORCLCDB 可知正确路径。从 ORCLCDB/tnsnames.ora 可看到 ORCLCDB 和 ORCLPDB 的 serviceName，或用命令查询当前可用 serviceName\nSQL&gt; select name,pdb from v$services order by name;\n\n11、查看用户如果处在 CDB$ROOT 中查询 DBA 视图，那么只能查询到公共的数据字典；如果处在 PDB 中，那么查询 DBA 视图只能查到此 PDB 的数据字典。12c 中新增了 CDB 数据字典,可以查看所有的数据字典。所以，当在 CDB 中查询 dba_users，那你只能查询到公共的用户，当处于 PDB 中，只能查到 PDB 中的本地用户；如果想查询所有的用户，可以使用下的语句。其中新增 oracle_maintained 字段提示了此用户是否由 oracle 管理：\nSQL&gt; select a.username,a.common,a.con_id,decode(a.CON_ID,1,&#x27;CDB$ROOT&#x27;,b.pdb_name) name from cdb_users a,cdb_pdbs bwhere a.con_id=b.con_id(+) and oracle_maintained=&#x27;N&#x27;order by a.con_id,a.username;\n\n以此类推，公共用户修改密码只能在 CDB$ROOT 中进行修改；本地用户只能在 PDB 中进行修改：\nSQL&gt; alter user c##cdb identified by newcdb;\n\n12、删除用户命令：drop user C##用户名\n若用户拥有对象，则不能直接删除，否则将返回一个错误值。指定关键字 cascade，可删除用户所有的对象，然后再删除用户。\n13、用户授权创建一个公共用户，此时是没有任何登录权限的：\nSQL&gt; create user c##cdb identified by cdb;User created.SQL&gt; show pdbs;    CON_ID CON_NAME                       OPEN MODE  RESTRICTED---------- ------------------------------ ---------- ----------         2 PDB$SEED                       READ ONLY  NO         3 ORCLPDB1                       READ WRITE NOSQL&gt; show con_nameCON_NAME------------------------------CDB$ROOTSQL&gt; conn c##cdb/cdbERROR:ORA-01045: user c##cdb lacks CREATE SESSION privilege; logon deniedWarning: You are no longer connected to ORACLE.\n\n在 CDB 中赋予 c##cdb 登录权限后，就可以登录到 CDB。登录 sys 账户进行授权（登录时默认在 CDB 中）：\nconn / as sysdbaConnected.SQL&gt; grant create session to c##cdb;Grant succeeded.\n\n\n注：grant 不添加 container 子句，则默认为当前容器，即 grant create session to c##cdb container=current;\n\n配置权限后可成功切换用户：\nSQL&gt; conn c##cdb/cdbConnected.\n\n在 PDB 内部的授权为本地授权，可以在 PDB 中对公共用户进行授权。公共用户虽然在所有 PDB 中都存在，但并不是创建了公共用户就有权限访问所有 PDB，还需要单独赋予 create session 权限。此时还没有赋予单独的 PDB 权限给账户，当尝试连接其他 PDB 时会报错：\nSQL&gt; alter session set container=ORCLPDB1;ERROR:ORA-01031: insufficient privileges\n\n通过登录 sys 账户连接 PDB，再对账户进行授权：\nSQL&gt; conn / as sysdbaConnected.SQL&gt; show con_nameCON_NAME------------------------------CDB$ROOTSQL&gt; alter session set container=brent;Session altered.SQL&gt; grant create session to c##cdb with admin option container=current;Grant succeeded.\n\n或者对公共用户进行公共授权，授权之后的用户就拥有了所有 PDB 的相关权限：\nSQL&gt; grant create session to c##cdb container=all;\n\n14、查看权限SQL&gt; select * from dba_sys_privs where grantee like &#x27;C##%&#x27;;\n\n15、撤销权限SQL&gt;revoke create table from test;\n\n16、通过 pdbseed 新建 PDB查找 pdbseed 目录的路径，例如 /u02/app/oracle/oradata/ORCL/pdbseed（可在挂载目录中查看），使用 sys 用户下执行下列命令：\nSQL&gt; create pluggable database ORCLPDB2 admin user pdbadmin identified by oracle roles=(resource) file_name_convert=(&#x27;/u02/app/oracle/oradata/ORCL/pdbseed&#x27;,&#x27;/u02/app/oracle/oradata/ORCL/orclpdb2&#x27;);Pluggable database created.SQL&gt; show pdbs;    CON_ID CON_NAME                       OPEN MODE  RESTRICTED---------- ------------------------------ ---------- ----------         2 PDB$SEED                       READ ONLY  NO         3 ORCLPDB1                       READ WRITE NO         4 ORCLPDB2                       MOUNTED\n\n\n注 1：orclpdb2 目录不存在，执行后自行建立；注 2：要在 CBD 容器下下执行该命令\n\n17、克隆本地 PDB 新建 PDB被克隆的 PDB 模式要修改为 read only\nSQL&gt; alter pluggable database ORCLPDB2 close;SQL&gt; alter pluggable database ORCLPDB2 open read only;SQL&gt; create pluggable database ORCLPDB3 from ORCLPDB2 file_name_convert=(&#x27;/u02/app/oracle/oradata/ORCL/orclpdb2&#x27;,&#x27;/u02/app/oracle/oradata/ORCL/orclpdb3&#x27;);\n\n18、更改 PDB 模式alter pluggable database ORCLPDB2 open read write;\n\n登陆时提示错误\nERROR:ORA-01017: invalid username/password; logon deniedWarning: You are no longer connected to ORACLE.\n\n注意用户是否授权，另外要增加连接符，具体在 tnsnames.ora 文件中新加一个连接符，再重新启动监听器 lsnrctl start\n19、保持 PDB 模式完成常规配置后，当 CDB 实例关闭重新开启后会重置 PDB 的模式为 MOUNTED，此时可执行 alter pluggable database ORCLPDB2 open; 手动启动。或在 PDB 启动后使用 alter pluggable database all save state; 命令，保持状态，让 PDB 保持启动。或者通过在 CDB 新建触发器：\nSQL&gt;create or replace trigger auto_open_pdbsafter startup on databasebeginexecute immediate &#x27;alter pluggable database all open&#x27;;end;/\n\n其他相关命令：\n\nalter pluggable database all except ORCLPDB2 close;，除 ORCLPDB2 外关闭全部 PDB\nalter pluggable database all open;，开启全部 PDB\nalter pluggable database all close immediate;，关闭全部 PDB\nshutdown immediate;，关闭 CDB\nstartup mount;，启动 CDB\n\n20、密码过期1、执行 docker exec -it oracle /bin/bash 进入正在运行容器的命令行，执行 sqlplus / as sysdba 登入\n2、关闭密码过期机制\nalter profile default limit password_life_time unlimited;\n\n3、切换到所在容器，例如 ORCLPDB1\nalter session set container=ORCLPDB1;\n\n4、重新修改用户密码 abc2，再改回旧密码 abc 即可\nalter user abc identified by abc2;\n\n其他1、 如果在 PDB 中已经存在一个用户或者角色，则在 CDB 中不能创建相同的账号或者角色名。\n2、 同样在 CDB 中创建账号后不能在 PDB 中出现同名的账号，因 CDB 中的账号对所有的 PDB 都是有效的。\n3、 在 CDB 中创建的账号将会在全部的 PDB 中出现，但是在 CDB 中的授权，如非特别指定的话，并不能传递到 PDB 中。\n4、 针对同一个共有账号在 PDB 下创建的账号在 CDB 是看不到的。针对同一个共有账号，在 PDB 和 CDB 下创建的共有账号因在 CDB 和 PDB 下被赋予了不同的含义，故在 CDB 下创建的对象和在 PDB 下创建的对象是可以同名的，反之也成立。\n其他查询1、查看所有用户：\nselect * from dba_users;select * from all_users;select * from user_users;\n\n2、查看用户或角色系统权限(直接赋值给用户或角色的系 bai 统权限)：\nselect * from dba_sys_privs;select * from user_sys_privs; (查看当前用户所拥有的权限)\n\n3、查看角色(只能查看登陆用户拥有的角色)所包含的权限\nsql&gt;select * from role_sys_privs;\n\n4、查看用户对象权限：\nselect * from dba_tab_privs;select * from all_tab_privs;select * from user_tab_privs;\n\n5、查看所有角色：\nselect * from dba_roles;\n\n6、查看用户或角色所拥有的角色：\nselect * from dba_role_privs;select * from user_role_privs;\n\n7.查看哪些用户有 sysdba 或 sysoper 系统权限(查询时需要相应权限)\nselect * from V$PWFILE_USERS\n","categories":["部署和安装"],"tags":["docker"]},{"title":"hexo-next-主题构建首页动态更新目录","url":"/5886f890-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n\n\n\n\n1 问题及需求问题\n\n首页（home）默认显示按日期排序的文章列表，使用 &lt;!-- more --&gt; 省略内容仍显得繁杂冗长；\n分类（categories）页面虽然有按类型、日期排序的文章列表，但切换分类需要往返多次。\n\n需求\n\n建立一个首页目录，将文章分类（categories 参数）和标题，分别作为列表的一级、二级显示；\n标题即为文章链接，点击可直接到达；想查看其他分类，直接回到首页即可。\n\n2 解决方案2.1 建立文件在 source/ 下建立 index.md，命名标题，内容留空。\n2.2 关闭默认首页修改 hexo 配置文件 _config.yml，找到 index_generator 配置项，修改 path 属性为一个无效值：\nindex_generator:  path: &#x27;xxxx&#x27;  per_page: 10  order_by: -date\n\n此时启动项目后，首页将不再出现文章列表，转而显示 index.md 内容。\n\n注：index.md 在渲染后成为 index.html\n\n3 动态更新目录若文章分类多，每次更新、调整文章都需要将相应链接手工同步到首页也是一件相当繁琐的事情。因此有必要考虑自动更新首页。\n3.1 hexo 加载顺序根据 hexo 文档 https://hexo.io/zh-cn/api/posts#%E6%B8%B2%E6%9F%93 关于渲染顺序的说明，要实现 index.md 的写入，要在 hexo g 命令执行之前完成，可引入 before_post_render 过滤器实现该需求。\n3.2 hexo 过滤器过滤器文档：https://hexo.io/zh-cn/api/filter#%E6%A6%82%E8%A6%81\n在主题目录下 themes\\next\\filters\\ 新建 index.js，添加 priority 分别为 9 和 10 的两个 before_post_render 过滤器，如下所示：\n&#x27;use strict&#x27;const categoriesMap = new Map();hexo.extend.filter.register(&#x27;before_post_render&#x27;, data =&gt; &#123;    // 首页目录不显示草稿内容    if (data.source.indexOf(&quot;_drafts&quot;) &gt;= 0) &#123;        return data;    &#125;    if (data.path.indexOf(&quot;index&quot;) &lt; 0 &amp;&amp; data.categories.length &gt; 0) &#123;        let curCategorie = data.categories.data[0].name;        if (categoriesMap.has(curCategorie)) &#123;            let valueArray = categoriesMap.get(curCategorie);            valueArray = valueArray.concat(`  - [$&#123;data.title&#125;](/$&#123;data.path&#125;)\\n`)            categoriesMap.set(curCategorie, valueArray);        &#125; else &#123;            categoriesMap.set(curCategorie, [`  - [$&#123;data.title&#125;](/$&#123;data.path&#125;)\\n`]);        &#125;    &#125;    return data;&#125;, 9);hexo.extend.filter.register(&#x27;before_post_render&#x27;, data =&gt; &#123;    // 精确定位index.html，防止误写其他路径不同但同名的文件    if (data.path.indexOf(&quot;index&quot;) === 0) &#123;        for (let key of categoriesMap.keys()) &#123;            data.content += `- $&#123;key&#125;\\n`            let valueArray = categoriesMap.get(key);            valueArray.forEach(element =&gt; &#123;                data.content += element;            &#125;);        &#125;        return data;    &#125;    return data;&#125;, 10);\n\n代码说明\n\n第一个过滤器遍历全部文章，获取所有现存的分类及所属文章链接；\n第二个过滤器写入 index.html\n\n3.3 有关属性为探究 data 为何物，可打断点观察其结构：\n&#123;  title: &quot;DataGrip-2018.3.4-数据导出配置案例&quot;,  date: &#123;……文章生成日期的有关参数（略）&#125;,  _content: &quot;……正文内容（略）&quot;,  source: &quot;_posts/DataGrip-2018-3-4-数据导出配置案例.md&quot;,  raw: &quot;……正文内容（略）&quot;,  slug: &quot;DataGrip-2018-3-4-数据导出配置案例&quot;,  published: true,  updated: &#123;……文章更新日期的有关参数（略）&#125;,  comments: true,  layout: &quot;post&quot;,  photos: [  ],  link: &quot;&quot;,  _id: &quot;cljzhnjmb001oz0u6en5ab6xb&quot;,  path: &quot;2022/12/07/DataGrip-2018-3-4-数据导出配置案例/&quot;,  permalink: &quot;http://www.dcheng.site/2022/12/07/DataGrip-2018-3-4-%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA%E9%85%8D%E7%BD%AE%E6%A1%88%E4%BE%8B/&quot;,  full_source: &quot;C:\\\\mainProjects\\\\blog\\\\source\\\\_posts\\\\DataGrip-2018-3-4-数据导出配置案例.md&quot;,  asset_dir: &quot;C:\\\\mainProjects\\\\blog\\\\source\\\\_posts\\\\DataGrip-2018-3-4-数据导出配置案例\\\\&quot;,  tags: &#123;    data: [      &#123;        name: &quot;DataGrip&quot;,        _id: &quot;cljzhnjmc001uz0u6hlov172o&quot;,        slug: &quot;DataGrip&quot;,        path: &quot;tags/DataGrip/&quot;,        permalink: &quot;http://www.dcheng.site/tags/DataGrip/&quot;,        posts: &#123;          data: [          ],          length: 0,        &#125;,        length: 0,      &#125;,    ],    length: 1,  &#125;,  categories: &#123;    data: [      &#123;        name: &quot;配置案例&quot;,        _id: &quot;cljzhnjmc001tz0u6967u3bji&quot;,        slug: &quot;配置案例&quot;,        path: &quot;categories/配置案例/&quot;,        permalink: &quot;http://www.dcheng.site/categories/%E9%85%8D%E7%BD%AE%E6%A1%88%E4%BE%8B/&quot;,        posts: &#123;          data: [          ],          length: 0,        &#125;,        length: 0,      &#125;,    ],    length: 1,  &#125;,  content: &quot;……正文内容（略）&quot;,  site: &#123;    data: &#123;    &#125;,  &#125;,&#125;\n\n4 最终效果\n图1-默认效果\n\n\n\n\n图2-动态目录效果\n\n\n","categories":["部署和安装"],"tags":["未标记"]},{"title":"win-环境下-node-压缩版安装","url":"/ed0e3b50-441c-11ee-bc1a-25c3478a32d1/","content":"\n\n\n\n1、下载 Windows Binary (.zip)包地址：https://nodejs.org/en/download\n2、设置解压到安装位置后，新建 node-cache 和 node-global 两个目录。开启 cmd 控制台切换到安装位置，执行配置：\ncd D:\\node-v18.17.1-win-x64npm config set cache &quot;D:\\node-v18.17.1-win-x64\\node-cache&quot;npm config set prefix &quot;D:\\node-v18.17.1-win-x64\\node-global&quot;\n\n添加如下环境变量\nD:\\node-v18.17.1-win-x64D:\\node-v18.17.1-win-x64\\node-global\n\n任意位置执行查看版本命令确认安装情况：\nc:\\&gt;npm -v9.6.7c:\\&gt;node -vv18.17.1\n","categories":["部署和安装"],"tags":["node"]},{"title":"ubuntu-配置共享文件夹","url":"/0255ad60-4353-11ee-bed6-3d33eaf7fa7a/","content":"\n\n\n\n官网：https://www.samba.org/\n1、安装 samba 服务器执行以下命令\nsudo apt-get install samba samba-common\n\n可通过 samba -V 查看是否安装成功，输出结果：\nVersion 4.15.13-Ubuntu\n\n2、创建目录假设共享路径为：/home/share\n修改权限\nsudo chmod 777 /home/share\n\n3、修改配置文件执行 sudo vim /etc/samba/smb.conf 增加如下内容：\n[src_share]comment = sharepath = /home/ubuntu/srcpublic = yesbrowseable = yeswritable = yesvalid users = ubuntucreate mask = 777directory mask = 777available = yes\n\n参数意义\n\n[src_share]，显示的共享文件夹名称\ncomment：注释说明\npath：共享路径\nbrowseable：是否在 Window Explorer 中显示该目录\nwritable：写权限\nvalid users：可以访问的用户\ncreate mask：新建立的文件的属性\ndirectory mask：新建立的目录的属性\navailable：共享资源是否可用\n\n4、添加 samba 访问账号及密码sudo smbpasswd -a username\n\n\n注：该用户需要在系统用户列表；可执行 sudo pdbedit -L 查看允许访问的用户。\n\n5、重启服务sudo service smbd restart\n","categories":["部署和安装"],"tags":["ubuntu"]},{"title":"win、ubuntu 环境安装 postgresql 15","url":"/0255ad61-4353-11ee-bed6-3d33eaf7fa7a/","content":"\n\n\n\n1、win10 或 Windows Server 2022 Datacenter下载地址：https://www.enterprisedb.com/download-postgresql-binaries\n1.1、执行安装1）解压，并添加 pgsql\\bin 到环境变量。\n2）新建目录 C:\\pgsql\\data，执行 initdb -U postgres -A password -E UTF-8 -W -D C:\\pgsql\\data，该步骤将提示输入密码。\n3）执行 pg_ctl -D &quot;C:/pgsql/data&quot; start 启动服务。\n4）执行 psql -U postgres 登录，输入之前步骤的密码。\n\n注意：控制台方式启动服务，当关闭控制台时，服务随即终止。若要保持后台启动，需要注册服务。\n\n5）注册服务：以管理员身份执行 pg_ctl register -N PostgreSQL -D &quot;C:/pgsql/data&quot;，再执行 net start PostgreSQL\n2、ubuntu 22.042.1、官方文档文档地址：https://www.postgresql.org/download/linux/ubuntu/ （version：20230726）\nLinux downloads (Ubuntu) Ubuntu\nPostgreSQL is available in all Ubuntu versions by default. However, Ubuntu “snapshots” a specific version of PostgreSQL that is then supported throughout the lifetime of that Ubuntu version. Other versions of PostgreSQL are available through the PostgreSQL apt repository.\nPostgreSQL Apt Repository\nIf the version included in your version of Ubuntu is not the one you want, you can use the PostgreSQL Apt Repository. This repository will integrate with your normal systems and patch management, and provide automatic updates for all supported versions of PostgreSQL throughout the support lifetime of PostgreSQL.\nThe PostgreSQL Apt Repository supports the current versions of Ubuntu:\n\nkinetic (22.10, non-LTS)\njammy (22.04, LTS)\nfocal (20.04, LTS)\nbionic (18.04, LTS)\n\non the following architectures:\n\namd64\narm64 (18.04 and newer; LTS releases only)\ni386 (18.04 and older)\nppc64el (LTS releases only)\n\nTo use the apt repository, follow these steps:\n# Create the file repository configuration:sudo sh -c &#x27;echo &quot;deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main&quot; &gt; /etc/apt/sources.list.d/pgdg.list&#x27;# Import the repository signing key:wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -# Update the package lists:sudo apt-get update# Install the latest version of PostgreSQL.# If you want a specific version, use &#x27;postgresql-12&#x27; or similar instead of &#x27;postgresql&#x27;:sudo apt-get -y install postgresql-15\n\nFor more information about the apt repository, including answers to frequent questions, please see the PostgreSQL Apt Repository page on the wiki.\nIncluded in distribution\nUbuntu includes PostgreSQL by default. To install PostgreSQL on Ubuntu, use the apt-get (or other apt-driving) command:\napt-get install postgresql-12\n\nThe repository contains many different packages including third party addons. The most common and important packages are (substitute the version number as required):\n2.2、执行 pg-15.3 安装执行 sudo apt-get -y install postgresql-15 将安装 15.3\n2.3、查看服务执行 sudo systemctl status postgresql 查看服务运行情况：\npostgresql.service - PostgreSQL RDBMS     Loaded: loaded (/lib/systemd/system/postgresql.service; enabled; vendor preset:&gt;     Active: active (exited) since Tue 2023-07-25 09:55:14 CST; 12min ago   Main PID: 4625 (code=exited, status=0/SUCCESS)        CPU: 2ms\n\n2.3、查看路径执行 ps -ef | grep postgres | grep -v &#39;grep&#39; 显示如下内容：\npostgres    5671       1  0 09:55 ?        00:00:00 /usr/lib/postgresql/15/bin/postgres -D /var/lib/postgresql/15/main -c config_file=/etc/postgresql/15/main/postgresql.confpostgres    5672    5671  0 09:55 ?        00:00:00 postgres: 15/main: checkpointerpostgres    5673    5671  0 09:55 ?        00:00:00 postgres: 15/main: background writerpostgres    5675    5671  0 09:55 ?        00:00:00 postgres: 15/main: walwriterpostgres    5676    5671  0 09:55 ?        00:00:00 postgres: 15/main: autovacuum launcherpostgres    5677    5671  0 09:55 ?        00:00:00 postgres: 15/main: logical replication launcher\n\n可获知以下信息：\n\n安装目录：/usr/lib/postgresql/15/bin/postgres\n初始化数据库的数据目录：/var/lib/postgresql/15/main\n配置文件路径：/etc/postgresql/15/main/postgresql.conf\n\n2.4、登录1）切换用户：执行 su - postgres\n\n注意：如果提示 su：认证失败，需要执行 sudo passwd postgres 设置密码再切换，输入设置的密码即可。\n\n2）输入 psql 登录\n\n如果本地登录需要切换新增的角色，要在 pg_hba.conf 配置认证方式。例如：local  all  all  md5\n\n3、通用部分3.1、创建角色CREATE ROLE name [ [ WITH ] option [ ... ] ]\n\noption 属性\n\n登录权限（LOGIN ），具有该属性的角色才能连接数据库。\n创建数据库（CREATEDB），具有该属性的角色才能够创建数据库（超级用户除外）。\n创建角色（CREATEROLE），具有该属性的角色才能够创建其他角色（超级用户除外）。\n启动复制（REPLICATION），具有该属性的角色才能够启动流复制（超级用户除外）。\n密码（PASSWORD），只有当用户连接数据库使用的客户端认证方法要求提供密码时，密码属性才有意义。password 和 md5 认证方法需要使用密码。\n超级用户（SUPERUSER），数据的超级用户可以避开所有的权限检查，只验证登录权限。\n\n例 1，创建角色并赋予【登录、创建数据库、密码】属性：create role abc123 login createdb password &#39;abc123&#39;;\n例 2，修改角色属性：alter role &lt;role_name&gt; login createdb;\n\n注：可执行 \\du 查看当前全部角色\n\n3.2、查看版本执行 psql --version 查看当前版本：\npsql (PostgreSQL) 15.3 (Ubuntu 15.3-1.pgdg22.04+1)\n\n3.3、远程登录\n修改 /etc/postgresql/15/main/pg_hba.conf，按需增加配置，如：host  all  all  0.0.0.0/0  md5\n修改配置文件 postgresql.conf，将 listen_addresses = &#39;localhost&#39; 修改为 listen_addresses = &#39;*&#39;\n执行 sudo systemctl restart postgresql 重启服务\n\n\n注意：即使修改配置文件，还应保证防火墙放行。尤其是 win 环境，需要在防火墙入站规则添加 5432 端口的放行规则。\n\n3.3.1、pg_hba.conf 配置参数1）TYPE（主机类型）\n\nlocal，unix-domain 的 socket 连接\nhost，TCP&#x2F;IP socket\nhostssl，SSL 加密的 TCP&#x2F;IP socket\n\n2）DATABASE（数据库名称）\nall、sameuser、samerole、replication、数据库名称，或者多个数据库名称用 逗号\n\n注意：all 不匹配 replication\n\n3）USER（用户名称）\nall、一个用户名、一组用户名，多个用户时，可以用逗号隔开，或者在用户名称前缀 +，在 USER 和 DATABASE 字段，也可以写一个单独的文件名称用 @ 前缀，该文件包含数据库名称或用户名称。\n4）ADDRESS（地址范围）\n该参数可以为 主机名称 或者 IP/32(IPV4) 或 IP/128(IPV6)，主机名称以 . 开头，samehost 或 samenet 匹配任意 ip 地址\n5）METHOD（验证方式）\n\ntrust，无需密码验证可直接连接访问\nreject，拒绝访问\nmd5，以 md5 加密\npassword，明文传输密码\nscram-sha-256\ngss\nsspi\nident\npeer\npam\nldap\nradius\ncert\n\n\n注意：若为 password 则发送的为明文密码\n\n4、问题集锦4.1、UTC 时间与系统时间偏差 8 小时解决方案：\n1）显式指定 PRC\nselect now() at time zone &#x27;PRC&#x27;;\n\n结果：2023-07-30 16:01:17.285747\n2）进一步指定格式\nselect to_char(now() at time zone &#x27;PRC&#x27;,&#x27;YYYY-MM-DD hh24:mi:ss&#x27;);\n\n结果：2023-07-30 16:03:34\n","categories":["部署和安装"],"tags":["postgresql"]},{"title":"win 删除服务","url":"/3a21e150-815b-11ee-8ef0-c118c637cb12/","content":"\n\n\n\n1、在注册表中删除1）进入注册表，定位至 计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\n2）找到要删除的服务，重启生效\n2、cmd 命令行删除1）以管理员身份进入 cmd\n2）执行 sc delete 服务名称，无需重启，立即生效\n3、powershell 命令行删除1）执行 sc delete 服务名称，重启生效\n\n查看系统全部服务状态、名称、描述，可执行 Get-Service\n\n","categories":["部署和安装"],"tags":["win"]},{"title":"win-本地部署-mariadb","url":"/bf9389c0-446f-11ee-90e9-49c3e96e9425/","content":"\n\n\n\n1、环境\nWindows 10 专业版 22H2\nmariadb-10.11.5\n\n2、部署步骤1）进入下载列表 https://mariadb.org/download/?t=mariadb&amp;p=mariadb&amp;r=10.11.5&amp;os=windows&amp;cpu=x86_64&amp;pkg=zip&amp;m=aliyun，获取 mariadb-10.11.5-winx64.zip，解压\n2）在 mariadb-10.11.5-winx64 目录下新建 data 文件夹，即为数据目录。并将 mariadb-10.11.5-winx64\\bin 添加到环境变量，则以下命令在 cmd 可直接执行。\n3）安装 MairaDB 服务管理员权限下在 cmd 终端执行 mysqld.exe --install MariaDB\n4）初始化管理员权限下在 cmd 终端执行 mysql_install_db.exe\n5）启动服务管理员权限下在 cmd 终端执行 net start mariaDB\n6）初始登录配置\n\n执行 mariadb -u root（初始登录无密码）\n执行 alter user &quot;root&quot;@&quot;localhost&quot; identified by &quot;root&quot;; 修改 root 账户密码\n\n","categories":["部署和安装"],"tags":["win","mariadb"]},{"title":"win 环境部署 FastAPI 应用为服务","url":"/327f6eb0-845a-11ef-97a5-ef015341acb0/","content":"\n\n\n\n0、环境1）win 10&#x2F;11 或 win server\n2）python 3.11.9\n3）nssm 2.24\n1、导出项目依赖1）默认使用 poetry 进行依赖管理。执行 poetry export -f requirements.txt --without-hashes &gt; requirements.txt\n\nrequirements.txt 文件第一行可更改安装源，首选 https://mirrors.aliyun.com/pypi/simple/\n\n2、安装依赖1）在服务端自定义安装 python 3.11.9，路径尽量简单，便于查找选择；\n2）执行 pip install -r requirements.txt，安装依赖到全局\n3、使用 nssm\n官网下载地址：https://nssm.cc/download\n\n1）使用 cmd 或 powershell 进入 nssm\\win64 目录\n2）执行配置。cmd 执行nssm install；powershell 执行 .\\nssm install\n3）在弹出对话框 Application 选项卡依次配置以下内容后点击 Install service\n\n\n\nPath，python 执行器，选择安装的 python 3.11.9 路径，示例路径：C:\\Python311\\python.exe\nStartup directory，项目根目录，示例：C:\\test-deploy-fastapi\\\nArguments，执行参数，填入程序入口文件名，示例：main.py\nService name，服务名称，自定义：FastApi\n\n4）启动服务即可\n4、其他该项目的 main.py 文件参考如下：\nimport uvicornfrom fastapi import FastAPIapp = FastAPI()@app.get(&quot;/&quot;)async def root():    return &#123;&quot;message&quot;: &quot;Hello World&quot;&#125;@app.get(&quot;/items/&#123;item_id&#125;&quot;)async def read_item(item_id: int):    return &#123;&quot;item_id&quot;: item_id&#125;if __name__ == &quot;__main__&quot;:    config = uvicorn.Config(&#x27;main:app&#x27;, host=&#x27;0.0.0.0&#x27;, port=8000)    server = uvicorn.Server(config)    server.run()\n","categories":["部署和安装"],"tags":["FastAPI"]},{"title":"win 配置开机启动时执行脚本","url":"/2d5ffe70-cd69-11ee-be69-4dedf56c58bd/","content":"\n\n\n\n1、环境1）win 或 win server\n2）适用于 exe 或 bat\n2、启动目录win+R 呼出运行栏后输入 shell:startup 进入启动目录，将需要开机执行的脚本放在此处即可。\n3、注册表1）两个路径\n\n计算机\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run，参考内容：\n\nWindows Registry Editor Version 5.00[HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run]&quot;wpsphotoautoasso&quot;=&quot;\\&quot;C:\\\\pro\\\\WPS Office\\\\12.1.0.16120\\\\office6\\\\photolaunch.exe\\&quot; /photo /checkasso&quot;&quot;SunloginClient&quot;=&quot;\\&quot;C:\\\\pro\\\\SunloginClient\\\\SunloginClient.exe\\&quot; --cmd=autorun&quot;\n\n\n计算机\\HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run，参考内容：\n\nWindows Registry Editor Version 5.00[HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run]&quot;BaiduYunDetect&quot;=&quot;\\&quot;C:\\\\Users\\\\pro\\\\AppData\\\\Roaming\\\\baidu\\\\BaiduNetdisk\\\\YunDetectService.exe\\&quot;&quot;&quot;Steam&quot;=&quot;\\&quot;C:\\\\pro\\\\Steam\\\\steam.exe\\&quot; -silent&quot;\n\n上述两种路径分别对应系统全局启动项和用户启动项。根据参考内容的格式，增加新「字符串值」，填入脚本路径即可。输入路径要用半角双引号，如：&quot;C:\\pro\\Steam\\steam.exe&quot;\n4、计划任务1）win+R 呼出运行栏后输入 control 进入控制面板，进入「管理工具」，进入「任务计划程序」，右键「计划任务程序库」选择「创建任务」；\n2）在「常规」选项卡填写任务名称、描述（可选），选择「不管用户是否登录都要运行」，弹出验证框输入密码即可；勾选「使用最高权限运行」；\n3）在「触发器」选项卡点击「新建」，指定启动时机\n4）在「操作」选项卡选择要执行的脚本路径，「起始于」填写脚本所在目录\n5、组策略添加启动脚本1）win+R 呼出运行栏后输入 gpedit.msc 进入本地组策略\n2）依次进入「计算机配置」→「Windows设置」→「脚本（启动&#x2F;关机）」，双击进入右侧「启动」，添加脚本路径。\n","categories":["部署和安装"],"tags":["win"]},{"title":"win 防火墙配置允许回显请求","url":"/3a220860-815b-11ee-8ef0-c118c637cb12/","content":"\n\n\n\n1、问题描述网络正常状态下，使用 ping 命令试图获取某主机回显信息时出现超时。\n2、解决方案1）进入 设置，搜索 防火墙，进入 高级设置\n2）在 入站规则 列表中找到 核心网络诊断-ICMP 回显请求(ICMPv4-In)，勾选 已启用\n\n注：核心网络诊断-ICMP 回显请求(ICMPv4-In) 一般有多个，应选择配置文件为 专用、公用 的条目。\n\n该解决方案在 win10 专业版、Windows Server 2022 Datacenter 测试可用。\n3、其他1）仅响应指定 ip 的远程计算机\n在 入站规则 列表中找到 核心网络诊断-ICMP 回显请求(ICMPv4-In)，进入 作用域 分页，在 远程 IP 地址 栏目下添加地址即可（默认为 本地子网）。\n","categories":["部署和安装"],"tags":["win"]},{"title":"win10 mstsc 远程连接失败","url":"/eaa99ea0-3c36-11ef-91e1-efd3d29ea494/","content":"\n\n\n\n1 确保远程连接功能已启用1）按下 Win+R 键打开运行窗口，输入「sysdm.cpl」打开「系统属性」窗口。\n2）在该窗口的「远程」选项卡下，确保「允许远程协助连接到此计算机」和&#x2F;或「允许远程桌面服务连接到此计算机」的复选框被勾选上。如果没有勾选，则勾选上并点击「应用」和「确定」按钮。\n2 检查防火墙设置1）按下 Win+R 键打开运行窗口，输入「control firewall.cpl」并按 Enter 键，打开「Windows Defender 防火墙」窗口。\n2）在该窗口的「高级设置」选项卡下，确保「入站规则」中有一个允许 mstsc.exe 的规则。如果没有该规则，点击「新建规则」按钮，按照向导创建一个新的规则，允许 mstsc.exe 的入站连接。\n","categories":["部署和安装"],"tags":["mstsc"]},{"title":"win10-powershell-禁止运行脚本的问题","url":"/ed0e8970-441c-11ee-bc1a-25c3478a32d1/","content":"\n\n\n\n1、问题描述使用 vscode 或 powershell 控制台时，由于默认执行策略是 Restricted，执行一些命令会提示报错：\nhexo : 无法加载文件 D:\\node-v18.17.1-win-x64\\node-global\\hexo.ps1，因为在此系统上禁止运行脚本。\n\n2、解决方案1）执行如下命令\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\n\n2）重启应用或控制台\n3、其他查看当前策略：get-executionpolicy\n","categories":["部署和安装"],"tags":["powershell"]},{"title":"云服务器部署-JavaWeb-环境","url":"/bf93b0d0-446f-11ee-90e9-49c3e96e9425/","content":"\n\n\n\n0、前言2020-03-15 修改，补充增加了内容。\n1、环境、工具及版本\nCentOS Linux 7.4.1708 (Core)\nAmazon Corretto 11\nMySQL 5.7.28 或 MySQL 8.0.18\nNginx 1.16.1\n\n2、安装 JDK&#x2F;JRE 参考步骤2.1、yum 安装1）添加 yum 存储库\n在该页面：https://docs.aws.amazon.com/zh_cn/corretto/latest/corretto-11-ug/downloads-list.html 选择适用的发行包，拷贝链接后，使用以下命令安装：\nrpm -Uvh https://d3pxv6yz143wms.cloudfront.net/11.0.3.7.1/java-11-amazon-corretto-devel-11.0.3.7-1.x86_64.rpm\n\n也可以下载到本地执行安装：\nrpm -Uvh java-11-amazon-corretto-devel-11.0.3.7-1.x86_64.rpm\n\n2）开始安装\n[root@iZ9vbe1cif1bx32Z ~]## yum install java\n\n3）输入命令：java -version，查看 JDK 是否安装成功，如果安装成功则显示版本号信息：\n[root@iZ9vbe1cif1bx32Z ~]## java -versionopenjdk version &quot;11.0.3&quot; 2019-04-16 LTSOpenJDK Runtime Environment Corretto-11.0.3.7.1 (build 11.0.3+7-LTS)OpenJDK 64-Bit Server VM Corretto-11.0.3.7.1 (build 11.0.3+7-LTS, mixed mode)\n\n2.2、手动安装1）在 etc 下建立存放目录，可以用图形化工具建立，或者命令行：mkdir /etc/java\n2）在 etc 下使用命令：wget https://d3pxv6yz143wms.cloudfront.net/11.0.3.7.1/amazon-corretto-11.0.3.7.1-linux-x64.tar.gz，或将本地文件上传。\n3）在 etc 下执行命令：tar zxvf jdk-8u171-linux-x64.tar.gz -C /etc/java/\n4）解压完成后，修改 /etc/profile 文件，在末尾添加内容后保存：\n##set java environmentexport JAVA_HOME=/etc/java/amazon-corretto-11.0.3.7.1-linux-x64export CLASSPATH=.:$JAVA_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JAVA_HOME:$PATH\n\n附加内容：若安装 JDK 8，环境变量设置可改为：\n##set java environmentexport JAVA_HOME=/usr/java/jdk/jdk1.8.0_171export JRE_HOME=/usr/java/jdk/jdk1.8.0_171/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$JAVA_HOME:$PATH\n\n5）使用命令：source /etc/profile，让环境变量生效\n6）输入命令：java -version，查看 JDK 是否安装成功。\n3、安装 MySQL 参考步骤采用官网介绍的安装方法，步骤如下。原文详见：A Quick Guide to Using the MySQL Yum Repository\n1）查询并移除 CentOS 7 默认安装的 mariaDB，执行该步骤需要获得 root 权限：\n[root@iZ9vbe1cif1bx32Z ~]## rpm -qa | grep mariadbmariadb-libs-5.5.60-1.el7_5.x86_64[root@iZ9vbe1cif1bx32Z ~]## yum -y remove mariadb-libs\n\n2）添加 yum 存储库\n在该页面：https://dev.mysql.com/downloads/repo/yum/ 选择适用的发行包，拷贝链接后，使用以下命令安装：\nrpm -Uvh https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm\n\n也可以下载到本地执行安装：\nrpm -Uvh mysql80-community-release-el7-3.noarch.rpm\n\n3）选择版本\n在 yum 存储库中，不同版本的 MySQL Community Server 托管在不同的子存储库中。默认情况下启用最新版本（当前为 MySQL 8.0）的子存储库，而所有其他系列（例如，MySQL 5.7 系列）的子存储库均被禁用。使用以下命令可查看 yum 存储库中的所有子存储库，并查看已启用或禁用的子存储库：\n[root@iZ9vbe1cif1bx32Z ~]## yum repolist all | grep mysqlmysql-cluster-7.5-community/x86_64 MySQL Cluster 7.5 Community   disabledmysql-cluster-7.5-community-source MySQL Cluster 7.5 Community - disabledmysql-cluster-7.6-community/x86_64 MySQL Cluster 7.6 Community   disabledmysql-cluster-7.6-community-source MySQL Cluster 7.6 Community - disabledmysql-cluster-8.0-community/x86_64 MySQL Cluster 8.0 Community   disabledmysql-cluster-8.0-community-source MySQL Cluster 8.0 Community - disabledmysql-connectors-community/x86_64  MySQL Connectors Community    enabled:    128mysql-connectors-community-source  MySQL Connectors Community -  disabledmysql-tools-community/x86_64       MySQL Tools Community         enabled:    100mysql-tools-community-source       MySQL Tools Community - Sourc disabledmysql-tools-preview/x86_64         MySQL Tools Preview           disabledmysql-tools-preview-source         MySQL Tools Preview - Source  disabledmysql55-community/x86_64           MySQL 5.5 Community Server    disabledmysql55-community-source           MySQL 5.5 Community Server -  disabledmysql56-community/x86_64           MySQL 5.6 Community Server    disabledmysql56-community-source           MySQL 5.6 Community Server -  disabledmysql57-community/x86_64           MySQL 5.7 Community Server    disabledmysql57-community-source           MySQL 5.7 Community Server -  disabledmysql80-community/x86_64           MySQL 8.0 Community Server    enabled:    145mysql80-community-source           MySQL 8.0 Community Server -  disabled\n\n若安装最新版本则无需进行配置。要安装旧版本，例如 MySQL 5.7 系列，需禁用最新版本的子存储库并启用旧版本子存储库。以下命令禁用 8.0 系列的子存储库并启用 5.7 系列的子存储库：\n[root@iZ9vbe1cif1bx32Z ~]## yum-config-manager --disable mysql80-community[root@iZ9vbe1cif1bx32Z ~]## yum-config-manager --enable mysql57-community\n\n注意：\n\n若提示找不到 yum-config-manager 命令，安装即可：yum -y install yum-utils\n应该随时只为一个系列启用子存储库。如果启用了多个系列的子存储库，那么 yum 将使用最新的系列\n\n通过以下命令，验证是否已启用正确的子存储库：\n[root@iZ9vbe1cif1bx32Z ~]## yum repolist enabled | grep mysqlmysql-connectors-community/x86_64 MySQL Connectors Community                 128mysql-tools-community/x86_64      MySQL Tools Community                      100mysql57-community/x86_64          MySQL 5.7 Community Server                 384\n\n4）开始安装\n通过以下命令安装 MySQL 服务器的软件包以及其他必需的软件包：\n[root@iZ9vbe1cif1bx32Z ~]## yum install mysql-community-server\n\n5）启动 MySQL 服务\n[root@iZ9vbe1cif1bx32Z ~]## service mysqld start\n\n6）检查状态\n使用命令 service mysqld status，出现以下提示说明服务正常运行（MySQL 5.7 和 8.0 的显示结果基本相同）。\n[root@iZ9vbe1cif1bx32Z ~]## service mysqld statusRedirecting to /bin/systemctl status mysqld.service● mysqld.service - MySQL Server   Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)   Active: active (running) since Mon 2019-10-28 17:53:00 CST; 3h 25min ago     Docs: man:mysqld(8)           http://dev.mysql.com/doc/refman/en/using-systemd.html  Process: 3731 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS)  Process: 3681 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 3735 (mysqld)   CGroup: /system.slice/mysqld.service           └─3735 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mys...Oct 28 17:52:56 iZ9vbe1cif1bx32Z systemd[1]: Starting MySQL Server...Oct 28 17:53:00 iZ9vbe1cif1bx32Z systemd[1]: Started MySQL Server.\n\n7）查看初始临时密码\n[root@iZ9vbe1cif1bx32Z ~]## grep &#x27;temporary password&#x27; /var/log/mysqld.log\n\n8）使用生成的临时密码登录\n[root@iZ9vbe1cif1bx32Z ~]## mysql -uroot -p\n\n9）尽快为超级用户帐户设置自定义密码\nmysql&gt; alter user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;MyNewPass4!&#x27;;\n\n注意：MySQL 的 validate_password 插件默认安装。要求密码至少包含一个大写字母，一个小写字母，一位数字和一个特殊字符，并且密码总长度至少为 8 个字符。\n4、MySQL 通用及专有设置4.1、用户控制及授权1）创建用户 test 并设置密码\nmysql&gt; create user test identified by &#x27;123aI~A!&#x27;;\n\n\n注：可不进入 user 表执行该语句\n\n2）查看用户 test 的权限（没有分配前，无权限）：\nmysql&gt; show grants for &#x27;test&#x27;@&#x27;%&#x27;;+----------------------------------+| Grants for test@%                |+----------------------------------+| GRANT USAGE ON *.* TO &#x27;test&#x27;@&#x27;%&#x27; |+----------------------------------+1 row in set (0.00 sec)\n\n3）给用户 test 在 database 数据库中对的所有表授权，如：EXECUTE（执行存储过程），INSERT，SELECT，UPDATE 权限，’%’ 表示来自任意 IP 的访问：\ngrant execute,insert,select,update on database.* to &#x27;test&#x27;@&#x27;%&#x27;;\n\n常用权限有以下几种：\n\nall privileges，所有权限\nselect，读取权限\ndelete，删除权限\nupdate，更新权限\ncreate，创建权限\ndrop，删除数据库、数据表权限\n\n4）取消来自远程服务器的 AA 用户对数据库 db 里的表 tb 的所有权限\nrevoke all on db.tb from AA@&quot;%&quot;;\n\n5）刷新权限\nflush privileges;\n\n6）删除用户\ndrop user test@&#x27;%&#x27;;\n\n\n注：可不进入 user 表执行该语句\n\n7）查看所有用户信息（8.0 版本显示结果稍有不同）\nmysql&gt; select user, host, authentication_string from mysql.user;+---------------+-----------+-------------------------------------------+| user          | host      | authentication_string                     |+---------------+-----------+-------------------------------------------+| root          | localhost | *ACE4C05F67A275C00548651B22A066C15B2AB728 || mysql.session | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE || mysql.sys     | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE || test          | %         | *112D65D910D5E3AFCD5624275229F2C0F1B5ADE4 |+---------------+-----------+-------------------------------------------+4 rows in set (0.00 sec)\n\n4.2、重置密码1）定位 &#x2F;etc&#x2F;my.cnf，在 my.cnf 文件 [mysqld] 下添加 skip-grant-tables 字符串，开启免密码登陆\n2）执行 service mysqld restart，重启服务，使配置生效\n3）执行 mysql -u root -p，无需键入内容，直接回车即可登录\n4）清空密码\nupdate mysql.user set authentication_string=&#x27;&#x27; where user=&#x27;root&#x27;;\n\n5）将 skip-grant-tables 字符串删除，执行 service mysqld restart，重启服务，使配置生效\n6）执行 mysql -u root -p，无需键入内容，直接回车即可登录\n7）执行 alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;MyNewPass4!&#39;; 重新设置密码\n4.3、移除 MySQL1）停止服务：service mysqld stop\n2）执行 rpm -qa | grep -i mysql 查看 MySQL 组件：\n[root@iZ9vbe1cif1bx32Z ~]## rpm -qa | grep -i mysqlmysql-community-libs-5.7.28-1.el7.x86_64mysql80-community-release-el7-3.noarchmysql-community-common-5.7.28-1.el7.x86_64mysql-community-client-5.7.28-1.el7.x86_64mysql-community-server-5.7.28-1.el7.x86_64\n\n3）组件彼此之间有依赖关系，按顺序逐项执行移除\nrpm -ev mysql-community-server-5.7.28-1.el7.x86_64rpm -ev mysql-community-client-5.7.28-1.el7.x86_64rpm -ev mysql-community-libs-5.7.28-1.el7.x86_64rpm -ev mysql-community-common-5.7.28-1.el7.x86_64rpm -ev mysql80-community-release-el7-3.noarch\n\n4）删除相关目录。执行 find / -name mysql（查找） 和 rm -rf xxx（删除） 逐项执行移除完全为止。可能包含的目录如下：\n[root@iZ9vbe1cif1bx32Z ~]## find / -name mysql/etc/selinux/targeted/active/modules/100/mysql/var/lib/mysql/var/lib/mysql/mysql/usr/share/mysql\n\n4.4、MySQL 8 使用简单密码MySQL 8 默认不能输入全数字的简单密码，需要进行如下设置：\nmysql&gt; set global validate_password.policy=0;mysql&gt; set global validate_password.length=1;\n\n4.5、MySQL 8 开启外部第三方客户端连接权限MySQL 8.0 采用了 caching_sha2_password 加密，是 sha256 的改进版加密方式，多数第三方客户端都不支持这种加密方式，自带的命令行可支持。具体可参看 官方文档 有关该内容说明。要解决该问题，需要修改加密方式。以 root 用户为例，如果要配置其他用户或授权 IP，对应修改名称和地址即可。\nALTER USER &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;MyNewPass4!&#x27;;\n\n5、安装 nginx 参考步骤5.1、yum 安装（配置文件，稳定版）采用官网介绍的安装方法，步骤如下。原文详见：Installation instructions\n1）新建配置文件 /etc/yum.repos.d/nginx.repo，内容如下：\n[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true\n\n2）配置中 enabled=1，因此默认安装稳定版，直接执行 yum install nginx 即可\n3）启动服务：systemctl start nginx.service\n4）查看运行状态：ps -ef | grep nginx，若有 master process 和 worker process 两个进程说明正常启动。\n其他常用命令行：\n\n查看版本：nginx -v\n停止服务：systemctl stop nginx.service\n重启服务：systemctl restart nginx.service\n开机启动服务：systemctl enable nginx.service\n全局配置文件路径：/etc/nginx/nginx.conf\n网站文件存放路径：/usr/share/nginx/html\n网站默认站点配置文件路径：/etc/nginx/conf.d/default.conf\n自定义 Nginx 站点配置文件存放路径：/etc/nginx/conf.d/\n查看服务器私有 IP：ip addr show eth0 | grep inet | awk &#39;&#123; print $2; &#125;&#39; | sed &#39;s/\\/.*$//&#39;\n卸载：yum remove nginx，之后可用 which nginx 确认是否卸载情况\n\n5.2、yum 安装（手动，稳定版）1）在该页面：http://nginx.org/packages/centos/7/x86_64/RPMS/ 选择适用的发行包，拷贝链接后，使用以下命令安装：\nrpm -Uvh http://nginx.org/packages/centos/7/x86_64/RPMS/nginx-1.16.1-1.el7.ngx.x86_64.rpm\n\n也可以下载到本地执行安装：\nrpm -Uvh nginx-1.16.1-1.el7.ngx.x86_64.rpm\n\n2）执行 yum install nginx 即可\n3）启动服务：systemctl start nginx.service\n5.3、编译安装nginx 中 gzip 模块需要 zlib 库，rewrite 模块需要 pcre 库，ssl 功能需要 openssl 库。以 /usr/mix 安装目录为例：\n\n建立 mix 目录\n\n$ mkdir mix\n\n\n安装 GCC 和 GCC-C++\n\n$ yum install gcc$ yum install gcc-c++\n\n\n注意：若未安装 GCC，安装 Nginx 会报如下错误：\n\n./configure: error: C compiler cc is not found\n\n若未安装 GCC-C++，安装 PCRE 库时报如下错误：\nconfigure: error: You need a C++ compiler for C++ support.\n\n\n编译安装 PCRE 库\n\n$ cd /usr/$ wget https://sourceforge.net/projects/pcre/files/pcre/8.43/pcre-8.43.tar.gz$ tar -zxvf pcre-8.43.tar.gz -C /usr/mix/$ cd mix/pcre-8.43$ ./configure$ make &amp;&amp; make install\n\n注意：这里使用 pcre 而不用 pcre2\n\n编译安装 zlib 库\n\n$ cd /usr/$ wget http://www.zlib.net/zlib-1.2.11.tar.gz$ tar -zxvf zlib-1.2.11.tar.gz -C /usr/mix/$ cd mix/zlib-1.2.11$ ./configure$ make &amp;&amp; make install\n\n\n编译安装 openssl\n\n$ cd /usr/$ wget https://www.openssl.org/source/openssl-1.0.2r.tar.gz$ tar -zxvf openssl-1.0.2r.tar.gz -C /usr/mix/$ cd mix/openssl-1.0.2r$ ./config$ make &amp;&amp; make install\n\n\n编译安装 nginx，并添加 PCRE、zlib 、openssl 的源码路径\n\n$ cd /usr/$ wget http://nginx.org/download/nginx-1.16.0.tar.gz$ tar -zxvf nginx-1.16.0.tar.gz -C /usr/mix/$ cd mix/nginx-1.16.0$ ./configure --prefix=/usr/mix/nginx --with-pcre=/usr/mix/pcre-8.43 --with-zlib=/usr/mix/zlib-1.2.11 --with-openssl=/usr/mix/openssl-1.0.2r$ make &amp;&amp; make install\n\n\n启动 Nginx，默认端口为 80\n\n$ ./usr/mix/nginx/sbin/nginx\n\n\n查看工作情况\n\n$ ps -ef | grep nginx\n\n\n其他命令\n\n./sbin/nginx -s reload            ## 重新载入配置文件./sbin/nginx -s reopen            ## 重启 Nginx./sbin/nginx -s stop              ## 停止 Nginx\n\n5.4、问题及解决方案5.4.1、nginx 设置反向代理后，页面上的 js css 文件无法加载可添加如下配置：\nlocation ~ .*\\.(js|css)$ &#123;    proxy_pass http://127.0.0.1:8866;&#125;\n\n完整示例：\nlisten 80;server_name www.test.com;location /&#123;    proxy_pass http://xxx.xxx.xxx.xxx:9002;    index index.html;    proxy_redirect off;    proxy_set_header  Host  $host;    proxy_set_header  X-Real-IP  $remote_addr;    proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;&#125;location ~ .*\\.(js|css)$ &#123;    proxy_pass http://xxx.xxx.xxx.xxx:9002;&#125;\n\n5.4.2、输入域名或 IP，访问不到主页1）查看云服务器商防火墙是否放行 80 端口；\n2）系统防火墙是否放行 80 端口，相关命令如下：\n\nsystemctl status firewalld.service，查看系统防火墙状态（running&#x2F;dead）\nfirewall-cmd --permanent --add-port=80/tcp，开启 80 端口（重启系统启防火墙后生效）\nfirewall-cmd --reload，重启系统防火墙\nfirewall-cmd --list-ports，查看系统防火墙已开启端口\n\n附加内容：防火墙的开启和关闭\n\n临时关闭防火墙：systemctl stop firewalld\n临时开启防火墙：systemctl start firewalld\n永久关闭防火墙：systemctl disable firewalld\n永久开启防火墙：systemctl enable firewalld\n\n\n注意事项：临时关闭或开启防火墙，当重启时会回复之前的状态；永久开启或关闭防火墙，重启后生效。\n\n附加内容：自启动服务命令\n\n查看服务是否开机启动：systemctl is-enabled firewalld.service\n查看已启动的服务列表：systemctl list-unit-files|grep enabled\n查看启动失败的服务列表：systemctl –failed\n\n附加内容：添加&#x2F;删除开放端口\n\n默认作用域下，每次修改端口和服务相当于修改 /etc/firewalld/zones/public.xml 文件，也可以直接操作文件\n添加 http 服务：firewall-cmd --zone=public --add-service=http --permanent\n查看端口是否开放，开启显示 yes：firewall-cmd --query-port=80/tcp\n查看服务是否开放，开启显示 yes：firewall-cmd --query-service=ssh\n删除开放的端口：firewall-cmd --remove-port=80/tcp --permanent\n删除开放的服务：firewall-cmd --zone=public --remove-service=http --permanent\n查看所有开启的服务：firewall-cmd --list-services\n列出指定作用域的所有设置：firewall-cmd --zone=public --list-all\n查看所有可用区域：firewall-cmd --get-zones\n列出所有预设服务：firewall-cmd --get-services，将列出 /usr/lib/firewalld/services/ 中的服务器名称。配置文件是以服务本身命名的 service-name.xml\n列出所有区域的设置：firewall-cmd --list-all-zones\n\n\n注 1：缺省时的作用域为 public，即默认带参数 --zone=public，可通过 firewall-cmd --get-default-zone 命令查看，可通过 firewall-cmd --set-default-zone=dmz 命令更改\n\n\n注 2：--permanent 参数为永久生效\n\n\n注 3：/etc/firewalld/zones/ 目录下保存作用域配置文件。如 public.xml 是当前生效配置；public.xml.old 是上一次生效配置。\n\n附加内容：防火墙作用域\n\npublic ：仅允许访问本机的 ssh，ping，dhcp 服务（默认）\ntrusted：允许任何访问\nblock：阻塞任何来访请求，明确拒绝\ndrop：丢弃任何来访的数据包，直接丢弃\n\n附加内容：其他防火墙操作\n定义规则\n\n设置某个 ip 访问某个服务：firewall-cmd --permanent --zone=public --add-rich-rule=&#39;rule family=&quot;ipv4&quot; source address=&quot;192.168.0.4/24&quot; service name=&quot;http&quot; accept&#39;\n删除配置：firewall-cmd --permanent --zone=public --remove-rich-rule=&#39;rule family=&quot;ipv4&quot; source address=&quot;192.168.0.4/24&quot; service name=&quot;http&quot; accept&#39; &#x2F;&#x2F;\n设置某个 ip 访问某个端口：firewall-cmd --permanent --add-rich-rule &#39;rule family=ipv4 source address=192.168.0.1/2 port port=80 protocol=tcp accept&#39;\n删除配置：firewall-cmd --permanent --remove-rich-rule &#39;rule family=ipv4 source address=192.168.0.1/2 port port=80 protocol=tcp accept&#39;\n将 1.2.3.4 这个源地址的连接全部给 drop 掉：firewall-cmd --add-rich-rule=&#39;rule family=&quot;ipv4&quot; source address=&quot;1.2.3.4&quot; drop&#39;\n\n伪装 IP\n\n检查是否允许伪装 IP：firewall-cmd --query-masquerade\n允许防火墙伪装 IP：firewall-cmd --add-masquerade\n禁止防火墙伪装 IP：firewall-cmd --remove-masquerade\n\n请求转发\n\n将 80 端口的请求转发至 8080：firewall-cmd --add-forward-port=port=80:proto=tcp:toport=8080\n将 80 端口的请求转发至 1 92.168.0.1：firewall-cmd --add-forward-port=proto=80:proto=tcp:toaddr=192.168.1.0.1\n将 80 端口的请求转发至 192.168.0.1 的 8080 端口：firewall-cmd --add-forward-port=proto=80:proto=tcp:toaddr=192.168.0.1:toport=8080\n\n6、部署过程中的其他问题6.1、解压 filename.tar.xz 文件使用命令：tar -xvf filename.tar.xz\n6.2、在 linux 服务器运行 jar 文件通常的方法是：\n$ java -jar test.jar\n\n但是这种方式在 SSH 窗口关闭时程序将中止运行，或者是运行时没法切出去执行其他任务，有没有办法让 jar 在后台运行。要解决这个问题，可以使用：\n$ nohup java -jar test.jar &amp;\n\n即不挂断运行命令，账户退出或终端关闭时，程序仍然运行。当用 nohup 命令执行作业时，缺省情况下该作业的所有输出被重定向到 nohup.out 的文件中，除非另外指定了输出文件。例如：\n$ nohup java -jar test.jar &gt;temp.txt &amp;\n\n此时把日志文件输入到指定的文件中，没有则会自动创建。\n附加内容：两种报错的解决\n▲ 提示 nohup: failed to run commandjava’: No such file or directory&#96;\n▲ 或者使用 .&#x2F;startup.sh 开启 tomcat 服务报错：\nNeither the JAVA_HOME nor the JRE_HOME environment variable is definedAt least one of these environment variable is needed to run this program\n\n以上情况，执行一次 source &#x2F;etc&#x2F;profile 即可。\n6.3、linux kill 命令格式：kill [参数][进程号]\n6.4、linux 查询端口情况netstat 命令各个参数说明如下：\n-t : 指明显示TCP端口-u : 指明显示UDP端口-l : 仅显示监听套接字(所谓套接字就是使应用程序能够读写与收发通讯协议(protocol)与资料的程序)-p : 显示进程标识符和程序名称，每一个套接字/端口都属于一个程序。-n : 不进行DNS轮询，显示IP(可以加速操作)\n\n要显示当前服务器上所有端口及进程服务，与 grep 结合可查看某个具体端口及服务情况：\nnetstat -ntlp   //查看当前所有tcp端口netstat -ntulp |grep 80   //查看所有80端口使用情况netstat -ntulp | grep 3306   //查看所有3306端口使用情况\n\n查询出来的结果，根据 ID 号可以用 kill 命令终止后台运行的任务。\n附加内容：使用 netstate 报 -bash: netstate: command not found网络工具没有安装，执行 yum install net-tools，安装即可\n6.5、jobs 命令：查看当前终端后台运行的任务。jobs 的状态可以是 running，stopped，Terminated。+ 号表示当前任务，- 号表示后一个任务。\n注：该命令可在使用 nohup 后紧接使用。\n6.7、scp 上传或下载文件\n可执行 yum install openssh-clients 命令进行安装\n上传文件到服务器：scp /Users/spirit/Documents/WechatIMG135.jpeg root@192.168.1.1:/usr/local\n上传文件夹到服务器：scp -r /Users/spirit/Documents/fileFolder root@192.168.1.1:/usr/local\n从服务器下载文件：scp root@192.168.1.1:/usr/local/WechatIMG135.jpeg /Users/spirit/Documents\n从服务器下载文件夹：scp -r root@192.168.1.1:/usr/local/fileFolder /Users/spirit/Documents\n\n参数说明：\n\n-1：强制 scp 命令使用协议 ssh1\n-2：强制 scp 命令使用协议 ssh2\n-4：强制 scp 命令只使用 IPv4 寻址\n-6：强制 scp 命令只使用 IPv6 寻址\n-B：使用批处理模式（传输过程中不询问传输口令或短语）\n-C：允许压缩。（将-C 标志传递给 ssh，从而打开压缩功能）\n-p：保留原文件的修改时间，访问时间和访问权限。\n-q：不显示传输进度条。\n-r：递归复制整个目录。\n-v：详细方式显示输出。scp 和 ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。\n-c：cipher，以 cipher 将数据传输进行加密，这个选项将直接传递给 ssh。\n-F：ssh_config，指定一个替代的 ssh 配置文件，此参数直接传递给 ssh。\n-i：identity_file，从指定文件中读取传输时使用的密钥文件，此参数直接传递给 ssh。\n-l：limit，限定用户所能使用的带宽，以 Kbit&#x2F;s 为单位。\n-o：ssh_option，如果习惯于使用 ssh_config(5)中的参数传递方式，\n-P：port，注意是大写的 P, port 是指定数据传输用到的端口号\n-S：program，指定加密传输时所使用的程序。此程序必须能够理解 ssh(1)的选项。\n\n","categories":["部署和安装"],"tags":["JavaWeb"]},{"title":"使用-Navicat-远程连接阿里云服务器的-MySQL-数据库","url":"/5886f891-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n需求使用 Navicat 连接阿里云远程 MySQL 数据库。\n解决方案1、开放权限登录 MySql，此时用命令指定用户名 root 可以通过密码 123456 访问所有数据库，之后刷新权限。相应的命令及结果如下：\nmysql&gt;GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27; WITH GRANT OPTION;Query OK, 0 rows affected (0.00 sec)mysql&gt;FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec)\n\n2、设置服务器安全组的端口放行规则ECS 云服务器安全组设置如下：\n\n\n轻量应用服务器防火墙设置如下：\n\n\n3、设置 Navicat进入 Navicat，新建连接，在「常规」选项卡中输入开放权限时的信息，用户名：root；密码：123456\n\n","categories":["部署和安装"],"tags":["mysql"]},{"title":"使用-github+Action-部署-Hexo-博客","url":"/5886f892-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n前言为便于叙述，统一说明如下：\n\n博客 github 源码仓库默认分支为 main，ssh 地址：git@github.com:username/blog.git\nusername.github.io：博客部署仓库，默认分支为 main\nhexo_deploy：本地私钥文件\n&#96;hexo_deploy.pub：本地公钥文件\n主题以 NexT 8.13.2 为例\n\n\n本地 hexo 安装、主题部署流程较简单，步骤省略。\n\n1、配置本地博客源代码库在本地博客源代码仓库根目录 _config.yml 文件中增加如下部署配置：\n# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy:  type: git  repo: git@github.com:username/username.github.io.git  branch: main\n\n\n注意：github 目前仅允许 ssh 提交，部署仓库必须为 ssh 地址\n\n2、配置专用密钥对本地重新生成一组密钥对，如 hexo_deploy.pub 与 hexo_deploy。私钥配置到 github 源码仓库的 repository secret，公钥配置到 username.github.io 部署仓库的 Deploy keys。该密钥对专用于「源码仓库」与「部署仓库」之间的 Action 自动部署。\n\ngithub 源码库新建后即可配置：依次进入 Settings -&gt; Secrets -&gt; Actions -&gt; New repository secret，名称取 HEXO_DEPLOY_SECRET，值取自 hexo_deploy 内容；username.github.io.git 部署仓库配置步骤略。\n\n也可以拿用户公钥 SSH keys（可访问全部仓库）及其对应的私钥完成该步骤，但是用户公钥不一致时（比如办公室和家里使用的用户公钥不同，除非复制同一份密钥对），Action 自动部署的私钥也要更改，使用专用密钥对可避免这个问题。\n3、创建 Action在本地博客源代码库根目录下创建 .github/workflows/deploy.yml 文件，参考内容如下：\nname: hexo-blog-deployon:  push:    branches:      - mainenv:  GIT_USER: username  GIT_EMAIL: username@gmail.com  DEPLOY_REPO: username/username.github.io  DEPLOY_BRANCH: mainjobs:  build:    name: Build on node $&#123;&#123; matrix.node_version &#125;&#125; and $&#123;&#123; matrix.os &#125;&#125;    runs-on: ubuntu-latest    strategy:      matrix:        os: [ubuntu-latest]        node_version: [19.x]    steps:      - name: Checkout        uses: actions/checkout@v2      - name: Checkout deploy repo        uses: actions/checkout@v2        with:          repository: $&#123;&#123; env.DEPLOY_REPO &#125;&#125;          ref: $&#123;&#123; env.DEPLOY_BRANCH &#125;&#125;          path: .deploy_git      - name: Use Node.js $&#123;&#123; matrix.node_version &#125;&#125;        uses: actions/setup-node@v1        with:          node-version: $&#123;&#123; matrix.node_version &#125;&#125;      - name: Configuration environment        env:          HEXO_DEPLOY_SECRET: $&#123;&#123;secrets.HEXO_DEPLOY_SECRET&#125;&#125;        run: |          sudo timedatectl set-timezone &quot;Asia/Shanghai&quot;          # 配置私钥，否则无法访问部署库，提示 git@github.com: Permission denied (publickey).          mkdir -p ~/.ssh/          echo &quot;$HEXO_DEPLOY_SECRET&quot; &gt; ~/.ssh/id_rsa          chmod 600 ~/.ssh/id_rsa          ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts          # 设置用户名和邮箱，否则提示 Please tell me who you are.          git config --global user.name $GIT_USER          git config --global user.email $GIT_EMAIL      - name: Install dependencies        run: |          npm install          npm install hexo-deployer-git --save          # 全局搜索插件          npm install hexo-generator-searchdb --save      - name: Deploy hexo        run: |          npm run deploy\n\n4、常用命令\n本地启动：hexo s\n清除缓存：hexo clean\n新建草稿：hexo new draft &lt;filename&gt;\n发布草稿：hexo publish [layout] &lt;filename&gt;\n\n5、其他（可选）部署留言栏 Utterances安装 github 应用： https://github.com/apps/utterances\nnext 最新版本已经集成 Utterances，因此不需要复制安装完成后的模板，直接在主题文件根目录下设置 _config.yml 文件即可：\n# Utterances# For more information: https://utteranc.esutterances:  enable: true  repo: username/username.github.io # Github repository owner and name  # Available values: pathname | url | title | og:title  issue_term: pathname  # Available values: github-light | github-dark | preferred-color-scheme | github-dark-orange | icy-dark | dark-blue | photon-dark | boxy-light  theme: github-light\n\n（可选）部署留言栏 giscus进入官网（https://giscus.app/）可拿到一段已经填充配置内容的 &lt;script&gt; 标签：\n&lt;script src=&quot;https://giscus.app/client.js&quot;    data-repo=&quot;[在此输入仓库]&quot;    data-repo-id=&quot;[在此输入仓库 ID]&quot;    data-category=&quot;[在此输入分类名]&quot;    data-category-id=&quot;[在此输入分类 ID]&quot;    data-mapping=&quot;pathname&quot;    data-strict=&quot;0&quot;    data-reactions-enabled=&quot;1&quot;    data-emit-metadata=&quot;0&quot;    data-input-position=&quot;bottom&quot;    data-theme=&quot;preferred_color_scheme&quot;    data-lang=&quot;zh-CN&quot;    crossorigin=&quot;anonymous&quot;    async&gt;&lt;/script&gt;\n\n如果要在每一篇文章后添加评论功能，以 next 主题为例，仅供参考。进入 themes/next/layout/_macro/post.njk 文件，找到模板中「文章末尾」（注释标志为 END POST BODY，如下所示），将上述片段加入。\n&#123;#####################&#125;&#123;### END POST BODY ###&#125;&#123;#####################&#125;&lt;footer class=&quot;post-footer&quot;&gt;  &#123;%- if is_index %&#125;    &lt;div class=&quot;post-eof&quot; style=&quot;margin:20px auto 20px;width:100%;background: transparent;border-top: 1px solid #e2e0e0&quot;&gt;&lt;/div&gt;  &#123;% else %&#125;    &#123;&#123;- next_inject(&#x27;postBodyEnd&#x27;) &#125;&#125;    &#123;%- if post.reward_settings.enable %&#125;      &#123;&#123; partial(&#x27;_partials/post/post-reward.njk&#x27;) &#125;&#125;    &#123;%- endif %&#125;    &#123;%- if theme.creative_commons.license and theme.creative_commons.post and post.copyright !== false %&#125;      &#123;&#123; partial(&#x27;_partials/post/post-copyright.njk&#x27;) &#125;&#125;    &#123;%- endif %&#125;    &#123;%- if theme.follow_me %&#125;      &#123;&#123; partial(&#x27;_partials/post/post-followme.njk&#x27;, &#123;&#125;, &#123;cache: theme.cache.enable&#125;) &#125;&#125;    &#123;%- endif %&#125;    &#123;#####################&#125;    &#123;###   add giscus  ###&#125;    &#123;#####################&#125;    &lt;script src=&quot;https://giscus.app/client.js&quot;        data-repo=&quot;[在此输入仓库]&quot;        data-repo-id=&quot;[在此输入仓库 ID]&quot;        data-category=&quot;[在此输入分类名]&quot;        data-category-id=&quot;[在此输入分类 ID]&quot;        data-mapping=&quot;pathname&quot;        data-strict=&quot;0&quot;        data-reactions-enabled=&quot;1&quot;        data-emit-metadata=&quot;0&quot;        data-input-position=&quot;bottom&quot;        data-theme=&quot;preferred_color_scheme&quot;        data-lang=&quot;zh-CN&quot;        crossorigin=&quot;anonymous&quot;        async&gt;    &lt;/script&gt;    &#123;%- if post.tags and post.tags.length %&#125;      &#123;%- set tag_indicate = &#x27;&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;&#x27; if theme.tag_icon else &#x27;#&#x27; %&#125;      &lt;div class=&quot;post-tags&quot;&gt;        &#123;%- for tag in post.tags.toArray() %&#125;          &lt;a href=&quot;&#123;&#123; url_for(tag.path) &#125;&#125;&quot; rel=&quot;tag&quot;&gt;&#123;&#123; tag_indicate &#125;&#125; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt;        &#123;%- endfor %&#125;      &lt;/div&gt;    &#123;%- endif %&#125;\n\n（可选）部署域名参考官方文档：验证用户站点的域\n\n注意：需要在 blog 源代码库 source 目录下放置 CNAME 文件。之后步骤按官方文档进行\n\n","categories":["部署和安装"],"tags":["github","hexo"]},{"title":"修改 mac 的 MAC 地址","url":"/931e2910-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n1 解决方案1）打开终端，输入 openssl rand -hex 6 | sed &#39;s/\\(..\\)/\\1:/g; s/.$//&#39; 生成一个 MAC 地址\n2）断开网卡连接，会要求输入密码。\nsudo /System/Library/PrivateFrameworks/Apple80211.framework/Resources/airport -z\n3）修改网卡地址，例如 en0：sudo ifconfig en0 ether xx:xx:xx:xx:xx:xx\n4）重连网卡，可能会要求输入密码：networksetup -detectnewhardware\n5）验证 MAC 地址是否修改成功：ifconfig\n","categories":["部署和安装"],"tags":["mac"]},{"title":"在win10+vscode+anaconda3+python3.11.3独立环境部署pytorch2.0.1+cuda11.8","url":"/148d4630-44e0-11ee-bc05-f9725afef782/","content":"\n\n\n\n该方式不用提前安装 vs2015_runtime 运行时以及 cuda、cudnn，在执行 pytorch 官网的命令后已经全部带有。因此，可在独立环境中同时存在多个版本的 cuda 或者 pytorch cpu 版本。\n1、确定可支持 CUDA 版本打开 NVIDIA Control Panel（NVIDIA 控制面板），点击左下角「系统信息」，在「组件」标签页查看支持的最高版本，如图所示：\n\n2、在 https://pytorch.org/ 查看 pytorch 支持的最高 CUDA 版本\n3、执行部署1）确保 anaconda3（python3.11.3）在 vscode 能够正常使用，相关部署参考 部署win10+vscode+anaconda3环境\n2）执行下列命令\nconda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n\n\n注：全部安装均采用默认源，其中 libcublas 包的安装比较费时。\n\n3）验证\n执行如下代码：\nimport torch# cuda是否可用print(torch.cuda.is_available())# 获取GPU信息print(&quot;GPU=&quot;, torch.cuda.get_device_name(torch.device(&quot;cuda:0&quot;)))# 获取pytorch版本print(&quot;pytorch version=&quot;, torch.__version__)# 获取cuda版本print(&quot;cuda Version=&quot;, torch.version.cuda)# 获取cudnn版本print(&quot;cudnn version=&quot;, torch.backends.cudnn.version())\n\n输出如下结果，表明全部组件安装成功：\nTrueGPU= NVIDIA GeForce RTX 4070pytorch version= 2.0.1cuda Version= 11.8cudnn version= 8700\n","categories":["部署和安装"],"tags":["cuda","pytorch","python3"]},{"title":"树莓派-ubuntu-环境下-mariadb-部署","url":"/ef12ce00-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n1、下载树莓派 Ubuntu Server 20.04.3 LTS\nhttps://cn.ubuntu.com/download/raspberry-pi\n2、使用 balenaEtcher 制作系统到闪存\nhttps://www.balena.io/etcher/\n3、设置 wifi\n参考官网步骤：https://ubuntu.com/tutorials/how-to-install-ubuntu-on-your-raspberry-pi#3-wifi-or-ethernet\n启动系统前，在闪存找到 network-config 文件，移除注释，按需设置。例如：\nwifis:  wlan0:    dhcp4: true    optional: true    access-points:      &quot;home network&quot;:        password: &quot;123456789&quot;\n\n4、启动系统\n\n默认用户名：ubuntu\n默认密码：ubuntu\n\n5、安装 ssh\nsudo apt-get updatesudo apt-get install openssh-server\n\n执行 apt-get 若出现 Could not get lock… 等类似提示，如下：\nE: Could not get lock /var/lib/dpkg/lock. It is held by process 34781 (dpkg)N: Be aware that removing the lock file is not a solution and may break your system.E: Unable to lock the administration directory (/var/lib/dpkg/), is another process using it?\n\n可通过 ps afx|grep apt 命令查看进程，使用 kill -9 &lt;进程编号&gt; 停止占用进程，再执行安装命令即可。\n\n注：不必删除 lock 文件。\n\n通过 sudo systemctl status ssh 查看服务状态是否正常，如下所示：\nubuntu@ubuntu:~$ sudo systemctl status ssh● ssh.service - OpenBSD Secure Shell server     Loaded: loaded (/lib/systemd/system/ssh.service; enabled; vendor preset: enabled)     Active: active (running) since Fri 2022-02-11 03:48:39 UTC; 1h 43min ago       Docs: man:sshd(8)             man:sshd_config(5)   Main PID: 45984 (sshd)      Tasks: 1 (limit: 4435)     CGroup: /system.slice/ssh.service             └─45984 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups\n\n通过 ssh ubuntu@xxx.xxx.xxx.xxx 连接即可。\n6、安装 mariadb\n参考官网步骤，采用阿里云镜像\nhttps://mariadb.org/download/?t=repo-config&amp;d=20.04+%22focal%22&amp;v=10.6&amp;r_m=aliyun\n依次执行如下命令：\nsudo apt-get install software-properties-common dirmngr apt-transport-httpssudo apt-key adv --fetch-keys &#x27;https://mariadb.org/mariadb_release_signing_key.asc&#x27;sudo add-apt-repository &#x27;deb [arch=amd64,arm64,ppc64el,s390x] https://mirrors.aliyun.com/mariadb/repo/10.6/ubuntu focal main&#x27;sudo apt updatesudo apt install mariadb-server\n\n通过 sudo systemctl status mariadb.service 查看服务状态，正常工作如下：\nubuntu@ubuntu:~$ sudo systemctl status mariadb.service● mariadb.service - MariaDB 10.6.5 database server     Loaded: loaded (/lib/systemd/system/mariadb.service; enabled; vendor prese&gt;    Drop-In: /etc/systemd/system/mariadb.service.d             └─migrated-from-my.cnf-settings.conf     Active: active (running) since Fri 2022-02-11 03:56:37 UTC; 39min ago       Docs: man:mariadbd(8)             https://mariadb.com/kb/en/library/systemd/   Main PID: 48637 (mariadbd)     Status: &quot;Taking your SQL requests now...&quot;      Tasks: 8 (limit: 4435)     CGroup: /system.slice/mariadb.service             └─48637 /usr/sbin/mariadbd\n\n7、修改密码\n通过 sudo mariadb -u root -p 登录，不必输入密码，直接回车后修改 root 密码：\nuse mysql;alter user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;xxxxxx&#x27;;\n\n可通过 select user, plugin from mysql.user; 查看登陆方式。初始状态为 unix_socket(MariaDB)，配置密码后为 mysql_native_password\nMariaDB [(none)]&gt; select user, plugin from mysql.user;+-------------+-----------------------+| User        | plugin                |+-------------+-----------------------+| mariadb.sys | mysql_native_password || root        | mysql_native_password || mysql       | mysql_native_password |+-------------+-----------------------+4 rows in set (0.011 sec)\n\n8、允许远程连接\n通过 sudo vim /etc/mysql/mariadb.conf.d/50-server.cnf 修改配置，将其中 bind-address = 127.0.0.1 修改为 0.0.0.0 或直接注释掉。\n新增远程连接用户 create user &lt;username&gt;@xxx.xxx.xxx.xxx identified by &#39;123456&#39;;\n9、其他\n启动 MariaDB 数据库服务 sudo systemctl start mysql\n重启数据库服务 sudo systemctl restart mysql\n设置 mysql 随系统服务启动 sudo update-rc.d mysql defaults\n撤销随系统服务启动 sudo update-rc.d -f mysql remove\n防火墙磁盘挂载以机械硬盘为例，已经在 windows 格式化为 exFAT 格式。通过 USB 接入树莓派后，登入系统，通过 sudo fdisk -l 查看当前磁盘状态如下：\nubuntu@ubuntu:~$ sudo fdisk -lDisk /dev/loop0: 48.92 MiB, 51277824 bytes, 100152 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/loop1: 61.98 MiB, 64962560 bytes, 126880 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/loop2: 28.7 MiB, 29433856 bytes, 57488 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/mmcblk0: 29.74 GiB, 31914983424 bytes, 62333952 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0xf66f0719Device         Boot  Start      End  Sectors  Size Id Type/dev/mmcblk0p1 *      2048   526335   524288  256M  c W95 FAT32 (LBA)/dev/mmcblk0p2      526336 62333918 61807583 29.5G 83 LinuxDisk /dev/sda: 298.9 GiB, 320072933376 bytes, 625142448 sectorsDisk model: 00AAJS-00L7A0Units: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 33553920 bytesDisklabel type: dosDisk identifier: 0x91676b87Device     Boot Start       End   Sectors   Size Id Type/dev/sda1        2048 625139711 625137664 298.1G  7 HPFS/NTFS/exFAT\n\n格式化硬盘为 ext4 格式\nubuntu@ubuntu:~$ sudo mkfs -t ext4 /dev/sdamke2fs 1.45.5 (07-Jan-2020)Found a dos partition table in /dev/sdaProceed anyway? (y,N) yCreating filesystem with 78142806 4k blocks and 19537920 inodesFilesystem UUID: bfff555b-254e-403a-880e-260601f7c1e5Superblock backups stored on blocks:\t32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,\t4096000, 7962624, 11239424, 20480000, 23887872, 71663616Allocating group tables: doneWriting inode tables: doneCreating journal (262144 blocks): doneWriting superblocks and filesystem accounting information: done\n\n通过以下命令建立目录\nmkdir /mnt/diskchmod 777 /mnt/disk\n\n挂载硬盘\nmount /dev/sda /mnt/disk\n\n查询 uuid\nubuntu@ubuntu:~$ sudo blkid/dev/mmcblk0p1: LABEL_FATBOOT=&quot;system-boot&quot; LABEL=&quot;system-boot&quot; UUID=&quot;5496-E6C8&quot; TYPE=&quot;vfat&quot; PARTUUID=&quot;f66f0719-01&quot;/dev/mmcblk0p2: LABEL=&quot;writable&quot; UUID=&quot;675ba907-3741-428c-afa4-c00f1b649e3c&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;f66f0719-02&quot;/dev/loop0: TYPE=&quot;squashfs&quot;/dev/loop1: TYPE=&quot;squashfs&quot;/dev/loop2: TYPE=&quot;squashfs&quot;/dev/sda: UUID=&quot;bfff555b-254e-403a-880e-260601f7c1e5&quot; TYPE=&quot;ext4&quot;\n\n通过 sudo vim /etc/fstab 在末尾添加下列内容，两者选其一：\nUUID=bfff555b-254e-403a-880e-260601f7c1e5 /mnt/disk ext4 defaults 0 0或/dev/sda /mnt/disk ext4 defaults 0 0\n\n第一个数字：0 表示开机不检查磁盘，1 表示开机检查磁盘；第二个数字：0 表示交换分区，1 代表启动分区（Linux），2 表示普通分区\n其他补充：进入 &#x2F;mnt&#x2F;disk 目录，其中包含\n如果你运行 fsck 命令（文件系统检查和修复命令），它也许会找到一些数据碎片，这些文件碎片在硬盘中并没有引用。特别的，fsck 也许能找到看起来是完整的文件，但是在系统中没有名字－一个 inode 但是不对应文件名。这个数据仍然占用硬盘空间，但是并不能通过正常方式访问。\n     lost+found目录的文件通常是未链接的文件（名字已经被删除），但是这些文件还被一些进程使用（数据没有删除），在突然关机时（内核panic或者突然断电）出现。这些文件系统会自动删除。\n\n    当因为软件或者硬件出现错误，导致文件系统不一致，也有可能把有问题的文件放到lost+found目录。它提供了恢复丢失文件的一种方法。\n\n\n\n    如果你不小心删除了lost+found目录，不能使用mkdir命令创建lost+found目录，应该使用mklost+found命令创建它。\n\n$ cd &#x2F;$ sudo mklost+found\n磁盘容量及分区状况（不能查看未挂载分区）df -Th\n磁盘容量及分区状况（可以查看未挂载分区）sudo fdisk -lsudo lsblk -f\n&#x2F;lib 目录大小du -sh &#x2F;lib\n&#x2F;lib 子目录大小du -sh &#x2F;lib&#x2F;*\n转移 mariadb 数据执行 sudo systemctl stop mariadb.service 停止服务\n新建 &#x2F;mnt&#x2F;disk&#x2F;mariadbdata\n通过 sudo vim /etc/mysql/mariadb.conf.d/50-server.cnf 修改 datadir 如下：\n[mysqld]## * Basic Settings#user                    = mysqlpid-file                = /run/mysqld/mysqld.pidbasedir                 = /usr#datadir                 = /var/lib/mysqldatadir                 = /mnt/disk/mariadbdatatmpdir                  = /tmplc-messages-dir         = /usr/share/mysqllc-messages             = en_USskip-external-locking\n\n执行 sudo cp -r /var/lib/mysql/* /mnt/disk/mariadbdata/ 复制旧数据到新位置。\n修改目录权限和组\nsudo chown -R mysql:mysql /mnt/disk/mariadbdata\n\n注意：若需要保存旧目录数据，应复制文件后再修改所有者，否则无法启动服务。\n\n执行 sudo systemctl start mariadb.service 重启服务\n其他如果将数据转移到 &#x2F;home 目录需要修改 /lib/systemd/system/mariadb.service 为 ProtectHome=false\n# Prevent accessing /home, /root and /run/userProtectHome=true\n\nThe MariaDB&#x2F;MySQL tools read configuration files in the following order:0. “&#x2F;etc&#x2F;mysql&#x2F;my.cnf” symlinks to this file, reason why all the rest is read.1. “&#x2F;etc&#x2F;mysql&#x2F;mariadb.cnf” (this file) to set global defaults,2. “&#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F;*.cnf” to set global options.3. “&#x2F;etc&#x2F;mysql&#x2F;mariadb.conf.d&#x2F;*.cnf” to set MariaDB-only options.4. “~&#x2F;.my.cnf” to set user-specific options.50-client.cnf 50-mysqld_safe.cnf 60-galera.cnf50-mysql-clients.cnf 50-server.cnf 99-enable-encryption.cnf.preset\n部署 java11参考 https://docs.aws.amazon.com/corretto/latest/corretto-11-ug/generic-linux-install.html\nwget -O- https://apt.corretto.aws/corretto.key | sudo apt-key add -sudo add-apt-repository &#x27;deb https://apt.corretto.aws stable main&#x27;sudo apt-get update; sudo apt-get install -y java-11-amazon-corretto-jdk\n\n安装路径\n/usr/lib/jvm/java-11-amazon-corretto/bin/\n","categories":["部署和安装"],"tags":["ubuntu","mariadb","raspberry-pi"]},{"title":"激活 win10/11 pro","url":"/53337b90-4f8d-11ee-9eaf-09d2cd19d790/","content":"\n\n\n\n1、激活步骤在需要激活的设备以管理员身份开启 cmd，执行以下步骤：\n1）卸载密钥，执行 slmgr /upk\n\n注意：务必要执行卸载步骤\n\n2）假设已部署的 kms 服务器 ip 为 192.168.1.5，执行 slmgr /skms 192.168.1.5 设置 kms 服务器地址。可参考 部署 kms 服务器 的内容建立 kms 服务器\n\nwin10 部署的服务器要注意防火墙规则是否允许访问\n\n3）安装密钥，执行 slmgr /ipk W269N-WFGWX-YVC9B-4J6C9-T83GX\n\n该密钥为 win10&#x2F;11 专业版固定，其他密钥详见 https://learn.microsoft.com/en-us/windows-server/get-started/kms-client-activation-keys\n\n4）激活，执行 slmgr /ato，等待数秒后提示是否成功\n5）验证，执行 slmgr /xpr 后若成功激活将显示有效时间 180 天\n","categories":["部署和安装"],"tags":["win"]},{"title":"部署 Office LTSC 2021 批量授权版本","url":"/53337b91-4f8d-11ee-9eaf-09d2cd19d790/","content":"\n\n\n\n0、前言本文仅提炼总结关键步骤，详情可见官网文档：https://learn.microsoft.com/zh-cn/deployoffice/ltsc2021/deploy?cid=kerryherger\n1、建立安装目录新建任意名称的目录 C:\\Users\\abc\\Desktop\\officefiles，用于归档部署过程中产生的文件。\n2、下载 Office 部署工具1）下载部署工具到 officefiles 目录，官网地址：https://www.microsoft.com/download/details.aspx?id=49117\n2）双击 officedeploymenttool.exe 可执行文件，选择提取文件路径，也直接放在 officefiles 目录\n3、创建 configuration.xml 文件使用 Office 自定义工具创建 configuration.xml 文件，工具地址：https://config.office.com/deploymentsettings，导出文件前要填写系列信息：\n1）体系结构 一般选择 64 位\n2）产品 中根据需求选择 office 套件和应用程序\n\nOffice 套件 选择 Office LTSC 专业增强版 2021 – 批量许可证\n\n如果需要 Visio，则 Visio 选择 Visio LTSC 专业版 2021 - 批量许可证，不需要则留空\n\nProject 与 其他产品 如无需要则留空\n\n\n3）应用 中根据需要选择组件，如：Word、PowerPoint、Access 等\n4）更新频道 不用动，下一步\n5）语言 选择 简体中文(中国)\n6）之后其他选项保持默认即可。完成后导出配置文件，选择 Office Open XML格式，放在 officefiles 目录\n\n注意：配置文件名称必须是 configuration.xml\n\n4、下载 Office LTSC 2021 安装文件1）以管理员身份打开 cmd，进入目录 C:\\Users\\abc\\Desktop\\officefiles\n2）执行 setup /download configuration.xml，此时在 officefiles 中会包含名为 Data 的新目录。\n5、安装 Office LTSC 20211）在目录 C:\\Users\\abc\\Desktop\\officefiles 中继续执行 setup /configure configuration.xml，安装完成后，将返回到命令提示符\n\n安装路径默认在 C:\\Program Files\\Microsoft Office\n\n6、激活1）以管理员身份打开 cmd，进入目录 C:\\Program Files\\Microsoft Office\\Office16\n2）假设已部署的 kms 服务器 ip 为 192.168.1.5，执行 cscript ospp.vbs /sethst:192.168.1.5 设置 kms 服务器地址。出现以下提示说明配置成功：\n---Processing-----------------------------------------------------------------Successfully applied setting.------------------------------------------Exiting-----------------------------\n\n\n可参考 部署 kms 服务器 的内容建立 kms 服务器\n\n3）执行 cscript ospp.vbs /act 激活。出现以下提示说明配置成功：\nMicrosoft (R) Windows Script Host Version 5.812版权所有(C) Microsoft Corporation。保留所有权利。---Processing-----------------------------------------------------------------Installed product key detected - attempting to activate the following product:SKU ID: fb61ac9a-1688-45d2-8f6b-0674dbffa33cLICENSE NAME: Office 21, Office21VisioPro2021VL_KMS_Client_AE editionLICENSE DESCRIPTION: Office 21, VOLUME_KMSCLIENT channelLast 5 characters of installed product key: K2HT4&lt;Product activation successful&gt;---------------------------------------Installed product key detected - attempting to activate the following product:SKU ID: fbdb3e18-a8ef-4fb3-9183-dffd60bd0984LICENSE NAME: Office 21, Office21ProPlus2021VL_KMS_Client_AE editionLICENSE DESCRIPTION: Office 21, VOLUME_KMSCLIENT channelLast 5 characters of installed product key: 6F7TH&lt;Product activation successful&gt;---------------------------------------------------------------------------------Exiting-----------------------------\n\n7、其他官方提供了上述使用到的 GVLK 列表（使用 Office 自定义工具创建 configuration.xml 文件时已经自动填写），详见：用于 KMS 和基于 Active Directory 的 Office、Project 和 Visio 激活的 GVLK\n","categories":["部署和安装"],"tags":["win","office"]},{"title":"部署 Windows Server 2022 Datacenter","url":"/077ca5b0-4ec4-11ee-86e1-a907f23a1148/","content":"\n\n\n\n1、下载安装包官方下载地址：https://www.microsoft.com/zh-cn/evalcenter/download-windows-server-2022\n\n注意：该下载为评估版本，需要升到正式版才能够激活。详见后续步骤\n\n2、设置网络安装后没有任何网络驱动，可按如下参考步骤接通有线连接：\n\n注：该案例主板为 ASUS PRIME B250M-PLUS，官网提供驱动不支持服务器系统\n\n1）进入「设备管理器」，双击打开「其他设备」\n2）此时「以太网控制器」应显示黄色叹号。右键选择「更新驱动程序」，选择「浏览我的电脑以查找驱动程序」，进一步选择「让我从计算机上….列表中选取」\n3）设备类型选择「网络适配器」\n4）左侧列表选择「intel Corporation」，右侧选择「Intel(R) Ethernet Connection 1219-LM」，下一步选「是」确认安装\n3、开启远程桌面默认为关闭，可按如下步骤开启：\n1）呼出开始菜单，打开「服务器管理器」\n2）进入「本地服务器」，点击「远程桌面」，选择允许即可\n4、关闭自动更新1）打开 cmd，执行 sconfig\n2）选择 5，更新设置，修改配置为「手动」\n5、激活系统1）确认当前系统版本\n从官网下载的版本为评估版本，可打开 cmd 执行 DISM /online /Get-CurrentEdition 输出系统信息，当前版本带有 Eval 结尾说明是评估版本：\n部署映像服务和管理工具版本: 10.0.20348.681映像版本: 10.0.20348.1787当前版本为:当前版本 : ServerDatacenterEval操作成功完成。\n\n2）前往 https://learn.microsoft.com/en-us/windows-server/get-started/kms-client-activation-keys 获取 Windows Server 2022 Datacenter 对应的 KMS Client Product Key\nWX4NM-KYWYW-QJJR4-XV3QB-6VM33\n\n3）执行 DISM /online /Set-Edition:ServerDatacenter /ProductKey:WX4NM-KYWYW-QJJR4-XV3QB-6VM33 /AcceptEula 等待更新完成，重启即可\n\n注意：默认的系统密钥切勿清除，必须保留\n\n4）此时系统密钥已经变更为上述从官网获得的 key，但仍提示未激活。可参考 部署 kms 服务器 的内容建立 kms 服务器\n5）建立完成后，假设已部署的 kms服务器ip为 192.168.1.5，执行 slmgr /skms 192.168.1.5 设置 kms 服务器地址\n6）直接执行 slmgr /ato 激活\n\n注意：不用执行卸载和安装密钥的步骤\n\n","categories":["部署和安装"],"tags":["win","server"]},{"title":"部署 kms 服务器","url":"/faef3d90-4ea4-11ee-addd-c161ce22f848/","content":"\n\n\n\n1、环境\nWindows 10 专业版 22H2\nUbuntu 22.04.2 LTS (GNU&#x2F;Linux 5.19.0-35-generic x86_64)\n\n\n建议在 ubuntu 环境下部署。win 环境容易促使杀毒软件报警；如果使用虚拟机部署，要让同一局域网其他设备访问，应设置虚拟网络为桥接模式\n\n2、Ubuntu 部署1）执行下载 wget https://github.com/Wind4/vlmcsd/releases/download/svn1113/binaries.tar.gz\n\n可到部署工具远程仓库查看最新版本：https://github.com/Wind4/vlmcsd/releases\n\n2）执行解压 tar -zxvf binaries.tar.gz\n3）进入目录 cd binaries/Linux/intel/static，执行 ./vlmcsdmulti-x64-musl-static vlmcsd\n\n注：如果重启或者关机，需要重新执行\n\n\n根据服务器系统和平台选择对应的文件，本文 ubuntu 环境为 x64，因此选用上述命令。其他可选：\n\nvlmcsdmulti-x64-musl-static          vlmcsd-x86-musl-staticvlmcsdmulti-x86-musl-static          vlmcsd-x86-musl-static-threadsvlmcsdmulti-x86-musl-static-threads  vlmcs-x64-musl-staticvlmcsd-x64-musl-static               vlmcs-x86-musl-static\n\n\n注意：要开放 1688 端口\n\n4）验证进程，执行 ps aux | grep vlmcsd，包含如下结果说明部署成功\nubuntu      2590  0.0  0.0    296     0 ?        S    20:45   0:00 ./vlmcsdmulti-x64-musl-static vlmcsd\n\n3、win10 部署1）下载部署文件，解压两次（binaries.tar.gz -&gt; binaries.tar -&gt; binaries）\n2）进入目录 binaries\\Windows\\intel，以管理员身份打开 cmd，执行 vlmcsd-Windows-x64.exe -s 安装服务\n\n注：vlmcsd-Windows-x64.exe -S 参数为大写 S 则移除服务\n\n3）在运行栏执行 services.msc 进入服务管理，找到 Key Management Server，启动该服务\n","categories":["部署和安装"],"tags":["win","ubuntu","kms"]},{"title":"部署-ubuntu-服务器","url":"/58871fa0-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n本例使用系统版本为 Ubuntu 22.04.2 LTS (GNU&#x2F;Linux 5.19.0-35-generic x86_64)\n\n提示：win 环境下最好使用 UltraISO 烧写镜像文件。经实测，按照官方文档推荐的 balenaEtcher 有损坏 U 盘风险。\n\n安装 ssh执行下列命令：\nsudo apt-get install openssh-server\n\n验证服务是否启动：sudo systemctl status ssh\n安装 Mariadb两种主要方式：\n1、Repositories 安装方式：https://mariadb.org/download/?t=repo-config&amp;d=22.04+%22jammy%22&amp;v=10.11&amp;r_m=neusoft\n2、从 https://archive.mariadb.org/mariadb-10.11.2/bintar-linux-systemd-x86_64/ 获得链接，直接下载压缩包\n\n本地二进制压缩包链接：https://archive.mariadb.org/mariadb-10.11.2/bintar-linux-systemd-x86_64/mariadb-10.11.2-linux-systemd-x86_64.tar.gz\n\n本例采用第一种。依次执行下列命令：\nsudo apt-get install apt-transport-https curlsudo curl -o /etc/apt/trusted.gpg.d/mariadb_release_signing_key.asc &#x27;https://mariadb.org/mariadb_release_signing_key.asc&#x27;sudo sh -c &quot;echo &#x27;deb https://mirrors.neusoft.edu.cn/mariadb/repo/10.11/ubuntu jammy main&#x27; &gt;&gt;/etc/apt/sources.list&quot;sudo apt-get updatesudo apt-get install mariadb-server\n\n3、验证服务是否启动：sudo systemctl status mariadb\n\n注意：安装完成后要执行 sudo -i 切换 root 再通过 mariadb -u root 进入设置密码：alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;MyNewPass4!&#39;;\n\n4、配置文件\n配置文件路径为：/etc/mysql/mariadb.conf.d/50-server.cnf\n5、取消 IP 限制\n当执行 netstat -an|grep 3306 命令发现如下反馈，说明此时无法远程连接数据库。\nubuntu@ubuntu-virtual-machine:~$ netstat -an|grep 3306tcp        0      0 127.0.0.1:3306          0.0.0.0:*               LISTEN\n\n打开配置文件\nsudo vim /etc/mysql/mariadb.conf.d/50-server.cnf\n\n找到 bind-address = 127.0.0.1 注释掉。\n\n可能需要安装 vim 编辑器，执行 sudo apt-get install vim\n\n部署 JDK以 corretto 为例。按相应 JDK 版本依次执行命令：\n官方文档：https://docs.aws.amazon.com/corretto/latest/corretto-17-ug/generic-linux-install.html\n1、JDK11\nwget -O- https://apt.corretto.aws/corretto.key | sudo apt-key add -sudo add-apt-repository &#x27;deb https://apt.corretto.aws stable main&#x27;sudo apt-get update; sudo apt-get install -y java-11-amazon-corretto-jdk\n\n2、JDK17\nwget -O- https://apt.corretto.aws/corretto.key | sudo apt-key add -sudo add-apt-repository &#x27;deb https://apt.corretto.aws stable main&#x27;sudo apt-get update; sudo apt-get install -y java-17-amazon-corretto-jdk\n\n3、卸载\nsudo dpkg --remove java-11-amazon-corretto-jdksudo dpkg --remove java-17-amazon-corretto-jdk\n\n修改本地网络地址1、固定 IP\n通过 ip a 命令查看网咖信息。修改前：\nubuntu@ubuntu-virtual-machine:~$ ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000    link/ether 00:0c:29:cb:bf:c6 brd ff:ff:ff:ff:ff:ff    altname enp2s1    inet 192.168.160.133/24 brd 192.168.160.255 scope global dynamic noprefixroute ens33       valid_lft 1555sec preferred_lft 1555sec    inet6 fe80::85bd:d35d:f025:dcf4/64 scope link noprefixroute       valid_lft forever preferred_lft forever\n\n查看 /etc/netplan 网络配置文件：\nubuntu@ubuntu-virtual-machine:~$ ls /etc/netplan01-network-manager-all.yaml\n\n执行 sudo vim /etc/netplan/*.yaml，添加以下内容：\n# Let NetworkManager manage all devices on this systemnetwork:    version: 2    renderer: NetworkManager    ethernets:       ens33:          addresses: [192.168.160.134/24]          routes:            - to: default              via: 192.168.160.2          nameservers:             addresses: [180.76.76.76, 223.5.5.5]\n\n其中：\n\nens33：拟设置的网卡名称\naddresses：拟设置的固定 ip 和掩码。掩码 24 表示前 24 位有效，剩下的 8 位可以是 0-254 之间的任一地址（255 为广播地址），例如 255.255.255.255 是 IPv4 中最大可能的 IP 地址，每个数字（255）都是由 8 个比特位表示的，每个比特位非 0 即 1，最大值即为 11111111，因此掩码 24 表示 255.255.255.0。同理，xxx.xxx.xxx.xxx&#x2F;32，表示掩码为 192.168.0.0\nroutes：网关地址。default 也可以写为 0.0.0.0/0 或 0/0\nnameservers：DNS 地址\n\n\n网关若使用 gateway4 属性会提示 ** (process:9908): WARNING **: 22:03:51.792: gateway4 has been deprecated, use default routes instead. See the &#39;Default routes&#39; section of the documentation for more details.\n\n执行 sudo netplan try 使配置生效。修改后：\nubuntu@ubuntu-virtual-machine:~$ ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000    link/ether 00:0c:29:cb:bf:c6 brd ff:ff:ff:ff:ff:ff    altname enp2s1    inet 192.168.160.134/24 brd 192.168.160.255 scope global noprefixroute ens33       valid_lft forever preferred_lft forever    inet6 fe80::20c:29ff:fecb:bfc6/64 scope link       valid_lft forever preferred_lft forever\n\n2、开启 dhcp\n无需再设置 addresses 属性（实际上 routes 属性也可以移除）。配置如下：\n# Let NetworkManager manage all devices on this systemnetwork:    version: 2    renderer: NetworkManager    ethernets:       ens33:          dhcp4: true          routes:            - to: default              via: 192.168.160.2          nameservers:             addresses: [180.76.76.76, 223.5.5.5]\n\n其他工具或命令查看 CPU、内存使用情况：sudo apt-get install htop\n防火墙一般系统默认带有防火墙。安装命令：sudo apt install ufw\n1、允许 ssh（特别注意开启，否则下次连接将无法远程连接）\n执行 sudo ufw allow ssh 或 sudo ufw allow 22 创建防火墙规则，允许 22 端口上的所有连接。\n2、启用 ufw\n执行 sudo ufw enable，确认启动后可通过 sudo ufw status verbose 查看状态。\n\n注：当状态为 Status: inactive 说明 ufw 未启动。如果处于活动状态，将显示 Status: active，并列出所有规则。\n\n3、拒绝连接\n执行 sudo ufw deny from 192.1.110.24，则拒绝全部来自该 IP 的连接。\n4、删除规则\n执行 sudo ufw status numbered 查看规则列表，获知规则的序号，再执行 sudo ufw delete 3（删除第 3 条规则）\n5、端口规则设置\nufw 默认的策略是允许出，不允许进，这个可以在配置文件 /etc/default/ufw 中看到。出规则需要配置。\n配置文件片段：\nDEFAULT_INPUT_POLICY = &quot;DROP&quot;;DEFAULT_OUTPUT_POLICY = &quot;ACCEPT&quot;;\n\n\n允许 http 连接：sudo ufw allow http 或 sudo ufw allow 80\n阻止 http 连接：sudo ufw denty http 或 sudo ufw denty 80\n开放特定端口范围：sudo ufw allow 3000:3007/tcp\n\n\n注：如果不指定协议，会自动允许 tcp 和 udp 两种协议。\n\n\n限制 IP 允许连接的端口：sudo ufw allow from 192.1.110.24 to any port 22\n配合子网掩码限制网段：sudo ufw allow from 192.1.110.24/24\n监听来自指定网卡的连接：sudo ufw allow in on eth1 to any port 3306\n\n6、停止和重置\n\n停用 ufw：sudo ufw disable\n重置 ufw 规则：sudo ufw reset\n\n其他相关命令\n显示所有连接：lsof -i\n仅获取 ipv6 流量：lsof -i6\n显示端口信息：lsof -i :5432\n\n\nlsof 命令参数：lsof -i[46] [protocol][@hostname|hostaddr][:service|port]\n\n\n列出所有：netstat -a \n使用 ip 地址列出所有监听状态的 tcp 端口以及程序名：netstat -atnlp\n\n\nnetstat 命令参数：\n\n\n显示所有连接中的 Socket：-a 或 --all\n显示正在使用 Socket 的程序识别码和程序名称：-p 或 --programs\n显示 TCP 传输协议的连线状况：-t 或 --tcp\n显示 UDP 传输协议的连线状况：-u 或 --udp\n\n显示结果参数释义：\n\nProto：协议名（tcp 协议还是 udp 协议还是 unix 协议）\n\nRecv-Q：网络接收队列。表示收到的数据已经在本地接收缓冲，但是还有多少没有被进程取走，recv()如果接收队列 Recv-Q 一直处于阻塞状态，可能是遭受了拒绝服务 denial-of-service 攻击；\n\nsend-Q：网路发送队列。对方没有收到的数据或者说没有 Ack 的,还是本地缓冲区.\n\nLocal Address：表示监听服务器上对应的 ip 地址的对应端口 (0.0.0.0 表示本地所有 ip)\n\nForeign Address：与本机端口通信的外部 socket。显示规则与 Local Address 相同\n\nState：链路状态。共有 12 中可能的状态\n\nLISTEN ：正在监听端口，可以接受连接\n\nSYN_SENT：socket 正在积极尝试建立一个连接，即处于发送后连接前的一个等待但未匹配进入连接的状态\n\nSYN_RECV：收到对方的连接建立请求\n\nESTABLISHED：代表一个打开的连接，双方可以进行或已经在数据交互\n\nFIN_WAIT1：socket 已关闭，连接正在或正要关闭\n\nCLOSE_WAIT：等待关闭。当对方关闭一个 SOCKET 后发送 FIN 报文给自己，系统毫无疑问地会回应一个 ACK 报文给对方，此时则进入到 CLOSE_WAIT 状态。接下来需要考虑的事情是察看你是否还有数据发送给对方，如果没有就可以关闭这个 SOCKET，发送 FIN 报文给对方，也即关闭连接。所以在 CLOSE_WAIT 状态下，需要完成的事情是等待你去关闭连接。\n\nFIN_WAIT2：连接已关闭，并且 socket 正在等待远端结束\n\nLAST_ACK：被动关闭一方在发送 FIN 报文后，最后等待对方的 ACK 报文。当收到 ACK 报文后，也即可以进入到 CLOSED 可用状态\n\nTIME_WAIT：socket 正在等待关闭处理仍在网络上的数据包。表示收到了对方的 FIN 报文，并发送出了 ACK 报文，就等 2MSL 后即可回到 CLOSED 可用状态。如果 FIN_WAIT_1 状态下，收到了对方同时带 FIN 标志和 ACK 标志的报文时，可以直接进入到 TIME_WAIT 状态，而无须经过 FIN_WAIT_2 状态。\n\nCLOSING：比较少见，等待远程 TCP 对连接中断的确认\n\nCLOSED：没有任何连接状态。被动关闭端在接受到 ACK 包后，就进入该状态。连接结束\n\nUNKNOWN：未知的状态\n\n\n\n\n","categories":["部署和安装"],"tags":["ubuntu","mariadb"]},{"title":"部署win10+vscode+anaconda3环境","url":"/148d4631-44e0-11ee-bc05-f9725afef782/","content":"\n\n\n\n1、安装 anaconda3务必选择添加环境变量（或用户变量），便于 vscode 新建环境，或者手动添加，假设安装目录为 D:\\anaconda3，添加如下路径：\nD:\\anaconda3D:\\anaconda3\\Library\\mingw-w64\\binD:\\anaconda3\\Library\\usr\\binD:\\anaconda3\\Library\\binD:\\anaconda3\\Scripts\n\n2、vscode 安装微软官方 python 插件，相关信息如下Name: PythonId: ms-python.pythonDescription: IntelliSense (Pylance), Linting, Debugging (multi-threaded, remote), Jupyter Notebooks, code formatting, refactoring, unit tests, and more.Version: 2023.10.1Publisher: MicrosoftVS Marketplace Link: https://marketplace.visualstudio.com/items?itemName=ms-python.python\n\n3、创建或复用 conda 环境1）创建匿名 conda 环境\nctrl+shift+P，输入&gt; Create Environment 命令，选择建立 conda 环境，进一步选择 python 版本。\n\n注意：这种方式会在项目下新建 .conda 目录。\n\n重新启动终端，将以全路径方式激活：\n(base) PS E:\\test&gt; activate(base) PS E:\\test&gt; conda activate e:\\test\\.conda(e:\\test\\.conda) PS E:\\test&gt;\n\n2）创建指定名称的 conda 环境\n终端执行 conda create -n &lt;env_name&gt; python=&lt;version&gt; 即可创建指定 python 版本且名为 env_name 的环境，该环境一般放在目录 anaconda3\\envs 下\n重新启动终端，将以名称激活：\n(base) PS E:\\test&gt; C:/anaconda3/Scripts/activate(base) PS E:\\test&gt; conda activate env_name(env_name) PS E:\\test&gt;\n\n3）复用\nctrl+shift+P，输入&gt; Select Interpreter 命令，选择已存在的 conda 环境（包括当前目录的匿名环境），重启终端即可。\n\n注意：重新选择环境后要重新进入终端\n\n4、问题及解决方案问题 1： 出现如下提示，应执行 conda init powershell，之后重新启动 vscode\nCommandNotFoundError: Your shell has not been properly configured to use &#x27;conda activate&#x27;.If using &#x27;conda activate&#x27; from a batch script, change yourinvocation to &#x27;CALL conda.bat activate&#x27;.To initialize your shell, run    $ conda init &lt;SHELL_NAME&gt;Currently supported shells are:  - bash  - cmd.exe  - fish  - tcsh  - xonsh  - zsh  - powershellSee &#x27;conda init --help&#x27; for more information and options.IMPORTANT: You may need to close and restart your shell after running &#x27;conda init&#x27;.\n\n问题 2： 使用终端进入 conda 环境的项目目录时，可能会提示报错信息：“……在此系统上禁止运行脚本”，\nvscode 终端选择 Windows PowerShell 时，默认执行策略是 Restricted，即不允许任何脚本运行。\n\n有关 Windows PowerShell 执行策略的详细信息，请参阅 about_Execution_Policy。\n\n\n可执行 get-executionpolicy 命令查看当前策略\n\n以管理员身份打开 PowerShell 输入 set-executionpolicy remotesigned，重启 vscode 终端，即可切换到当前 conda 环境。一般而言，解除上述问题后，每次新建终端进入 conda 环境后，会自动执行 active 和 conda active 命令进入默认的 base 环境，例如：\n(base) PS E:\\test&gt; activate(base) PS E:\\test&gt; conda activate base(base) PS E:\\test&gt;\n\n5、其他相关命令\n查看安装源：conda config --show-sources\n添加安装源：conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n其他安装源：conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/\n其他安装源：conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/\n换回 conda 的默认源，删除 channels：conda config --remove-key channels\n\n\n删除安装源：conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n查看源优先级：conda config --get channels\n查看 .condarc 文件位置（执行 conda config 系列命令时生成）：conda info\n显示 channel 来源： conda config --set show_channel_urls yes\n查看所有虚拟环境：conda info --envs 或 conda env list\n安装指定版本依赖：conda install package=version\n临时指定源：conda install package=version -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n\n","categories":["部署和安装"],"tags":["anaconda"]},{"title":"VBA 案例片段合集","url":"/eaa9ecc0-3c36-11ef-91e1-efd3d29ea494/","content":"\n\n\n\n调整行高Sub Macro1()    Dim arr, rng As Range, i&amp;    Application.ScreenUpdating = False    t = Timer    arr = Range(&quot;A1&quot;).CurrentRegion    For i = 1 To UBound(arr)        If Rows(i).RowHeight &gt; 10 Then            If rng Is Nothing Then                Set rng = Cells(i, 1)            Else                Set rng = Union(rng, Cells(i, 1))        End If    Next    If Not rng Is Nothing Then        rng.EntireRow.RowHeight = 10    Application.ScreenUpdating = True    MsgBox Timer - tEnd Sub\n\n\n释义：遍历 A 列中不为空的行，将行高设置为 10。\n\n细节说明：\n\nApplication.ScreenUpdating = False，关闭视图跟随\nt = Timer，获取当前时间（非本案例必须）\nUBound(arr)，返回引用区域的上限值\n\n获取行数和列数1、方式一：\nActiveSheet.UsedRange.Rows.CountActiveSheet.UsedRange.Columns.Count\n\n注意事项：该方式结果可能会大于现有数量，原因曾经删除过行（或列），而且是非整行或整列删除。该语句仍返回未删除前的值，这部分行虽然已经删除，但是也记录在内。\n2、方式二：\nActiveSheet.Range(&quot;A65535&quot;).End(xlUp).RowActiveSheet.Range(&quot;IV1&quot;).End(xlToLeft).Column\n\n或\nActiveSheet.[A65536].End(xlUp).RowActiveSheet.[IV1].End(xlToLeft).Column\n\n注意事项：只能计算出一列（行）的最后一个单元格所在的行（列）数。本例返回 A 列最后一个单元格所占的行数。\n3、方式三：\nApplication.CountA(ActiveSheet.Range(&quot;A:A&quot;))Application.CountA(ActiveSheet.Range(&quot;1:1&quot;))\n\n或\nApplication.CountA(ActiveSheet.Columns(1))Application.CountA(ActiveSheet.Columns(1))\n\n注意事项：只能统计一列（行）的实际使用情况，得到的不一定是最后一行（列）的位置。方式二的数值比此方式大时，说明在 A 列的数据间有空白未填写的单元格。\n判断文件是否打开Function isOpen(strName As String) As Boolean    Dim w As Workbook    For Each w In Application.Workbooks        If w.Name = strName Then            isOpen = True: Exit Function        End If    Next    isOpen = FalseEnd Function\n\n清除工作表中所有无内容空行Sub 删除空行()    &#x27;关闭视图跟随    Application.ScreenUpdating = False    &#x27;定义变量    Dim sheet As Worksheet    &#x27;最大行数    Dim maxLineNum    &#x27;循环变量    Dim index As Integer    &#x27;内容为空的最小行号    Dim minLineNum As Integer: minLineNum = 0    &#x27;遍历所有工作表    For Each sheet In Sheets        &#x27;清零        minLineNum = 0        &#x27;激活要操作的工作表        sheet.Activate        &#x27;解锁（必须要解锁工作表才能够删除行）        sheet.Unprotect Password:=123456        &#x27;获取最大行数        maxLineNum = sheet.[A65536].End(xlUp).Row        &#x27;逆序删除（删除行或列均需要逆序删除）        For index = maxLineNum To 3 Step -1            &#x27;B 列内容为空则判为无内容空行            If sheet.Range(&quot;B&quot; &amp; Trim(Str(index))).Value = &quot;&quot; Then                minLineNum = index            End If        Next        If minLineNum &gt; 0 Then            sheet.Range(sheet.Rows(minLineNum), sheet.Rows(maxLineNum - 1)).Delete        End If        &#x27;执行完毕后恢复加锁状态        sheet.Protect Password:=123456    NextEnd Sub\n\n筛选二维数组重复元素以二维数组为例\nSub RemovingDuplication()    &#x27;临时变量    Dim indexRow, indexA, indexB As Integer    &#x27;无重复元素动态一维数组    Dim resultTempArray()    ReDim resultTempArray(1 To 1)    &#x27;筛选中间元素数组    Dim tempArray()    Dim tempSplit() As String    Dim Temp As String    &#x27;遍历二维数组每行    For indexRow = 1 To 2        &#x27;取第 n 行        tempArray = Application.index(dataArray, indexRow, 0)        &#x27;重复元素用 @ 替代        For indexA = 1 To UBound(tempArray)            For indexB = indexA + 1 To UBound(tempArray)                If tempArray(indexA) = tempArray(indexB) Then tempArray(indexB) = &quot;@&quot;            Next        Next        &#x27;分隔 tempArray，消除 @ 标记，用空白字符串代替，获得无重复元素字符串        Temp = Replace(Join(tempArray, &quot;,&quot;), &quot;@&quot;, &quot;&quot;)        &#x27;将无重复元素字符串重新按逗号分隔        tempSplit = Split(Temp, &quot;,&quot;)        For indexA = LBound(tempSplit) To UBound(tempSplit)            &#x27;将不为空字符串的元素存入动态一维数组            If tempSplit(indexA) &lt;&gt; &quot;&quot; Then                resultTempArray(UBound(resultTempArray)) = tempSplit(indexA)                ReDim Preserve resultTempArray(1 To UBound(resultTempArray) + 1)            End If        Next        &#x27;清空，构建结果字符串，格式为：（序号）元素名称，间隔为空格        Temp = &quot;&quot;        For indexA = 1 To UBound(resultTempArray) - 1            Temp = Temp + &quot;(&quot; + Trim(Str(indexA)) + &quot;)&quot; + resultTempArray(indexA)            If indexA &lt;&gt; UBound(resultTempArray) - 1 Then                Temp = Temp + &quot; &quot;            End If        Next        &#x27;写入结果        With Worksheets(&quot;样品数据&quot;)            &#x27;根据下标来依次填写结果到单元格，本例共两个类别            .Range(&quot;类别&quot; &amp; Trim(Str(indexRow))).Value = UBound(resultTempArray) - 1            .Range(&quot;详细&quot; &amp; Trim(Str(indexRow))).Value = Temp        End With        &#x27;每次统计下个类别前都清空        ReDim resultTempArray(1 To 1)    NextEnd Sub\n\n实现将指定内容跨文件复制将 workBook1.xlsm 所有工作表的指定区域复制到 workBook2.xlsx，更新标题，工作表名称不变，并设置打印信息。\nSub CopyRangeAcrossFile()    &#x27;关闭视图跟随    Application.ScreenUpdating = False    Dim desSheet, desTitle, bottomTitle, sheet As Worksheet    &#x27;最大行数    Dim maxLineNum    Set desSheet = Workbooks.Open(ThisWorkbook.Path &amp; &quot;\\&quot; &amp; &quot;workBook2.xlsx&quot;)    For Each sheet In Sheets        &#x27;获取第一列的长度（包含无内容空行）        maxLineNum = WorksheetFunction.CountA(sheet.Columns(1))        &#x27;激活要复制的工作表（重要，否则无法复制）        sheet.Activate        &#x27;指定复制区域        sheet.Range(&quot;A1:M&quot; &amp; Trim(Str(maxLineNum))).Select        Selection.Copy        &#x27;激活要粘贴的工作表（注意：workBook2.xlsx 至少有一个空表，否则无法粘贴）        desSheet.Sheets(1).Activate        &#x27;新建工作表，名称与原工作表相同        desSheet.Worksheets.Add().Name = sheet.Name        &#x27;选择新工作表中要粘贴的区域        desSheet.Sheets(sheet.Name).Range(&quot;A1&quot;).Select        &#x27;不运算粘贴、不跳过空格、不转置        Selection.PasteSpecial Paste:=xlPasteAll, Operation:=xlNone, SkipBlanks:=False, Transpose:=False        &#x27;更新新工作表标题        desSheet.Sheets(sheet.Name).Range(&quot;A1&quot;).Value = &quot;new&quot; &amp; sheet.Range(&quot;A1&quot;).Value        &#x27;设置新工作表标题字体        desSheet.Sheets(sheet.Name).Range(&quot;A1&quot;).Font.Size = 14        &#x27;设置新工作表行高（全部行）        desSheet.Sheets(sheet.Name).Cells.RowHeight = 28        &#x27;独立设置新工作表标题行高        desSheet.Sheets(sheet.Name).Rows(1).RowHeight = 50        &#x27;设置新工作表 A 列列宽        desSheet.Sheets(sheet.Name).Columns(&quot;A&quot;).ColumnWidth = 3        &#x27;设置新工作表打印信息        With desSheet.Sheets(sheet.Name).PageSetup            &#x27;设置页面的方向。xlPortrait 纵向；xlLandscape 横向            .Orientation = xlLandscape            &#x27;左右页边距            .LeftMargin = Application.InchesToPoints(1)            .RightMargin = Application.InchesToPoints(1)            &#x27;设置打印区域            .PrintArea = &quot;A1:L&quot; &amp; Trim(Str(maxLineNum + 4))        End With    NextEnd Sub\n\n使用 ReDim 实现二维动态数组Sub DynamicArray()    Dim cellType, rowIndex, sheet As Worksheet    &#x27;定义数组    Dim dataArray()    &#x27;改变大小（必须要在使用前定好基础大小，初始为 2 行 1 列）    ReDim dataArray(1 To 2, 1 To 1)    &#x27;遍历所有工作表    For Each sheet In Sheets        &#x27;遍历行        For rowIndex = 1 To 65535            &#x27;获取 O 列单元格的值            cellType = sheet.Range(&quot;O&quot; &amp; Trim(Str(rowIndex))).Value            &#x27;遇到内容为空的行意味着到达结尾，退出循环            If cellType = &quot;&quot; Then                Exit For            End If            &#x27;根据内容分类存入数组            If cellType = &quot;苹果&quot; Then                &#x27;获取当前数组的列数上限所在位置，存入                dataArray(1, UBound(dataArray, 2)) = cellName                &#x27;改变大小，本列增加 1 个存储位置                ReDim Preserve dataArray(1 To 11, 1 To UBound(dataArray, 2) + 1)            ElseIf cellType = &quot;荔枝&quot; Then                dataArray(2, UBound(dataArray, 2)) = cellName                ReDim Preserve dataArray(1 To 11, 1 To UBound(dataArray, 2) + 1)            End If        Next    NextEnd Sub\n\nVBA 在工作表插入新行Sub InsertRow()    Dim currentSheet As Worksheet    &#x27;激活当前工作表    Set currentSheet = ActiveSheet    &#x27;限制不能插入行的工作表    If currentSheet.Name = &quot;Sheet1&quot; Or currentSheet.Name = &quot;Sheet2&quot; Then        MsgBox &quot;该表格不允许添加行！&quot;        Exit Sub    End If    &#x27;获取当前激活工作表的最大行数（）    Dim maxLineNum    &#x27;对话框确定插入行数    Dim insertNum As Integer    insertNum = InputBox(&quot;输入要插入的行数！&quot;, &quot;输入行数&quot;, &quot;&quot;)    &#x27;解锁（必须要解锁工作表才能够增加行）    currentSheet.Unprotect Password:=123456    &#x27;循环变量    Dim index As Integer    &#x27;循环，在当前激活工作表末尾插入新行    For index = 1 To insertNum        &#x27;获取当前激活工作表有效行数上限（不含无内容空行）        maxLineNum = WorksheetFunction.CountA(currentSheet.Columns(1))        currentSheet.Rows(maxLineNum).Insert shift:=xlShiftDown    Next    &#x27;执行完毕后恢复加锁状态    currentSheet.Protect Password:=123456End Sub\n","categories":["其他分类","Excel"],"tags":["VBA"]},{"title":"公式案例合集","url":"/eaaa13d0-3c36-11ef-91e1-efd3d29ea494/","content":"\n\n\n\nINDIRECT 通过字符串或变量引用单元格和区域INDIRECT(ref_text, [a1])\n\n释义：返回由文本字符串指定的引用，可以是单元格，也可以是区域。\n\n参数说明：\n\nRef_text，必需。对包含 A1 样式及 R1C1 样式的引用、定义为引用的名称或对单元格的引用作为文本字符串的单元格的引用。如果 ref_text 不是有效的单元格引用, 则间接返回 #REF!；如果 ref_text 引用另一个工作簿（外部引用），则必须打开另一个工作簿。如果源工作簿未打开, 则间接返回 #REF!。注意：Excel Web App 中不支持外部引用；如果 ref_text 引用的单元格区域超出 1048576 的行限制或列限制 16384（XFD）, 则间接返回 #REF! 错误。此行为不同于早于 Microsoft Office Excel 2007 的 Excel 版本, 这将忽略超过的限制并返回值。\nA1，可选。一个逻辑值，用于指定包含在单元格 ref_text 中的引用的类型。如果 a1 为 TRUE 或省略，ref_text 被解释为 A1-样式的引用；如果 a1 为 FALSE，则将 ref_text 解释为 R1C1 样式的引用。\n\n使用案例：\n\n可通过变量来构造表名，设 A3 值为 1，C3 值为 sheet，要返回名称 sheet1 表中 E3:E200 区域的引用：=INDIRECT(C3&amp;A3&quot;!E3:E200&quot;)；返回单元格：=INDIRECT(C3&amp;A3&quot;!B1&quot;)\n\nISNUMBER 判断单元格内容是否为数字ISNUMBER()\n\n释义：如果目标单元格为数值则返回 TRUE，否则 FALSE。\n\n使用案例：\n\n结合 IF 函数，可使用公式判断单元格值：=IF(ISNUMBER(A1),&quot;是&quot;,&quot;否&quot;)\n若要判定文本型数值，需要利用 VALUE() 函数对内容进行数值转换，如果转换成功说明确实为数值；如果出错则说明不是数值。上述公式改为：=IF(ISERROR(VALUE(A1)),&quot;否&quot;,&quot;是&quot;)\n\nLOOKUP 函数中 0/ 含义解读\n\n\nA\nB\nC\nD\nH\nI\n\n\n\n1\n\n\n\n\n\n\n\n2\n编号\n姓名\n销量\n姓名\n销量\n\n\n3\n1\n王东\n66\n王东\n？\n\n\n4\n2\n张三\n56\n\n\n\n\n5\n3\n李四\n67\n\n\n\n\n6\n4\n王五\n56\n\n\n\n\n7\n5\n二三\n33\n\n\n\n\n8\n6\n西西\n57\n\n\n\n\n9\n7\n南北\n20\n\n\n\n\n查询王东的销量，在 I3 输入公式：\nLOOKUP(1,0/(B3:B9=H3),C3:C9)\n\n公式解读\nB3:B9=H3 的运算结果\n\n如果 A=B，会返回结果 TRUE，TRUE 在运算中相当于数字 1\n\n如果 A&lt;&gt;B，会返回结果 FALSE，FALSE 在运算中相当于数字 0\n\n\n所以：B3:B9=H3 的运算结果是有 TRUE 和 FALSE 构成的一组值，结果如下图：\n\n\n\nA\nB\nC\nD\nH\nI\nJ\nK\n\n\n\n1\n\n\n\n\n\n\n\n\n\n2\n编号\n姓名\n销量\n姓名\n销量\n(B3:B9&#x3D;H3)的运算结果\n0&#x2F;(B3:B9&#x3D;H3)\n\n\n3\n1\n王东\n66\n王东\n？\nTRUE\n0\n\n\n4\n2\n张三\n56\n\n\nFALSE\n#DIV&#x2F;0!\n\n\n5\n3\n李四\n67\n\n\nFALSE\n#DIV&#x2F;0!\n\n\n6\n4\n王五\n56\n\n\nFALSE\n#DIV&#x2F;0!\n\n\n7\n5\n二三\n33\n\n\nFALSE\n#DIV&#x2F;0!\n\n\n8\n6\n西西\n57\n\n\nFALSE\n#DIV&#x2F;0!\n\n\n9\n7\n南北\n20\n\n\nFALSE\n#DIV&#x2F;0!\n\n\n0/(B3:B9=H3) 的结果如上图。\n提取所需值原理\n\nLOOKUP 函数查找时可以忽略错误值且，这样一组数值忽略后只剩下一个值 0。\n\nLOOKUP 函数当查找的值不存在时，按照小于此值的最大值进行匹配。故设置查找值为 1，从而实现查询的目的。\n\n\n\n备注：0/ 的目的就是把符合条件的值变为 0，不符合条件的变为错误，利用 LOOKUP 函数的特征查找到符合条件的值。\n\n多条件查询\n查询销售员在相应地区的销售额。\n方法：\n在目标单元格中输入公式：=IFERROR(LOOKUP(1,0/((B3:B9=H3)*(E3:E9=I3)),C3:C9),&quot;&quot;)\n释义：\n1、原理和单条件查询是一样的。\n2、TRUE*TRUE=1，TRUE*FALSE=0\n\n\n\nA\nB\nC\nD\nE\nF\nH\nI\nJ\nJ\nK\n\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n2\n编号\n姓名\n销量\n性别\n地区\n姓名\n地区\n销量\n(B3:B9&#x3D;H3)运算结果\n(E3:E9&#x3D;I3)运算结果\n\n\n3\n1\n王东\n66\n男\n北京\n王东\n北京\n？\nTRUE\nTRUE\n\n\n4\n2\n张三\n56\n男\n上海\n\n\n\nFALSE\nFALSE\n\n\n5\n3\n李四\n67\n女\n苏州\n\n\n\nFALSE\nFALSE\n\n\n6\n4\n王五\n56\n女\n上海\n\n\n\nFALSE\nFALSE\n\n\n7\n5\n二三\n33\n男\n天津\n\n\n\nFALSE\nFALSE\n\n\n8\n6\n西西\n57\n女\n上海\n\n\n\nFALSE\nFALSE\n\n\n9\n7\n南北\n20\n男\n上海\n\n\n\nFALSE\nFALSE\n\n\nMATCH运算方式\n这个函数有三个参数：第一个参数是查找对象，第二参数指定查找的范围或是数组，第三参数为查找的匹配方式。第三参数有三个选项：0、1、-1，分别表示精确匹配、升序查找、降序查找模式。\n例 1：以下公式返回 2\n=MATCH(“A”,&#123;“C”,”A”,”B”,”A”,”D”&#125;,0)\n\n第三参数使用 0，表示在第 2 个参数的数组中精确字母 A 第一次出现的位置为 2，不考虑第 2 次出现位置，且第 2 个参数无需排序。\n例 2：以下公式返回 3\n=MATCH(6,&#123;1,3,5,7&#125;,1)\n\n第三参数使用 1，（也可省略），其中第 2 个参数的数组要求按升序排列，并查找出小于或等于 6 的最大值（即数组中的 5）在第 3 个元素位置。\n例 3：以下公式返回 2。\n=MATCH(8,&#123;11,9,6,5,3,1&#125;,-1)\n\n其中第 2 个参数的数组要求按降序排列，并查找出大于或等于 8 的最小值（即数组中的 9）在第 2 个元素位置。\nMATCH 函数与 INDEX\n函数逆向查询\n由于实际应用中，只要求返回位置的问题不多，好像 MATCH 函数一时派不上用场了。其实这个函数更多的时候，是与其他引用类函数组合应用，最典型的使用是与 INDEX 函数组合，能够完成类似 VLOOKUP 函数和 HLOOKUP 函数的查找功能，并且可以实现逆向查询，即从左向右或是从下向上查询。\n如下图所示，需要根据 E 列的姓名在 A 列查询对应的部门。\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n1\n部门\n姓名\n\n部门\n姓名\n\n\n2\n财务部\n小兰\n\n？\n小美\n\n\n3\n销售部\n小翠\n\n\n\n\n\n4\n采购部\n小美\n\n\n\n\n\n5\n人资部\n小花\n\n\n\n\n\n6\n安监部\n小青\n\n\n\n\n\n7\n质保部\n小丽\n\n\n\n\n\n8\n仓储部\n小芳\n\n\n\n\n\n这种逆向查询的数据可以使用 LOOKUP 函数，用 INDEX+MATCH 函数实现的方法。D2 单元格输入以下公式：\n=INDEX(A:A,MATCH(E2,B:B,))\n\n返回查询结果为采购部。\nINDEX 函数是常用的引用类函数之一，可以在一个区域引用或数组范围中，根据指定的行号和列号来返回一个值。\nMATCH(E2,B:B,) 部分，第三参数简写，表示使用 0，即精确匹配方式查询 E2 单元格姓名 小美 在 B 列的位置，结果为 4。计算结果用作 INDEX 函数的参数，INDEX 函数再根据指定的行号返回 A 列中对应的值。\n使用 INDEX 函数和 MATCH 函数的组合应用来查询数据，公式看似相对复杂一些，但在实际应用中，更加灵活多变。\n1、查找首次出现的位置\n除了使用特定的值作为查询参数，也可以使用逻辑值进行查询。以下图为例，是某公司的销售数据。需要查询首次超过平均销售额的月份。\n\n\n\n\nA\nB\nC\nD\n\n\n\n1\n月份\n销售额\n\n首次超过平均销售额的月份\n\n\n2\n一月\n855\n\n？\n\n\n3\n二月\n827\n\n\n\n\n4\n三月\n893\n\n\n\n\n5\n四月\n899\n\n\n\n\n6\n五月\n895\n\n\n\n\n7\n六月\n921\n\n\n\n\n8\n七月\n897\n\n\n\n\n8\n八月\n932\n\n\n\n\n8\n九月\n943\n\n\n\n\n8\n十月\n910\n\n\n\n\n8\n十一月\n821\n\n\n\n\n8\n十二月\n951\n\n\n\n\nD2 单元格使用以下数组公式：\n=INDEX(A2:A13,MATCH(TRUE,B2:B13&gt;AVERAGE(B2:B13),))\n\n\n数组公式要按 Shift+Ctrl+Enter 组合键\n\n计算过程：\n\nAVERAGE(B2:B13)部分，用来计算出 B2:B13 单元格的平均值 895.33。\nB2:B13&gt;AVERAGE(B2:B13)部分，用 B2:B13 与平均值分别作比较，得到由逻辑值 TRUE 或是 FALSE 组成的内存数组：&#123;FALSE;FALSE;FALSE;TRUE;FALSE;FALSE;TRUE;FALSE;TRUE;TRUE;TRUE;TRUE;FALSE;TRUE&#125;\nMATCH 函数第一参数使用逻辑值 TRUE，使用精确匹配方式查询 TRUE 在数组中第一次出现的位置，结果为 4。本例中的第一参数也可以写成 1=1，返回逻辑值 TRUE，与直接使用 TRUE 效果相同。\nMATCH 函数的计算结果用作 INDEX 函数的参数，INDEX 函数再根据指定的行号返回 A 列中对应的月份。\n\n2、查找最后一次出现的位置\n除了查询首次出现的位置，MATCH 函数还可以查询最后一次出现的位置。以下图为例，需要查询最后次超过平均销售额的月份。\n\n\n\n\nA\nB\nC\nD\n\n\n\n1\n月份\n销售额\n\n最后一次超过平均销售额的月份\n\n\n2\n一月\n855\n\n？\n\n\n3\n二月\n827\n\n\n\n\n4\n三月\n893\n\n\n\n\n5\n四月\n899\n\n\n\n\n6\n五月\n895\n\n\n\n\n7\n六月\n921\n\n\n\n\n8\n七月\n897\n\n\n\n\n9\n八月\n932\n\n\n\n\n10\n九月\n892\n\n\n\n\n11\n十月\n864\n\n\n\n\n12\n十一月\n821\n\n\n\n\n13\n十二月\n843\n\n\n\n\nD2 单元格使用以下数组公式：\n=INDEX(A2:A13,MATCH(1,0/(B2:B13&gt;AVERAGE(B2:B13))))\n\n\n数组公式要按 Shift+Ctrl+Enter 组合键\n\n计算过程：\n\n先使用 AVERAGE 函数计算出 B2:B13 单元格的平均值。\n再用 B2:B13 与平均值分别作比较，得到由逻辑值 TRUE 或是 FALSE 组成的内存数组。用 0 除以这个内存数组，返回以下结果：&#96;\n\n","categories":["其他分类","Excel"],"tags":["公式"]},{"title":"公众号添加数学公式","url":"/cb6aa8e0-4cf8-11ef-b554-2b6cf9b62df3/","content":"\n\n\n\n1、SVG 图片1）可以使用 Office PowerPoint 插入公式后，使用右键菜单的「另存为图片」-&gt;「保存类型」选择「可缩放的向量图形(*.svg)」\n\nWPS 截至目前无此功能。\n\n2）浏览器打开图片，获取源码后使用可编辑公众号源码的插件，Edge 中安装如「壹伴 · 小插件」，插入源码，调整行内样式。\n2、插入 LaTeX 公式1）使用在线 LaTeX 公式编辑器：https://products.aspose.app/tex/zh/equation-editor/svg，编辑完成后复制 \\begin&#123;equation*&#125; 和 \\end&#123;equation*&#125; 之间的内容。\n2）进入 mdnice 编辑器：https://editor.mdnice.com/?outId=4c8e49095bbc44f1b2136d96d680bdf4，将上个步骤复制内容按下列格式粘贴。\n行内公式：$\\ce&#123;Hg^2+ -&gt;[I-] HgI2 -&gt;[I-] [Hg^&#123;II&#125;I4]^2-&#125;$块公式：$$H(D_2) = -\\left(\\frac&#123;2&#125;&#123;4&#125;\\log_2 \\frac&#123;2&#125;&#123;4&#125; + \\frac&#123;2&#125;&#123;4&#125;\\log_2 \\frac&#123;2&#125;&#123;4&#125;\\right) = 1$$\n\n展示效果如下：\n\n\n2）在 mdnice 编辑器右侧菜单点击「复制到公众号」，前往公众号粘贴即可\n\n如果要使用行内效果，前后的文字也在编辑器中敲好。\n\n","categories":["其他分类","公众号"],"tags":["公众号"]},{"title":"AtomicInteger-用法","url":"/ef12ce01-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n\n前言AtomicInteger 源自 java.util.concurrent.atomic 包，另外有 AtomicBoolean、AtomicInteger、AtomicLong、AtomicLongArray、AtomicReference 等原子类，主要用于在高并发环境下，简化同步处理.\nAtomic 包介绍\nJava1.5 的 Atomic 包名为 java.util.concurrent.atomic。这个包提供了一系列原子类。这些类可以保证多线程环境下，当某个线程在执行 atomic 的方法时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由 JVM 从等待队列中选择一个线程执行。Atomic 类在软件层面上是非阻塞的，它的原子性其实是在硬件层面上借助相关的指令来保证的。\nAtomic 包中的类可以分成 4 组：\n\nAtomicBoolean，AtomicInteger，AtomicLong，AtomicReference\n\nAtomicIntegerArray，AtomicLongArray\n\nAtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater\n\nAtomicMarkableReference，AtomicStampedReference，AtomicReferenceArray\n\n\n我们来看一下最简单的 AtomicInteger 有哪些常见的方法以及这些方法的作用。\nget()             直接返回值getAndAdd(int)    增加指定的数据，返回变化前的数据getAndDecrement() 减少1，返回减少前的数据getAndIncrement() 增加1，返回增加前的数据getAndSet(int)    设置指定的数据，返回设置前的数据addAndGet(int)    增加指定的数据后返回增加后的数据decrementAndGet() 减少1，返回减少后的值incrementAndGet() 增加1，返回增加后的值lazySet(int)      仅仅当get时才会setcompareAndSet(int, int) 尝试新增后对比，若增加成功则返回true否则返回false\n\n在 Java 中，++i 和 i++ 操作并不是线程安全的，在使用的时候，不可避免的会用到 synchronized 关键字。而 AtomicInteger 则通过一种线程安全的加减操作接口。\nAtomicInteger 的基本方法创建一个 AtomicInteger\nSystem.out.println(atomicInteger.get());\n\n输出 ： 123\n创建一个不传值的，默认值为 0\nAtomicInteger atomicInteger = new AtomicInteger();System.out.println(atomicInteger.get());\n\n输出： 0\n获取和赋值atomicInteger.get(); //获取当前值atomicInteger.set(999); //设置当前值atomicInteger.compareAndSet(expectedValue,newValue)    public static void main(String[] args) &#123;        AtomicInteger atomicInteger = new AtomicInteger(0);        System.out.println(atomicInteger.get());        int expectedValue = 123;        int newValue      = 234;        Boolean b =atomicInteger.compareAndSet(expectedValue, newValue);        System.out.println(b);        System.out.println(atomicInteger);    &#125;\n\n输出结果为： 0 false 0\npublic static void main(String[] args) &#123;       AtomicInteger atomicInteger = new AtomicInteger(123);       System.out.println(atomicInteger.get());       int expectedValue = 123;       int newValue      = 234;       Boolean b =atomicInteger.compareAndSet(expectedValue, newValue);       System.out.println(b);       System.out.println(atomicInteger);   &#125;\n\n输出结果为： 123 true 234\n由上可知该方法表示，atomicInteger 的值与 expectedValue 相比较，如果不相等，则返回 false，atomicInteger 原有值保持不变；如果两者相等，则返回 true,atomicInteger 的值更新为 newValue\ngetAndAdd()方法与 AddAndGet 方法AtomicInteger atomicInteger = new AtomicInteger(123);System.out.println(atomicInteger.get());  --123System.out.println(atomicInteger.getAndAdd(10)); --123 获取当前值，并加10System.out.println(atomicInteger.get()); --133System.out.println(atomicInteger.addAndGet(10)); --143 获取加10后的值，先加10System.out.println(atomicInteger.get()); --143\n\ngetAndDecrement()和 DecrementAndGet()方法AtomicInteger atomicInteger = new AtomicInteger(123);System.out.println(atomicInteger.get());   --123System.out.println(atomicInteger.getAndDecrement()); --123 获取当前值并自减System.out.println(atomicInteger.get());  --122System.out.println(atomicInteger.decrementAndGet()); --121 先自减再获取减1后的值System.out.println(atomicInteger.get()); --121\n\n使用 AtomicInteger，即使不用同步块 synchronized，最后的结果也是 100，可用看出 AtomicInteger 的作用，用原子方式更新的 int 值。主要用于在高并发环境下的高效程序处理。使用非阻塞算法来实现并发控制。\npublic class Counter &#123;    public static AtomicInteger count = new AtomicInteger(0);    public static void inc()&#123;        try&#123;            Thread.sleep(1); //延迟1毫秒        &#125;catch (InterruptedException e)&#123; //catch住中断异常，防止程序中断            e.printStackTrace();        &#125;        count.getAndIncrement();//count值自加1    &#125;    public static void main(String[] args) throws InterruptedException &#123;        final CountDownLatch latch = new CountDownLatch(100);        for(int i=0;i&lt;100;i++)&#123;            new Thread(new Runnable() &#123;                @Override                public void run() &#123;                    Counter.inc();                    latch.countDown();                &#125;            &#125;).start();        &#125;        latch.await();        System.out.println(&quot;运行结果：&quot;+Counter.count);    &#125;&#125;\n\n运行结果： 100\n使用普通 Integerpublic class Counter &#123;    public volatile  static int count = 0;    public static void inc()&#123;        try&#123;            Thread.sleep(1); //延迟1毫秒        &#125;catch (InterruptedException e)&#123; //catch住中断异常，防止程序中断            e.printStackTrace();        &#125;        count++;//count值自加1    &#125;    public static void main(String[] args) throws InterruptedException &#123;        final CountDownLatch latch = new CountDownLatch(100);        for(int i=0;i&lt;100;i++)&#123;            new Thread(new Runnable() &#123;                @Override                public void run() &#123;                    Counter.inc();                    latch.countDown();                &#125;            &#125;).start();        &#125;        latch.await();        System.out.println(&quot;运行结果：&quot;+Counter.count);   &#125;&#125;\n\n运行结果：98\n如果在 inc 方法前面加个 synchronized 也能是线程安全的；\n它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。\nimport java.util.concurrent.CountDownLatch;/** * created by guanguan  on 2017/10/23 **/public class Counter &#123;     public volatile static  Integer count = 0;    public synchronized static void inc()&#123;        try&#123;            Thread.sleep(1); //延迟1毫秒        &#125;catch (InterruptedException e)&#123; //catch住中断异常，防止程序中断            e.printStackTrace();        &#125;          count++;//count值自加1    &#125;    public static void main(String[] args) throws InterruptedException &#123;        final CountDownLatch latch = new CountDownLatch(100);        for(int i=0;i&lt;100;i++)&#123;            new Thread(new Runnable() &#123;                @Override                public void run() &#123;                    Counter.inc();                    latch.countDown();                &#125;            &#125;).start();        &#125;        latch.await();        System.out.println(&quot;运行结果：&quot;+Counter.count);    &#125;&#125;\n\n运行结果：100\nsynchronized 的使用说明：\n一、当两个并发线程访问同一个对象 object 中的这个 synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。\n二、然而，当一个线程访问 object 的一个 synchronized(this)同步代码块时，另一个线程仍然可以访问该 object 中的非 synchronized(this)同步代码块。\n三、尤其关键的是，当一个线程访问 object 的一个 synchronized(this)同步代码块时，其他线程对 object 中所有其它 synchronized(this)同步代码块的访问将被阻塞。\n四、第三个例子同样适用其它同步代码块。也就是说，当一个线程访问 object 的一个 synchronized(this)同步代码块时，它就获得了这个 object 的对象锁。结果，其它线程对该 object 对象所有同步代码部分的访问都被暂时阻塞。\n五、以上规则对其它对象锁同样适用.\n6、从上面的例子中我们可以看出：使用 AtomicInteger 是非常的安全的.而且因为 AtomicInteger 由硬件提供原子操作指令实现的。在非激烈竞争的情况下，开销更小，速度更快。\njava 的关键域有 3 个\n// setup to use Unsafe.compareAndSwapInt for updatesprivate static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;private volatile int value;\n\n这里， unsafe 是 java 提供的获得对对象内存地址访问的类，注释已经清楚的写出了，它的作用就是在更新操作时提供“比较并替换”的作用。实际上就是 AtomicInteger 中的一个工具。\nvalueOffset 是用来记录 value 本身在内存的便宜地址的，这个记录，也主要是为了在更新操作在内存中找到 value 的位置，方便比较。\n注意：value 是用来存储整数的时间变量，这里被声明为 volatile，就是为了保证在更新操作时，当前线程可以拿到 value 最新的值（并发环境下，value 可能已经被其他线程更新了）。\n这里，我们以自增的代码为例，可以看到这个并发控制的核心算法：\n源码\npublic final int updateAndGet(IntUnaryOperator updateFunction) &#123;    int prev, next;    do &#123;        prev = get();        next = updateFunction.applyAsInt(prev);    &#125; while (!compareAndSet(prev, next));    return next;&#125;\n\nAtomicInteger 源码分析public final int incrementAndGet() &#123;    for (;;) &#123;        int current = get();        int next = current + 1;        if (compareAndSet(current, next))            return next;    &#125;&#125;\n\n方法中采用了 CAS 操作，每次从内存中读取数据然后将此数据和+1 后的结果进行 CAS 操作，如果成功就返回结果，否则重试直到成功为止。而 compareAndSet 利用 JNI 来完成 CPU 指令的操作。\npublic final boolean compareAndSet(int expect, int update) &#123;    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125;\n\n整体的过程就是这样子的，利用 CPU 的 CAS 指令，同时借助 JNI 来完成 Java 的非阻塞算法。\n什么是 CASCAS，Compare and Swap 即比较并交换。 java.util.concurrent 包借助 CAS 实现了区别于 synchronized 同步锁的一种乐观锁。乐观锁就是每次去取数据的时候都乐观的认为数据不会被修改，所以不会上锁，但是在更新的时候会判断一下在此期间数据有没有更新。CAS 有 3 个操作数：内存值 V，旧的预期值 A，要修改的新值 B。当且仅当预期值 A 和内存值 V 相同时，将内存值 V 修改为 B，否则什么都不做。CAS 的关键点在于，系统在硬件层面保证了比较并交换操作的原子性，处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。\nCAS 的优缺点CAS 由于是在硬件层面保证的原子性，不会锁住当前线程，它的效率是很高的。\nCAS 虽然很高效的实现了原子操作，但是它依然存在三个问题。\n1、ABA 问题。CAS 在操作值的时候检查值是否已经变化，没有变化的情况下才会进行更新。但是如果一个值原来是 A，变成 B，又变成 A，那么 CAS 进行检查时会认为这个值没有变化，但是实际上却变化了。ABA 问题的解决方法是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么 A－B－A 就变成 1A-2B－3A。从 Java1.5 开始 JDK 的 atomic 包里提供了一个类 AtomicStampedReference 来解决 ABA 问题。\n2、并发越高，失败的次数会越多，CAS 如果长时间不成功，会极大的增加 CPU 的开销。因此 CAS 不适合竞争十分频繁的场景。\n3、只能保证一个共享变量的原子操作。当对多个共享变量操作时，CAS 就无法保证操作的原子性，这时就可以用锁，或者把多个共享变量合并成一个共享变量来操作。比如有两个共享变量 i ＝ 2,j&#x3D;a，合并一下 ij&#x3D;2a，然后用 CAS 来操作 ij。从 Java1.5 开始 JDK 提供了 AtomicReference 类来保证引用对象的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作。\n","categories":["后端技术","java"],"tags":["java"]},{"title":"CompletableFuture-异步处理任务","url":"/58871fa1-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n\noracle JDK8 有关内容的文档：https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html\n\n创建异步任务runAsync 执行 CompletableFuture 任务，没有返回值\nstatic CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable, Executor executor)\n\nsupplyAsync 执行 CompletableFuture 任务，可有返回值\nstatic &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)\n\n\n如果不指定 Executor 实现，则使用 ForkJoinPool.commonPool() 作为执行异步代码的线程池\n\n创建异步任务后，可根据需求进行如下的操作：\n\n\n\n方法名称\n类型\n传参\n返回值\n\n\n\nthenRun\n单任务消费\n无传参\n无返回值\n\n\nthenRunAsync\n单任务消费\n无传参\n无返回值\n\n\nthenApply\n单任务消费\n要传参\n有返回值\n\n\nthenApplyAsync\n单任务消费\n要传参\n有返回值\n\n\nthenAccept\n单任务消费\n要传参\n无返回值\n\n\nthenAcceptAsync\n单任务消费\n要传参\n无返回值\n\n\nthenCombine\n双任务消费（与）\n要传参（两个任务的执行结果）\n有返回值\n\n\nthenCombineAsync\n双任务消费（与）\n要传参（两个任务的执行结果）\n有返回值\n\n\nthenAcceptBoth\n双任务消费（与）\n要传参（两个任务的执行结果）\n无返回值\n\n\nthenAcceptBothAsync\n双任务消费（与）\n要传参（两个任务的执行结果）\n无返回值\n\n\nrunAfterBoth\n双任务消费（与）\n无传参\n无返回值\n\n\nrunAfterBothAsync\n双任务消费（与）\n无传参\n无返回值\n\n\napplyToEither\n双任务消费（或）\n要传参（已完成任务的执行结果）\n有返回值\n\n\napplyToEitherAsync\n双任务消费（或）\n要传参（已完成任务的执行结果）\n有返回值\n\n\nacceptEither\n双任务消费（或）\n要传参（已完成任务的执行结果）\n无返回值\n\n\nacceptEitherAsync\n双任务消费（或）\n要传参（已完成任务的执行结果）\n无返回值\n\n\nrunAfterEither\n双任务消费（或）\n无传参\n无返回值\n\n\nrunAfterEitherAsync\n双任务消费（或）\n无传参\n无返回值\n\n\nwhenComplete\n单任务消费\n要传参（正常返回值和异常）\n无返回值\n\n\nwhenCompleteAsync\n单任务消费\n要传参（正常返回值和异常）\n无返回值\n\n\nhandle\n单任务消费\n要传参（正常返回值和异常）\n有返回值\n\n\nhandleAsync\n单任务消费\n要传参（正常返回值和异常）\n有返回值\n\n\nexceptionally\n单任务消费\n要传参 （异常）\n无返回值\n\n\nthenCompose\n单任务消费\n要传参\n有返回值\n\n\nallOf\n多任务消费（与）\n要传参（任务列表）\n无返回值\n\n\nanyOf\n多任务消费（或）\n要传参（任务列表）\n无返回值\n\n\n\n不带 Async 版本由上一个任务的线程继续执行该任务，Async 版本可以指定执行该异步任务的 Executor 实现，如果不指定，默认使用 ForkJoinPool.commonPool()\n\n单任务消费\n\n\n回调方法\n类型\n传参\n返回值\n\n\n\nthenRun\n单任务消费\n无传参\n无返回值\n\n\nthenRunAsync\n单任务消费\n无传参\n无返回值\n\n\nthenAccept\n单任务消费\n要传参\n无返回值\n\n\nthenAcceptAsync\n单任务消费\n要传参\n无返回值\n\n\nthenApply\n单任务消费\n要传参\n有返回值\n\n\nthenApplyAsync\n单任务消费\n要传参\n有返回值\n\n\npublic static void main(String[] args) throws Exception &#123;    var executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());    var supplyAsyncTask = CompletableFuture.supplyAsync(() -&gt; &#123;        System.out.println(&quot;supplyAsyncTask=&quot; + Thread.currentThread().getName());        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        return &quot;&quot;;    &#125;, executor);    // thenApply    var thenApplyTask = supplyAsyncTask.thenApply((param) -&gt; &#123;        System.out.println(&quot;thenApplyTask=&quot; + Thread.currentThread().getName());        return &quot;&quot;;    &#125;);    // thenApplyAsync不指定线程池    var thenApplyAsyncTask = supplyAsyncTask.thenApplyAsync((param) -&gt; &#123;        System.out.println(&quot;thenApplyAsyncTask=&quot; + Thread.currentThread().getName());        return &quot;&quot;;    &#125;);    // thenApplyAsync指定线程池    var thenApplyAsyncTask2 = supplyAsyncTask.thenApplyAsync((param) -&gt; &#123;        System.out.println(&quot;thenApplyAsyncTask2=&quot; + Thread.currentThread().getName());        return &quot;&quot;;    &#125;, executor);    // 不调用get()将不执行回调    thenApplyAsyncTask.get();    thenApplyAsyncTask2.get();    // 关闭线程池    executor.shutdown();&#125;\n\n输出结果：\nsupplyAsyncTask=pool-1-thread-1thenApplyAsyncTask2=pool-1-thread-2thenApplyTask=pool-1-thread-2thenApplyAsyncTask=ForkJoinPool.commonPool-worker-3\n\n双任务消费（与）将两个 CompletableFuture 组合起来，只有这两个都正常执行完了，才会执行某个任务。\n\n\n\n方法名称\n类型\n传参\n返回值\n\n\n\nthenCombine\n双任务消费（与）\n有传参（两个任务的执行结果）\n有返回值\n\n\nthenCombineAsync\n双任务消费（与）\n有传参（两个任务的执行结果）\n有返回值\n\n\nthenAcceptBoth\n双任务消费（与）\n有传参（两个任务的执行结果）\n无返回值\n\n\nthenAcceptBothAsync\n双任务消费（与）\n有传参（两个任务的执行结果）\n无返回值\n\n\nrunAfterBoth\n双任务消费（与）\n无传参\n无返回值\n\n\nrunAfterBothAsync\n双任务消费（与）\n无传参\n无返回值\n\n\npublic static void main(String[] args) throws Exception &#123;    var task1 = CompletableFuture.supplyAsync(() -&gt; &quot;task1&quot;);    var task2 = CompletableFuture.supplyAsync(() -&gt; &quot;task2&quot;);    var task3 = CompletableFuture.supplyAsync(() -&gt; &quot;task3&quot;);    task1.thenCombine(task2, (param1, param2) -&gt; &#123;        // task1task2        System.out.println(param1 + param2);        return param1 + param2;    &#125;).thenCombine(task3, (param12, param3) -&gt; &#123;        // task1task2task3        System.out.println(param12 + param3);        return param12 + param3;    &#125;);    task1.thenAcceptBoth(task2, (param1, param2) -&gt; &#123;        // task1task2        System.out.println(param1 + param2);    &#125;).thenAcceptBoth(task3, (param12, param3) -&gt; &#123;        // nulltask3        System.out.println(param12 + param3);    &#125;);    task1.runAfterBoth(task2, () -&gt; &#123;        // task1 and task2        System.out.println(&quot;task1 and task2&quot;);    &#125;);&#125;\n\n双任务消费（或）将两个 CompletableFuture 组合起来，只要其中一个执行完了，就执行回调方法。\n\n\n\n方法名称\n类型\n传参\n返回值\n\n\n\napplyToEither\n双任务消费（或）\n有传参（已完成任务的执行结果）\n有返回值\n\n\napplyToEitherAsync\n双任务消费（或）\n有传参（已完成任务的执行结果）\n有返回值\n\n\nacceptEither\n双任务消费（或）\n有传参（已完成任务的执行结果）\n无返回值\n\n\nacceptEitherAsync\n双任务消费（或）\n有传参（已完成任务的执行结果）\n无返回值\n\n\nrunAfterEither\n双任务消费（或）\n无传参\n无返回值\n\n\nrunAfterEitherAsync\n双任务消费（或）\n无传参\n无返回值\n\n\npublic static void main(String[] args) throws Exception &#123;    var task1 = CompletableFuture.supplyAsync(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(5);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        return &quot;task1&quot;;    &#125;);    var task2 = CompletableFuture.supplyAsync(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(3);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        return &quot;task2&quot;;    &#125;);    var task3 = CompletableFuture.supplyAsync(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(3);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        return &quot;task3&quot;;    &#125;);    task1.applyToEither(task2, (param) -&gt; &#123;        // applyToEither=task2        System.out.println(&quot;applyToEither=&quot; + param);        return param;    &#125;).acceptEither(task3, (param) -&gt; &#123;        // acceptEither=task2 或 acceptEither=task3        System.out.println(&quot;acceptEither=&quot; + param);    &#125;).get();    // task1 or task2    task1.runAfterEither(task2,()-&gt; System.out.println(&quot;task1 or task2&quot;));&#125;\n\n其他whenComplete、whenCompleteAsync某个任务执行完成后，执行的回调方法，无返回值。可以访问 CompletableFuture 的结果和异常作为参数，使用它们并执行想要的操作。此方法并不能转换完成的结果。会内部抛出异常。其正常返回的 CompletableFuture 的结果来自上个任务。\nhandle、handleAsync不论正常返回还是出异常都会进入 handle，参数通常为 new BiFunction&lt;T, Throwable, R&gt;();，其中\n\nT：上一任务传入的对象类型\nThrowable：上一任务传入的异常\nR：返回的对象类型\n\n\nhandle 和 thenApply 的区别：如果任务出现异常不会进入 thenApply；任务出现异常也会进入 handle，可对异常处理。\n\n\nhandle 和 whenComplete 的区别：handle 可对传入值 T 进行转换，并产生自己的返回结果 R；whenComplete 的返回值和上级任务传入的结果一致，不能转换。\n\n\nwhenComplete、whenCompleteAsync、handle 和 handleAsync 的输入参数一个是正常结果一个是异常结果，而 exceptionally 的输入参数为异常结果。\n\npublic static void main(String[] args) throws Exception &#123;    var supplyAsyncTask = CompletableFuture.supplyAsync(() -&gt; &#123;        // 制造一个异常        // int value = 1 / 0;        return &quot;supplyAsyncTask&quot;;    &#125;);    var handle = supplyAsyncTask.handle((s, throwable) -&gt; &#123;        if (Optional.ofNullable(throwable).isPresent()) &#123;            return throwable.getMessage();        &#125;        return new ArrayList() &#123;&#123;            add(s);        &#125;&#125;;    &#125;);    // supplyAsyncTask异常时，输出1：java.lang.ArithmeticException: / by zero    // 输出2：[supplyAsyncTask]    System.out.println(handle.get());&#125;\n\nexceptionally某个任务执行抛出异常时执行的回调方法。抛出异常作为参数，传递到回调方法。仅处理异常情况。如果任务成功完成，那么将被跳过。\npublic static void main(String[] args) throws Exception &#123;    var supplyAsyncTask = CompletableFuture.supplyAsync(() -&gt; &#123;        double error=1/0;        return &quot;ok&quot;;    &#125;, executor).exceptionally((e)-&gt;&#123;        // java.lang.ArithmeticException: / by zero        System.out.println(e.getMessage());        return &quot;error&quot;;    &#125;);    // &quot;error&quot;    System.out.println(supplyAsyncTask.get());&#125;\n\ncomplete如果尚未完成，则将 get() 和相关方法返回的值设置为给定值。如果此调用导致此 CompletableFuture 转换到完成状态，则返回 true，否则返回 false。文档描述：\nIf not already completed, sets the value returned by get() and related methods to the given value.Params:value – the result valueReturns:true if this invocation caused this CompletableFuture to transition to a completed state, else false\n\npublic static void main(String[] args) throws Exception &#123;    var task1 = CompletableFuture.supplyAsync(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(15);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        return 10;    &#125;);    // 若get放在此处，一直等待task1完成，输出10    // System.out.println(task1.get());    // 强制task1完成，输出true    System.out.println(task1.complete(5));    // 输出5    System.out.println(task1.get());    // task1已完成，输出false    System.out.println(task1.complete(50));&#125;\n\nthenCompose源码定义\npublic &lt;U&gt; CompletableFuture&lt;U&gt; thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn);public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn) ;public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn, Executor executor) ;\n\nthenCompose 方法会在某个任务执行完成后，将该任务的执行结果作为入参，执行指定的方法。该方法会返回一个新的 CompletableFuture 实例\npublic static void main(String[] args) throws Exception &#123;    var task1 = CompletableFuture.supplyAsync(() -&gt; 10);    var task2 = task1.thenCompose(param -&gt; &#123;        System.out.println(&quot;this is task2 param=&quot; + param);        return CompletableFuture.supplyAsync(() -&gt; &#123;            System.out.println(&quot;this is task2 square&quot;);            return Math.pow(param, 2);        &#125;);    &#125;).thenApply(param -&gt; &#123;        System.out.println(&quot;thenApply get the square=&quot; + param);        return param;    &#125;);    var task3 = task1.thenCompose(param -&gt; &#123;        System.out.println(&quot;this is task3 param=&quot; + param);        return CompletableFuture.runAsync(() -&gt; &#123;            System.out.println(&quot;this is task3 square&quot;);            System.out.println(Math.pow(param, 2));        &#125;);    &#125;);    System.out.println(&quot;task2 get=&quot; + task2.get());    System.out.println(&quot;task3 get=&quot; + task3.get());&#125;输出：this is task2 param=10this is task2 squarethenApply get the square=100.0this is task3 param=10this is task3 square100.0task2 get=100.0task3 get=null\n\nallOf静态方法，阻塞等待所有给定的 CompletableFuture 执行结束后，返回一个 CompletableFuture&lt;Void&gt; 结果。所有任务都执行完成后，才执行 allOf 的回调方法。如果任意一个任务异常，执行 get 方法时会抛出异常。\npublic static void main(String[] args) throws Exception &#123;    var task1 = CompletableFuture.supplyAsync(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(2);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        return &quot;task1&quot;;    &#125;);    var task2 = CompletableFuture.runAsync(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(1);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        int value = 1 / 0;        System.out.println(&quot;task2 is over&quot;);    &#125;);    CompletableFuture.allOf(task1, task2).whenComplete((param, throwable) -&gt; &#123;        // null        System.out.println(param);    &#125;).exceptionally(throwable -&gt; &#123;        // task3 allOf throwable=java.lang.ArithmeticException: / by zero        System.out.println(&quot;task3 allOf throwable=&quot; + throwable.getMessage());        return null;    &#125;).get();&#125;\n\nanyOf静态方法，阻塞等待任意一个给定的 CompletableFuture 对象执行结束后，返回一个 CompletableFuture&lt;Void&gt; 结果。任意一个任务执行完，就执行 anyOf 的回调方法。如果执行的任务异常，执行 get 方法时会抛出异常。\n","categories":["后端技术","java"],"tags":["java"]},{"title":"CompletionService-及时获取任务返回值","url":"/588746b0-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\nExecutorService定义如下的 TaskCallable 类，返回值的延迟输出时间根据传入值决定：\npublic record TaskCallable(String taskID, Double value, Double rate) implements Callable&lt;String&gt; &#123;    @Override    public String call() throws Exception &#123;        TimeUnit.MILLISECONDS.sleep(value.longValue());        return String.format(&quot;taskID=&#123; %s &#125; result=&#123; %s*%s -&gt; %s &#125;&quot;, taskID, value, rate, value * rate);    &#125;&#125;\n\n向线程池添加三个任务，执行时间有所区别，最后依次调用 get() 方法输出结果。\n查看完整示例代码\nExecutorService executorService = Executors.newFixedThreadPool(5);var futureList = Arrays.asList(        executorService.submit(new TaskCallable(&quot;1aa8c994-281e-4fbb-a09b-cdf389eedf3b&quot;, 1000.0, 0.5)),        executorService.submit(new TaskCallable(&quot;321996c2-73c0-411a-8e66-fcfa04d94ae1&quot;, 5000.0, 1.0)),        executorService.submit(new TaskCallable(&quot;3df9d22e-17d9-4b48-a821-867974681d6e&quot;, 600.0, 1.2)));for (int index = 0; index &lt; futureList.size(); index++) &#123;    var result = futureList.get(index).get();    System.out.println(result);&#125;executorService.shutdown();\n\n输出结果：\ntaskID=&#123; 1aa8c994-281e-4fbb-a09b-cdf389eedf3b &#125; result=&#123; 1000.0*0.5 -&gt; 500.0 &#125;taskID=&#123; 321996c2-73c0-411a-8e66-fcfa04d94ae1 &#125; result=&#123; 5000.0*1.0 -&gt; 5000.0 &#125;taskID=&#123; 3df9d22e-17d9-4b48-a821-867974681d6e &#125; result=&#123; 600.0*1.2 -&gt; 720.0 &#125;计时器&#123; b10bbd47-63c4-4545-b236-15303f40cc1f &#125;停止，耗时=&#123; 5004ms &#125;\n\n由于 get() 方法是阻塞的，因此如果某个 Future 执行时间太长，整个遍历过程将会阻塞，无法及时从已完成的 Future 拿到返回值。上述例子中，即使 600ms 的任务，也只能等到前两个长时间任务都完成后才能输出。\nCompletionServiceCompletionSerive 接口的实现类 ExecutorCompletionService 优化了获取异步操作结果。ExecutorCompletionService 中内置了存放 Future 的队列 completionQueue，在任务调用完成后，将要返回的 future 放入到该队列。客户端通过 take() 方法得到 future，再调用 get() 方法从而获取任务执行结果。\nprivate static class QueueingFuture&lt;V&gt; extends FutureTask&lt;Void&gt; &#123;    QueueingFuture(RunnableFuture&lt;V&gt; task,                    BlockingQueue&lt;Future&lt;V&gt;&gt; completionQueue) &#123;        super(task, null);        this.task = task;        this.completionQueue = completionQueue;    &#125;    private final Future&lt;V&gt; task;    private final BlockingQueue&lt;Future&lt;V&gt;&gt; completionQueue;    protected void done() &#123; completionQueue.add(task); &#125;&#125;\n\n向 CompletionService 提交任务的方式与 ExecutorService 一样。两者的区别在于取结果的方式。有了 CompletionService，可以不再需要 Future 集合。如果要得到最早的执行结果，调用 completionService.take().get() 即可：\n查看完整示例代码\nExecutorService executorService = Executors.newFixedThreadPool(5);CompletionService&lt;String&gt; completionService = new ExecutorCompletionService&lt;&gt;(executorService);completionService.submit(new TaskCallable(&quot;1aa8c994-281e-4fbb-a09b-cdf389eedf3b&quot;, 1000.0, 0.5));completionService.submit(new TaskCallable(&quot;321996c2-73c0-411a-8e66-fcfa04d94ae1&quot;, 5000.0, 1.0));completionService.submit(new TaskCallable(&quot;3df9d22e-17d9-4b48-a821-867974681d6e&quot;, 600.0, 1.2));for (int index = 0; index &lt; 3; index++) &#123;    System.out.println(completionService.take().get());&#125;executorService.shutdown();\n\n输出结果\ntaskID=&#123; 3df9d22e-17d9-4b48-a821-867974681d6e &#125; result=&#123; 600.0*1.2 -&gt; 720.0 &#125;taskID=&#123; 1aa8c994-281e-4fbb-a09b-cdf389eedf3b &#125; result=&#123; 1000.0*0.5 -&gt; 500.0 &#125;taskID=&#123; 321996c2-73c0-411a-8e66-fcfa04d94ae1 &#125; result=&#123; 5000.0*1.0 -&gt; 5000.0 &#125;计时器&#123; 7223efb6-ec07-4294-8f23-8b73b536c9b4 &#125;停止，耗时=&#123; 5002ms &#125;\n\nCompletionService 结合异步实现多线程处理任务定义一个任务队列，异步执行「入队」和「出队」，最终通过CompletionService获取全部任务的返回结果。\n查看完整示例代码\n// 定义队列LinkedBlockingDeque&lt;TaskCallable&gt; linkedBlockingDeque = new LinkedBlockingDeque&lt;&gt;();// 模拟任务数量final int taskCount = 5;// 获取CPU核心数int coreNum = Runtime.getRuntime().availableProcessors();// 定义线程池ThreadPoolExecutor customPool = new ThreadPoolExecutor(coreNum, coreNum, coreNum, TimeUnit.MINUTES, new LinkedBlockingDeque&lt;&gt;(),        new ThreadFactory() &#123;            private final AtomicInteger customPoolCurrent = new AtomicInteger(1);            @Override            public Thread newThread(Runnable runnable) &#123;                Thread thread = new Thread(runnable, String.format(&quot;customPool-thread-%s&quot;, customPoolCurrent.getAndIncrement()));                thread.setPriority(Thread.MAX_PRIORITY);                return thread;            &#125;        &#125;, new ThreadPoolExecutor.CallerRunsPolicy());CompletionService&lt;String&gt; completionService = new ExecutorCompletionService&lt;&gt;(customPool);var pushElement = CompletableFuture.runAsync(() -&gt; &#123;    for (int index = 0; index &lt; taskCount; index++) &#123;        var value = Math.random() * 1000;        var taskCallable = new TaskCallable(UUID.randomUUID().toString(), value, Math.random());        linkedBlockingDeque.push(taskCallable);        System.out.println(String.format(&quot;线程 %s 完成 %s 入队&quot;, Thread.currentThread().getName(), taskCallable));        try &#123;            TimeUnit.MILLISECONDS.sleep(300);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;);var submitTask = CompletableFuture.supplyAsync(() -&gt; &#123;    while (true) &#123;        try &#123;            boolean flagTask = pushElement.isDone();            boolean flagPeek = Optional.ofNullable(linkedBlockingDeque.peek()).isPresent();            // 当【入队任务完成】且【队列没有元素可取】时结束            if (flagTask == true &amp;&amp; flagPeek == false) &#123;                break;            &#125;            if (flagPeek == false) &#123;                // 仅【队列没有元素可取】时，跳过                continue;            &#125;            // 【队列有元素可取】时，添加任务到线程池            TimeUnit.MILLISECONDS.sleep(500);            var taskCallable = linkedBlockingDeque.take();            completionService.submit(taskCallable);            System.out.println(String.format(&quot;线程 %s 将 %s 提交到线程池&quot;, Thread.currentThread().getName(), taskCallable));        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;    return false;&#125;);boolean submit = submitTask.get();if (!submit) &#123;    for (int index = 0; index &lt; taskCount; index++) &#123;        System.out.println(completionService.take().get());    &#125;&#125;customPool.shutdown();customPool.awaitTermination(3, TimeUnit.SECONDS);\n\n输出结果：\n线程 ForkJoinPool.commonPool-worker-1 完成 TaskCallable[taskID=29ad9f36-2e25-457a-8a50-40b2619ccd85, value=297.9894322218015, rate=0.39525736986090654] 入队线程 ForkJoinPool.commonPool-worker-1 完成 TaskCallable[taskID=72434730-e52a-4819-a249-25b1e8450c81, value=861.735810794833, rate=0.0508273434713048] 入队线程 ForkJoinPool.commonPool-worker-2 将 TaskCallable[taskID=72434730-e52a-4819-a249-25b1e8450c81, value=861.735810794833, rate=0.0508273434713048] 提交到线程池线程 ForkJoinPool.commonPool-worker-1 完成 TaskCallable[taskID=6f25d9e6-9f38-4d84-ac59-259324f800f1, value=931.5744113116666, rate=0.8237427385465251] 入队线程 ForkJoinPool.commonPool-worker-1 完成 TaskCallable[taskID=6e3de271-2169-49c7-a425-9973304379a9, value=754.2015420496596, rate=0.480198992823775] 入队线程 ForkJoinPool.commonPool-worker-2 将 TaskCallable[taskID=6e3de271-2169-49c7-a425-9973304379a9, value=754.2015420496596, rate=0.480198992823775] 提交到线程池线程 ForkJoinPool.commonPool-worker-1 完成 TaskCallable[taskID=ffcb4a5e-603b-46dd-b4d0-02dc2bc7204c, value=259.60270090020333, rate=0.404730459043419] 入队线程 ForkJoinPool.commonPool-worker-2 将 TaskCallable[taskID=ffcb4a5e-603b-46dd-b4d0-02dc2bc7204c, value=259.60270090020333, rate=0.404730459043419] 提交到线程池线程 ForkJoinPool.commonPool-worker-2 将 TaskCallable[taskID=6f25d9e6-9f38-4d84-ac59-259324f800f1, value=931.5744113116666, rate=0.8237427385465251] 提交到线程池线程 ForkJoinPool.commonPool-worker-2 将 TaskCallable[taskID=29ad9f36-2e25-457a-8a50-40b2619ccd85, value=297.9894322218015, rate=0.39525736986090654] 提交到线程池taskID=&#123; 72434730-e52a-4819-a249-25b1e8450c81 &#125; result=&#123; 861.735810794833*0.0508273434713048 -&gt; 43.7997420367923 &#125;taskID=&#123; 6e3de271-2169-49c7-a425-9973304379a9 &#125; result=&#123; 754.2015420496596*0.480198992823775 -&gt; 362.1668208783845 &#125;taskID=&#123; ffcb4a5e-603b-46dd-b4d0-02dc2bc7204c &#125; result=&#123; 259.60270090020333*0.404730459043419 -&gt; 105.06912030425069 &#125;taskID=&#123; 29ad9f36-2e25-457a-8a50-40b2619ccd85 &#125; result=&#123; 297.9894322218015*0.39525736986090654 -&gt; 117.78251922633414 &#125;taskID=&#123; 6f25d9e6-9f38-4d84-ac59-259324f800f1 &#125; result=&#123; 931.5744113116666*0.8237427385465251 -&gt; 767.3776567337393 &#125;","categories":["后端技术","java"],"tags":["java"]},{"title":"Java8-Map-新增方法","url":"/ef12f511-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n\n在 Java 8 中的 Map.Entry 接口中增加了 comparingByKey, comparingByValue 方法，它们都返回 Comparator&lt;Map.Entry&lt;K,V&gt;&gt;, Comparator 是一个函数接口，主要是方便 Lambda 表达式的使用。\n在 Java 8 中的 Map 接口增加了一些 default 方法，提升了对 key，value 操作的便利性。下面是基本数据的定义，通过这些数据说明新增的一些方法。\nMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;();map.put(1, &quot;a&quot;);map.put(2, &quot;b&quot;);map.put(3, &quot;c&quot;);\n\ngetOrDefault 方法如果指定的 key 存在，则返回该 key 对应的 value，如果不存在，则返回指定的值。例子如下\n// key为4不存在，输出 dSystem.out.println(map.getOrDefault(4, &quot;d&quot;));\n\nforEach 方法遍历 Map 中的所有 Entry, 对 key, value 进行处理， 接收参数 (K, V) -&gt; void, 例子如下\n// 输出1a, 2b, 3cmap.forEach((key, value) -&gt; System.out.println(key + value));\n\nreplaceAll 方法替换 Map 中所有 Entry 的 value 值，这个值由旧的 key 和 value 计算得出，接收参数 (K, V) -&gt; V, 类似如下代码\nfor (Map.Entry&lt;K, V&gt; entry : map.entrySet())    entry.setValue(function.apply(entry.getKey(), entry.getValue()));\n\n例如如下：\nmap.replaceAll((key, value) -&gt; (key + 1) + value);// 输出 12a 23b 34cmap.forEach((key, value) -&gt; System.out.println(key + value));\n\nputIfAbsent 方法如果 key 关联的 value 不存在，则关联新的 value 值，返回 key 关联的旧的值，类似如下代码\nV v = map.get(key);if (v == null)    v = map.put(key, value);return v;\n\n示例代码如下：\nmap.putIfAbsent(3, &quot;d&quot;);map.putIfAbsent(4, &quot;d&quot;);// 输出 cSystem.out.println(map.get(3));// 输出 dSystem.out.println(map.get(4));\n\nremove 方法接收 2 个参数，key 和 value，如果 key 关联的 value 值与指定的 value 值相等（equals），则删除这个元素，类似代码如下：\nif (map.containsKey(key) &amp;&amp; Objects.equals(map.get(key), value)) &#123;    map.remove(key);    return true;&#125; else    return false;\n\n示例代码如下：\nmap.remove(1, &quot;b&quot;);// 未删除成功， 输出 aSystem.out.println(map.get(1));map.remove(2, &quot;b&quot;);// 删除成功，输出 nullSystem.out.println(map.get(2));\n\nreplace(K key, V oldValue, V newValue) 方法如果 key 关联的值与指定的 oldValue 的值相等，则替换成新的 newValue，类似代码如下：\nif (map.containsKey(key) &amp;&amp; Objects.equals(map.get(key), value)) &#123;    map.put(key, newValue);    return true;&#125; else    return false;\n\n示例代码如下\nmap.replace(3, &quot;a&quot;, &quot;z&quot;);// 未替换成功，输出 cSystem.out.println(map.get(3));map.replace(1, &quot;a&quot;, &quot;z&quot;);// 替换成功， 输出 zSystem.out.println(map.get(1));\n\nreplace(K key, V value) 方法如果 map 中存在 key，则替换成 value 值，否则返回 null, 类似代码如下:\nif (map.containsKey(key)) &#123;    return map.put(key, value);&#125; else    return null;\n\n示例代码如下：\n// 输出旧的值， aSystem.out.println(map.replace(1, &quot;aa&quot;));// 替换成功，输出新的值， aaSystem.out.println(map.get(1));// 不存在key为4， 输出 nullSystem.out.println(map.replace(4, &quot;d&quot;));// 不存在key为4， 输出 nullSystem.out.println(map.get(4));\n\ncomputeIfAbsent 方法如果指定的 key 不存在，则通过指定的 K -&gt; V 计算出新的值设置为 key 的值，类似代码如下：\nif (map.get(key) == null) &#123;    V newValue = mappingFunction.apply(key);    if (newValue != null)        map.put(key, newValue);&#125;\n\n示例代码如下：\nmap.computeIfAbsent(1, key -&gt; key + &quot; computed&quot;);// 存在key为1，则不进行计算，输出值 aSystem.out.println(map.get(1));map.computeIfAbsent(4, key -&gt; key + &quot; computed&quot;);// 不存在key为4，则进行计算，输出值 4 computedSystem.out.println(map.get(4));\n\ncomputeIfPresent 方法如果指定的 key 存在，则根据旧的 key 和 value 计算新的值 newValue, 如果 newValue 不为 null，则设置 key 新的值为 newValue, 如果 newValue 为 null, 则删除该 key 的值，类似代码如下：\nif (map.get(key) != null) &#123;    V oldValue = map.get(key);    V newValue = remappingFunction.apply(key, oldValue);    if (newValue != null)        map.put(key, newValue);    else        map.remove(key);&#125;\n\n示例代码如下：\nmap.computeIfPresent(1, (key, value) -&gt; (key + 1) + value);// 存在key为1， 则根据旧的key和value计算新的值，输出 2aSystem.out.println(map.get(1));map.computeIfPresent(2, (key, value) -&gt; null);// 存在key为2， 根据旧的key和value计算得到null，删除该值，输出 nullSystem.out.println(map.get(2));\n\ncompute 方法compute 方法是 computeIfAbsent 与 computeIfPresent 的综合体。\nmerge 方法构造\nmerge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction)\n\n如果指定的 key 不存在，则设置指定的 value 值，否则根据 key 的旧的值 oldvalue，value 计算出新的值 newValue, 如果 newValue 为 null, 则删除该 key，否则设置 key 的新值 newValue。类似如下代码：\nV oldValue = map.get(key);V newValue = (oldValue == null) ? value :        remappingFunction.apply(oldValue, value);if (newValue == null)    map.remove(key);else    map.put(key, newValue);\n\n示例代码如下：\n// 存在key为1， 输出 a mergeSystem.out.println(map.merge(1, &quot; merge&quot;, (oldValue, newValue) -&gt; oldValue + newValue));// 新值为null，删除key，输出 nullSystem.out.println(map.merge(1, &quot; merge&quot;, (oldValue, newValue) -&gt; null));// 输出 &quot; merge&quot;System.out.println(map.merge(4, &quot; merge&quot;, (oldValue, newValue) -&gt; oldValue + newValue));\n","categories":["后端技术","java"],"tags":["java"]},{"title":"Spring Boot 注解之 @ConditionalOnProperty","url":"/302ec220-debd-11ee-bdc4-19fdf0ccb3e7/","content":"\n\n\n\n1、使用情景1）根据配置属性有条件地创建 Bean\n2）可以用在类及方法上：标有 @Configuration 的类以及标有 @Bean 的方法\n3）当属性满足时才会使标有该注解的类或方法生效\n2、使用详情\n\n\n序号\n配置项\nhaving\n是否创建 Bean\n\n\n\n1\nconfig-test.property.action: true\nhavingValue&#x3D;”true”\n创建\n\n\n2\nconfig-test.property.action: false\nhavingValue&#x3D;”false”\n创建\n\n\n3\nconfig-test.property.action: enable\nhavingValue&#x3D;”enable”\n创建\n\n\n4\nconfig-test.property.action: no\nhavingValue&#x3D;”enable”\n不创建\n\n\n5\nconfig-test.property.action: true\n不配置\n创建\n\n\n6\nconfig-test.property.action: false\n不配置\n不创建\n\n\n7\nconfig-test.property.action: enable\n不配置\n创建\n\n\n8\nconfig-test.property.action: no\n不配置\n创建\n\n\n3、案例1）创建一个 Cake 类，getKind 方法返回当前蛋糕的口味：\npublic abstract class Cake &#123;    protected String kind;    public String getKind() &#123;        return kind;    &#125;&#125;\n\n2）创建两个子类 PineappleCake、StrawberryCake，表示不同口味的蛋糕：\npublic class PineappleCake extends Cake &#123;    public PineappleCake() &#123;        this.kind = &quot;PineappleCake&quot;;    &#125;&#125;public class StrawberryCake extends Cake &#123;    public StrawberryCake() &#123;        this.kind = &quot;StrawberryCake&quot;;    &#125;&#125;\n\n3）创建 Config 类，其中使用 @ConditionalOnProperty 注解根据配置文件指定的口味创建相应的 Bean\n@Configurationpublic class Config &#123;    @Bean(name = &quot;customCake&quot;)    @ConditionalOnProperty(prefix = &quot;cake.property&quot;, name = &quot;kind&quot;, havingValue = &quot;PineappleCake&quot;)-    public Cake pineappleCake() &#123;        return new PineappleCake();    &#125;    @Bean(name = &quot;customCake&quot;)    @ConditionalOnProperty(prefix = &quot;cake.property&quot;, name = &quot;kind&quot;, havingValue = &quot;StrawberryCake&quot;)    public Cake strawberryCake() &#123;        return new StrawberryCake();    &#125;&#125;\n\n4）单元测试用例\n@SpringBootTestclass TestSpringBootApplicationTests &#123;    private final ApplicationContextRunner contextRunner = new ApplicationContextRunner();    @Test    void contextLoads() &#123;        this.contextRunner.withPropertyValues(&quot;cake.property.kind=PineappleCake&quot;)                .withUserConfiguration(Config.class)                .run(context -&gt; &#123;                    assertThat(context).hasBean(&quot;customCake&quot;);                    Cake cake = context.getBean(PineappleCake.class);                    assertThat(cake.getKind()).isEqualTo(&quot;PineappleCake&quot;);                    assertThat(context).doesNotHaveBean(&quot;StrawberryCake&quot;);                &#125;);    &#125;&#125;\n\n5）使用案例\n配置文件 application.yml 添加如下属性：\ncake:  property:    kind: PineappleCake\n\n按名称注入，获得的 kind 值与配置文件相同\n@SpringBootTestclass TestSpringBootApplicationTests &#123;    @Resource    @Qualifier(&quot;customCake&quot;)    private Cake cake;    @Test    void contextLoads2() &#123;        assertThat(cake.getKind()).isEqualTo(&quot;PineappleCake&quot;);    &#125;&#125;\n","categories":["后端技术","java"],"tags":["springboot","java"]},{"title":"SpringBoot 整合 Aop","url":"/d2d3a3f0-ef58-11ee-9bca-69dcfb906dc3/","content":"\n\n\n\n1 前言1）环境\n\ngradle-8.5\nAmazon Corretto 17.0.4_9\nid &#39;org.springframework.boot&#39; version &#39;3.2.3&#39;\nid &#39;io.spring.dependency-management&#39; version &#39;1.1.4&#39;\n\n2）添加依赖\nimplementation &#x27;org.springframework.boot:spring-boot-starter-aop&#x27;\n\n2 理论概念\n切面（Aspect）：切入点和通知的集合\n连接点（Joinpoint）：目标对象中可以被增强的所有方法\n通知（Advice）：增强的代码（逻辑），分为前置，后置，最终，异常，环绕\n切入点（Pointcut）：目标对象中经过匹配最终增强的方法\n引入（Introduction）：动态的为某个类增加和减少方法\n目标对象（Target Object）：被代理的对象\nAOP 代理对象（AOP Proxy）：AOP 框架创建的代理对象，用于实现切面，调用方法\n织入（Weaving）：将通知应用到切入点的过程\n\n@Pointcut 注解是 Spring AOP（面向切面编程）中的一个关键组成部分，它允许开发人员定义可重用的切入点表达式，这些表达式可以被多个通知（Advice）引用。\n1）定义切入点表达式： 在包含 @Aspect 注解的类内部，使用 @Pointcut 注解定义一个方法，并在注解值中提供一个切入点表达式。这个表达式用于匹配满足特定条件的方法执行点。\n2）定义通知（Advice）： 在包含 @Aspect 注解的类内部，使用 @Before、@After、@AfterReturning、@AfterThrowing、@Around 注解定义一个通知（Advice），并在注解值中提供一个切入点表达式。通知（Advice）用于在方法执行前、后、返回值、异常抛出时执行特定的代码。\n3）通知类型：\n\n@Before(前置通知)： 在目标方法执行前执行的通知。\n@After(最终通知)： 不管目标方法是否正常执行完成（即无论是否有异常抛出），都会在目标方法执行后执行的通知。\n@AfterReturning (后置通知&#x2F;正常返回通知)： 在目标方法正常执行完毕并返回后执行的通知。可以访问到方法的返回值。\n@AfterThrowing(抛出异常通知)： 当目标方法抛出异常后执行的通知，可以访问到抛出的异常对象。\n@Around (环绕通知)： 最强大的通知类型，它可以完全控制目标方法的执行流程。可以在方法调用前后插入自定义行为，并决定何时以及是否执行目标方法。\n\n4）切入点表达式语法：\n@Pointcut(&quot;execution(modifiers-pattern? return-type-pattern declaring-type-pattern? method-name-pattern(param-pattern) throws-pattern?)&quot;)public void myPointcutDefinition() &#123;&#125;\n\nexecution 切点表达式使用较多，支持的通配符：\n\n*：匹配所有\n..：匹配多级包或者多个参数\n+表示类以及子类\n\n其他部分：\n\nexecution: 关键字，表示这是一个执行切点表达式。\nmodifiers-pattern: 可选，方法的修饰符，比如 public、protected、*（任意修饰符）等。\nreturn-type-pattern: 必须，方法的返回类型，可以是具体的类型，也可以是通配符 *（表示任意类型）或 ..（表示任意数量的任意类型参数）。\ndeclaring-type-pattern: 可选，方法所在的类或接口的全限定名，可以使用 * 或 .. 通配符。\nmethod-name-pattern: 必须，方法名称，可以是具体的名称，也可以使用通配符 * 匹配任意名称。\nparam-pattern: 必须，方法的参数列表，格式为 (paramType1, paramType2, …)，每个参数类型可以是具体类型、* 或 ..。\nthrows-pattern: 可选，方法声明抛出的异常类型列表，格式为 throws ExceptionType1, ExceptionType2, …。\n\n例子：\n// 匹配 com.example包及其子包下所有类的公共方法@Pointcut(&quot;execution(public * com.example..*(..))&quot;)public void anyPublicMethodInComExample() &#123;&#125;// 匹配 com.example.service包下的 UserService 类的所有方法@Pointcut(&quot;execution(* com.example.service.UserService.*(..))&quot;)public void userServiceMethods() &#123;&#125;// 匹配返回类型为void且方法名为process的任意方法@Pointcut(&quot;execution(void process(..))&quot;)public void voidProcessMethods() &#123;&#125;\n\n其他切点表达式：\n\nwithin - 匹配方法所在的包或者类\n\nthis - 用于向通知方法中传入代理对象的引用\n\ntarget - 用于向通知方法中传入目标对象的引用\n\nargs - 用于向通知方法中传入参数，并且匹配参数个数\n\n@args - 和 args 都是匹配参数，但是@args 要求传入切入点的参数必须标注指定注解，且不能是 SOURCE 源码注解，比如 Lombok 的\n\n@within - 匹配加了某个注解的类中的所有方法\n\n@target - 与@within 类似，但是要求标注到类上的注解，必须为 RUNTIME 的\n\n@annotation - 匹配加了某个注解的方法\n\nbean 通过 spring 容器中的 beName 匹配，可以使用通配符*来标识以什么开头，以什么结尾\n\n\n5）通知（Advice）执行顺序：\n\n@Before：先执行 @Before 通知，再执行切入点表达式匹配的方法。\n@AfterReturning：先执行切入点表达式匹配的方法，再执行 @AfterReturning 通知。\n@AfterThrowing：先执行切入点表达式匹配的方法，再执行 @AfterThrowing 通知。\n@After：先执行切入点表达式匹配的方法，再执行 @After 通知。\n@Around：先执行 @Around 通知，再执行切入点表达式匹配的方法，最后执行 @After 通知。\n\n3 案例3.1 日志记录功能实现一个日志记录功能，要求记录用户的所有请求信息，包括请求方法、请求路径、请求参数、请求体、请求头、响应状态码、响应体等。\n1）创建日志记录切面类\n@Aspect@Componentpublic class LogAspect &#123;    private static final Logger LOGGER = LoggerFactory.getLogger(LogAspect.class);    @Pointcut(&quot;execution(public * com.example.controller.*.*(..))&quot;)    public void logPointcut() &#123;    &#125;    @Before(&quot;logPointcut()&quot;)    public void doBefore(JoinPoint joinPoint) &#123;        LOGGER.info(&quot;Request: &#123;&#125; &#123;&#125;&quot;, joinPoint.getSignature().getName(), joinPoint.getArgs());    &#125;    @AfterReturning(pointcut = &quot;logPointcut()&quot;, returning = &quot;result&quot;)    public void doAfterReturning(Object result) &#123;        LOGGER.info(&quot;Response: &#123;&#125;&quot;, result);    &#125;    @AfterThrowing(pointcut = &quot;logPointcut()&quot;, throwing = &quot;e&quot;)    public void doAfterThrowing(Throwable e) &#123;        LOGGER.error(&quot;Exception: &#123;&#125;&quot;, e);    &#125;&#125;\n\n2）配置日志记录切面类\n@Configuration@EnableAspectJAutoProxypublic class LogConfig &#123;&#125;\n\n3）测试\n@RestController@RequestMapping(&quot;/api&quot;)public class TestController &#123;    @GetMapping(&quot;/test&quot;)    public String test() &#123;        return &quot;test&quot;;    &#125;&#125;\n\n3.2 运行时间统计@Aspect@Componentpublic class RunTimeAop &#123;    // 定义切入点，匹配所有Service层的方法    @Pointcut(&quot;execution(* server.services..*(..))&quot;)    public void businessServiceMethods() &#123;    &#125;    // 在方法执行前记录开始计时    @Around(&quot;businessServiceMethods()&quot;)    public Object logTime(ProceedingJoinPoint pjp) throws Throwable &#123;        // 获取方法签名和参数        MethodSignature signature = (MethodSignature) pjp.getSignature();        Method method = signature.getMethod();        Object[] args = pjp.getArgs();        StopWatch stopWatch = new StopWatch();        stopWatch.start();        // 执行目标方法        Object result = pjp.proceed();        stopWatch.stop();        Spliterator&lt;Object&gt; spliterator = Arrays.spliterator(args);        Stream&lt;Object&gt; stream = StreamSupport.stream(spliterator, false);        if (args.length &gt; 0 &amp;&amp; !Objects.isNull(result)) &#123;            // 合并参数            String combinedJsonString = stream.flatMap(element -&gt; &#123;                        if (element instanceof Map) &#123;                            Map&lt;String, String&gt; map = (Map&lt;String, String&gt;) element;                            return map.entrySet().stream()                                    .map(entry -&gt; &quot;\\&quot;&quot; + entry.getKey() + &quot;\\&quot;: \\&quot;&quot; + entry.getValue() + &quot;\\&quot;&quot;);                        &#125; else if (element instanceof String) &#123;                            return Stream.of(&quot;\\&quot;&quot; + element + &quot;\\&quot;&quot;);                        &#125; else &#123;                            return Stream.empty();                        &#125;                    &#125;)                    .collect(Collectors.joining(&quot;,&quot;, &quot;[&quot;, &quot;]&quot;));            System.out.printf(&quot;%s实际执行时间= %sms 随机时间= %sms 参数列表：%s%n&quot;, method.getName(), stopWatch.getTotalTimeMillis(), result, combinedJsonString);        &#125; else &#123;            System.out.printf(&quot;%s实际执行时间= %sms%n&quot;, method.getName(), stopWatch.getTotalTimeMillis());        &#125;        return result;    &#125;&#125;\n\n@Servicepublic class AopServiceIntMapParams &#123;    private static final ObjectMapper objectMapper = new ObjectMapper();    public int readFakeData(Map&lt;String, String&gt; params,String type) throws InterruptedException, JsonProcessingException &#123;        Random random = new Random();        int timeout = random.nextInt(701) + 50;        TimeUnit.MILLISECONDS.sleep(timeout);        String jsonString = objectMapper.writeValueAsString(params);        System.out.println(jsonString);        return timeout;    &#125;&#125;\n\n@Servicepublic class AopServiceVoidNoParams &#123;    private static final ObjectMapper objectMapper = new ObjectMapper();    public void readFakeData2() throws InterruptedException, JsonProcessingException &#123;        Random random = new Random();        int timeout = random.nextInt(701) + 50;        TimeUnit.MILLISECONDS.sleep(timeout);    &#125;&#125;\n","categories":["后端技术","java"],"tags":["springboot","java"]},{"title":"ThreadPoolExecutor-线程池","url":"/ef12f512-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n\n                                        阻塞队列为空                shutdown()           线程池工作线程数为0            +--------------&gt; SHUTDOWN ----------------+            |                                         |              terminated()RUNNING ----+                                         +----&gt; TIDYING ------------&gt; TERMINATED            | shutdownNow()          线程池工作线程数为0 |            +--------------&gt;   STOP   ----------------+\n\n构造方法\npublic ThreadPoolExecutor(int corePoolSize,                            int maximumPoolSize,                            long keepAliveTime,                            TimeUnit unit,                            BlockingQueue&lt;Runnable&gt; workQueue,                            ThreadFactory threadFactory,                            RejectedExecutionHandler handler) &#123;    if (corePoolSize &lt; 0 ||        maximumPoolSize &lt;= 0 ||        maximumPoolSize &lt; corePoolSize ||        keepAliveTime &lt; 0)        throw new IllegalArgumentException();    if (workQueue == null || threadFactory == null || handler == null)        throw new NullPointerException();    this.corePoolSize = corePoolSize;    this.maximumPoolSize = maximumPoolSize;    this.workQueue = workQueue;    this.keepAliveTime = unit.toNanos(keepAliveTime);    this.threadFactory = threadFactory;    this.handler = handler;&#125;\n\n参数解析\n\ncorePoolSize：核心线程池的大小。创建了线程池后，默认情况下线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务。当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到 corePoolSize 后，就会把到达的任务放到缓存队列当中；\nmaximumPoolSize：线程池最大线程数；\nkeepAliveTime：表示线程没有任务执行时最多保持多久时间会终止；\nunit：参数 keepAliveTime 的时间单位（DAYS、HOURS、MINUTES、SECONDS 等）\nworkQueue：阻塞队列，用来存储等待执行的任务\nArrayBlockingQueue，有界队列\nLinkedBlockingQueue，无界队列\nSynchronousQueue\n\n\nthreadFactory：线程工厂，主要用来创建线程\nhandler：拒绝处理任务的策略\nAbortPolicy：丢弃任务并抛出 RejectedExecutionException 异常，默认策略\nDiscardPolicy：丢弃任务，但不抛出异常\nDiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务，重复此过程\nCallerRunsPolicy：由调用线程处理该任务\n\n\n\n预定义线程池FixedThreadPool\npublic static ExecutorService newFixedThreadPool(int nThreads) &#123;    return new ThreadPoolExecutor(nThreads, nThreads,                                    0L, TimeUnit.MILLISECONDS,                                    new LinkedBlockingQueue&lt;Runnable&gt;());&#125;\n\n\ncorePoolSize 与 maximumPoolSize 相等，即其线程全为核心线程，是一个固定大小的线程池，是其优势；\nkeepAliveTime &#x3D; 0 该参数默认对核心线程无效，而 FixedThreadPool 全部为核心线程；\nworkQueue 为 LinkedBlockingQueue（无界阻塞队列），队列最大值为 Integer.MAX_VALUE。如果任务提交速度持续大余任务处理速度，会造成队列大量阻塞。因为队列很大，很有可能在拒绝策略前，内存溢出。是其劣势；\nFixedThreadPool 的任务执行是无序的；\n\n适用场景：可用于 Web 服务瞬时削峰，但需注意长时间持续高峰情况造成的队列阻塞。\nCachedThreadPool\npublic static ExecutorService newCachedThreadPool() &#123;    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                    60L, TimeUnit.SECONDS,                                    new SynchronousQueue&lt;Runnable&gt;());&#125;\n\n\ncorePoolSize &#x3D; 0，maximumPoolSize &#x3D; Integer.MAX_VALUE，即线程数量几乎无限制；\nkeepAliveTime &#x3D; 60s，线程空闲 60s 后自动结束。\nworkQueue 为 SynchronousQueue 同步队列，这个队列类似于一个接力棒，入队出队必须同时传递，因为 CachedThreadPool 线程创建无限制，不会有队列等待，所以使用 SynchronousQueue；\n\n适用场景：快速处理大量耗时较短的任务，如 Netty 的 NIO 接受请求时，可使用 CachedThreadPool。\nSingleThreadExecutor\npublic static ExecutorService newSingleThreadExecutor() &#123;    return new FinalizableDelegatedExecutorService        (new ThreadPoolExecutor(1, 1,                                0L, TimeUnit.MILLISECONDS,                                new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;\n\n这里多了一层 FinalizableDelegatedExecutorService 包装，这一层有什么用呢，写个 dome 来解释一下：\n    public static void main(String[] args) &#123;        ExecutorService fixedExecutorService = Executors.newFixedThreadPool(1);        ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) fixedExecutorService;        System.out.println(threadPoolExecutor.getMaximumPoolSize());        threadPoolExecutor.setCorePoolSize(8);        ExecutorService singleExecutorService = Executors.newSingleThreadExecutor();//      运行时异常 java.lang.ClassCastException//      ThreadPoolExecutor threadPoolExecutor2 = (ThreadPoolExecutor) singleExecutorService;    &#125;\n\n对比可以看出，FixedThreadPool 可以向下转型为 ThreadPoolExecutor，并对其线程池进行配置，而 SingleThreadExecutor 被包装后，无法成功向下转型。因此，SingleThreadExecutor 被定以后，无法修改，做到了真正的 Single。\nScheduledThreadPool\npublic static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123;    return new ScheduledThreadPoolExecutor(corePoolSize);&#125;\n\n\nnewScheduledThreadPool 调用的是 ScheduledThreadPoolExecutor 的构造方法，而 ScheduledThreadPoolExecutor 继承了 ThreadPoolExecutor，构造是还是调用了其父类的构造方法。\n\npublic ScheduledThreadPoolExecutor(int corePoolSize) &#123;    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,            new DelayedWorkQueue());&#125;\n\n对于 ScheduledThreadPool 本文不做描述，其特性请关注后续篇章。\n自定义线程池以下是自定义线程池，使用了有界队列，自定义 ThreadFactory 和拒绝策略的 demo\npublic class ThreadTest &#123;    public static void main(String[] args) throws InterruptedException, IOException &#123;        int corePoolSize = 2;        int maximumPoolSize = 4;        long keepAliveTime = 10;        TimeUnit unit = TimeUnit.SECONDS;        BlockingQueue&lt;Runnable&gt; workQueue = new ArrayBlockingQueue&lt;&gt;(2);        ThreadFactory threadFactory = new NameTreadFactory();        RejectedExecutionHandler handler = new MyIgnorePolicy();        ThreadPoolExecutor executor = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit,                workQueue, threadFactory, handler);        executor.prestartAllCoreThreads(); // 预启动所有核心线程        for (int i = 1; i &lt;= 10; i++) &#123;            MyTask task = new MyTask(String.valueOf(i));            executor.execute(task);        &#125;        System.in.read(); //阻塞主线程    &#125;    static class NameTreadFactory implements ThreadFactory &#123;        private final AtomicInteger mThreadNum = new AtomicInteger(1);        @Override        public Thread newThread(Runnable r) &#123;            Thread t = new Thread(r, &quot;my-thread-&quot; + mThreadNum.getAndIncrement());            System.out.println(t.getName() + &quot; has been created&quot;);            return t;        &#125;    &#125;    public static class MyIgnorePolicy implements RejectedExecutionHandler &#123;        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;            doLog(r, e);        &#125;        private void doLog(Runnable r, ThreadPoolExecutor e) &#123;            // 可做日志记录等            System.err.println( r.toString() + &quot; rejected&quot;);//          System.out.println(&quot;completedTaskCount: &quot; + e.getCompletedTaskCount());        &#125;    &#125;    static class MyTask implements Runnable &#123;        private String name;        public MyTask(String name) &#123;            this.name = name;        &#125;        @Override        public void run() &#123;            try &#123;                System.out.println(this.toString() + &quot; is running!&quot;);                Thread.sleep(3000); //让任务执行慢点            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        public String getName() &#123;            return name;        &#125;        @Override        public String toString() &#123;            return &quot;MyTask [name=&quot; + name + &quot;]&quot;;        &#125;    &#125;&#125;\n\n输出结果如下：\nmy-thread-1 has been createdmy-thread-2 has been createdmy-thread-3 has been createdMyTask[name=1]is running!MyTask[name=2]is running!my-thread-4 has been createdMyTask[name=3]is running!MyTask[name=6]is running!MyTask[name=7]is rejectedMyTask[name=8]is rejectedMyTask[name=9]is rejectedMyTask[name=10]is rejectedMyTask[name=4]is running!MyTask[name=5]is running!\n\n1，由于线程预启动，首先创建了 1，2 号线程，然后 task1，task2 被执行；2，但任务提交没有结束，此时任务 task3，task6 到达发现核心线程已经满了，进入等待队列；3，等待队列满后创建任务线程 3，4 执行任务 task3，task6，同时 task4，task5 进入队列；4，此时创建线程数（4）等于最大线程数，且队列已满，所以 7，8，9，10 任务被拒绝；5，任务执行完毕后回头来执行 task4，task5，队列清空。\n","categories":["后端技术","java"],"tags":["java"]},{"title":"jackson 2.x 解析 json 案例","url":"/e37eb230-cd6b-11ee-b21c-118c995770df/","content":"\n\n\n\n1、官方参考\nJackson Home Page:https://github.com/FasterXML/jackson\nJackson Wiki:http://wiki.fasterxml.com/JacksonHome\nJackson doc: https://github.com/FasterXML/jackson-docs\nJackson Download Page:http://wiki.fasterxml.com/JacksonDownload\n\n2、简介Jackson 有两个主要分支，1.x 处于维护状态，只会发布 bug 修复版本。2.x 还在积极地开发当中。这两个版本的 Java 包名和 Maven artifact 不一样，所以它们不互相兼容，但是可以和平共存，项目可以同时依赖 1.x 和 2.x 而不会发生冲突。\nJackson 1.x（目前版本从 1.1~1.9）与 2.x 版本的依赖从包名可以看出来。1.x 的类库中，包命名以：org.codehaus.jackson.xxx 开头，而 2.x 类库中包命令：com.fastxml.jackson.xxx 开头。\n3、主要模块1）核心模块\n核心模块是扩展模块构建的基础，到 2.7 版本为止，共有 3 个核心模块（依赖关系从上到下）:\n\nStreaming : jackson-core jar，定义了底层的 streaming API 和实现了 Json 特性。\nAnnotations : jackson-annotations jar，包含了标准的 Jackson 注解。\nDatabind : jackson-databind jar，实现了数据绑定和对象序列化，它依赖于 streaming 和 annotations 的包。\n\n2）第三方数据类型模块\n这些扩展是插件式的 Jackson 模块，用 ObjectMapper.registerModule() 注册，并且通过添加 serializers 和 deserializers 以便 Databind 包（ObjectMapper &#x2F; ObjectReader &#x2F; ObjectWriter）可以读写这些类型，来增加对各种常用的 Java 库的数据类型的支持。参考：https://github.com/FasterXML/jacksonThird-party datatype modules。\n3）数据格式模块\nJackson 也有处理程序对 JAX-RS 标准实现者例如 Jersey, RESTeasy, CXF 等提供了数据格式支持。处理程序实现了 MessageBodyReader 和 MessageBodyWriter，目前支持的数据格式包括 JSON, Smile, XML, YAML 和 CBOR。\n数据格式提供了除了 Json 之外的数据格式支持，它们绝大部分仅仅实现了 streaming API abstractions，以便数据绑定组件可以按照原来的方式使用。另一些（几乎不需要）提供了 databind 标准功能来处理例如 schemas。参考https://github.com/FasterXML/jacksonData format modules\n4）jackon 的三个核心类库\nmaven 依赖:\n&lt;dependency&gt;  &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;  &lt;artifactId&gt;jackson-core&lt;/artifactId&gt;  &lt;version&gt;2.7.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;  &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;  &lt;version&gt;2.7.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;  &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;  &lt;version&gt;2.7.4&lt;/version&gt;&lt;/dependency&gt;\n\n4、处理 JsonJackson 提供了三种可选的 Json 处理方法：流式 API（Streaming API）、树模型（Tree Model）、数据绑定（Data Binding）。三种处理 Json 的方式的特性：\n\nStreaming API：是效率最高的处理方式（开销低、读写速度快，但程序编写复杂度高）\nTree Model：是最灵活的处理方式\nData Binding：是最常用的处理方式\n\n1）Data Binding\n\n主要使用 ObjectMapper 来操作 Json，默认情况下会使用 BeanSerializer 来序列化 POJO。\n如果是解析，那么如下的例子里的 TestJson 必须要有 setters，且 setters 必须是 public 修饰的，否则属性的值将会为 null。\n如果是生成，那么必须有 getters，且 getters 必须是 public 修饰的。\n如果属性不是 private 修饰，那么可以不用有 getters 和 setters。\n\n要点：\nObjectMapper mapper = new ObjectMapper();mapper.writeValue(jsonFile, Bean);mapper.readValue(jsonFile, Bean.class 或 Collection&lt;Bean&gt;);\n\n1）生成 json\ncity.java 文件：\npackage com.myjackson.databinding;public class City &#123;    private Integer id;    private String cityName;    public City()&#123;&#125;    public Integer getId() &#123;        return id;    &#125;    public void setId(Integer id) &#123;        this.id = id;    &#125;    public String getCityName() &#123;        return cityName;    &#125;    public void setCityName(String cityName) &#123;        this.cityName = cityName;    &#125;&#125;\n\nprovince.java 文件：\npackage com.myjackson.databinding;import java.util.Date;import java.util.List;public class Province &#123;    private Integer id;    private String name;    private Date birthDate;    private List&lt;City&gt; cities;    public Province()&#123;&#125;    public Integer getId() &#123;        return id;    &#125;    public void setId(Integer id) &#123;        this.id = id;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public List&lt;City&gt; getCities() &#123;        return cities;    &#125;    public void setCities(List&lt;City&gt; cities) &#123;        this.cities = cities;    &#125;    public Date getBirthDate() &#123;        return birthDate;    &#125;    public void setBirthDate(Date birthDate) &#123;        this.birthDate = birthDate;    &#125;&#125;\n\ncountry.java 文件：\npackage com.myjackson.databinding;import java.util.Date;import java.util.HashMap;import java.util.List;import java.util.Map;public class Country &#123;    private Integer id;    private String countryName;    private Date establishTime;    private List&lt;Province&gt; provinces;    private String[] lakes;    private Map&lt;String, String&gt; forest = new HashMap&lt;String, String&gt;();    public Country()&#123;    &#125;    public Integer getId() &#123;        return id;    &#125;    public void setId(Integer id) &#123;        this.id = id;    &#125;    public String getCountryName() &#123;        return countryName;    &#125;    public void setCountryName(String countryName) &#123;        this.countryName = countryName;    &#125;    public Date getEstablishTime() &#123;        return establishTime;    &#125;    public void setEstablishTime(Date establishTime) &#123;        this.establishTime = establishTime;    &#125;    public List&lt;Province&gt; getProvinces() &#123;        return provinces;    &#125;    public void setProvinces(List&lt;Province&gt; provinces) &#123;        this.provinces = provinces;    &#125;    public String[] getLakes() &#123;        return lakes;    &#125;    public void setLakes(String[] lakes) &#123;        this.lakes = lakes;    &#125;    public Map&lt;String, String&gt; getForest() &#123;        return forest;    &#125;    public void setForest(Map&lt;String, String&gt; forest) &#123;        this.forest = forest;    &#125;&#125;\n\n测试案例\n@Testpublic void Bean2JsonStr() throws ParseException, JsonGenerationException, JsonMappingException, IOException&#123;    // 使用 ObjectMapper 转化对象为 Json    ObjectMapper mapper = new ObjectMapper();    SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);    mapper.setDateFormat(dateFormat); //设置日期序列化格式    City city1 = new City();    city1.setId(1);    city1.setCityName(&quot;gz&quot;);    City city2 = new City();    city2.setId(2);    city2.setCityName(&quot;dg&quot;);    Province province = new Province();    province.setId(1);    province.setName(&quot;GD&quot;);    province.setBirthDate(new Date());    List&lt;City&gt; cities = new ArrayList&lt;City&gt;();    cities.add(city1);    cities.add(city2);    province.setCities(cities);    Country country = new Country();    country.setCountryName(&quot;China&quot;);    country.setId(1);    country.setEstablishTime(dateFormat.parse(&quot;1949-10-01&quot;));    country.setLakes(new String[] &#123; &quot;Qinghai Lake&quot;, &quot;Poyang Lake&quot;,&quot;Dongting Lake&quot;, &quot;Taihu Lake&quot; &#125;);    HashMap&lt;String, String&gt; forest = new HashMap&lt;String, String&gt;();    forest.put(&quot;no.1&quot;, &quot;dxal&quot;);    forest.put(&quot;no.2&quot;, &quot;xxal&quot;);    country.setForest(forest);    List&lt;Province&gt; provinces = new ArrayList&lt;Province&gt;();    provinces.add(province);    country.setProvinces(provinces);    mapper.configure(SerializationFeature.INDENT_OUTPUT, true);     // 为了使JSON视觉上的可读性，在生产中不需如此，会增大Json的内容    mapper.setSerializationInclusion(Include.NON_EMPTY);  // 配置mapper忽略空属性    mapper.writeValue(new File(&quot;country.json&quot;), country);  // 默认情况，Jackson使用Java属性字段名称作为 Json的属性名称,也可以使用Jackson annotations(注解)改变Json属性名称&#125;\n\n运行得到 country.json：\n&#123;  &quot;id&quot;: 1,  &quot;countryName&quot;: &quot;China&quot;,  &quot;establishTime&quot;: &quot;1949-10-01&quot;,  &quot;provinces&quot;: [    &#123;      &quot;id&quot;: 1,      &quot;name&quot;: &quot;GD&quot;,      &quot;birthDate&quot;: &quot;2017-02-04&quot;,      &quot;cities&quot;: [        &#123;          &quot;id&quot;: 1,          &quot;cityName&quot;: &quot;gz&quot;        &#125;,        &#123;          &quot;id&quot;: 2,          &quot;cityName&quot;: &quot;dg&quot;        &#125;      ]    &#125;  ],  &quot;lakes&quot;: [&quot;Qinghai Lake&quot;, &quot;Poyang Lake&quot;, &quot;Dongting Lake&quot;, &quot;Taihu Lake&quot;],  &quot;forest&quot;: &#123;    &quot;no.1&quot;: &quot;dxal&quot;,    &quot;no.2&quot;: &quot;xxal&quot;  &#125;&#125;\n\n2）解析 json\n@Testpublic void JsonStr2Bean() throws JsonParseException, JsonMappingException, IOException&#123;    ObjectMapper mapper = new ObjectMapper();    File jsonFile = new File(&quot;country.json&quot;);    //当反序列化 json 时，未知属性会引起的反序列化被打断，这里我们禁用未知属性打断反序列化功能，    //因为，例如 json 里有 10 个属性，而我们的 bean 中只定义了 2 个属性，其它 8 个属性将被忽略    mapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES);    Country country = mapper.readValue(jsonFile, Country.class);    System.out.println(country.getCountryName()+country.getEstablishTime());    List&lt;Province&gt; provinces = country.getProvinces();    for (Province province : provinces) &#123;        System.out.println(&quot;province:&quot;+province.getName() + &quot;\\n&quot; + &quot;birthDate:&quot;+province.getBirthDate());        for (City city: province.getCities()) &#123;            System.out.println(city.getId()+&quot; &quot;+city.getCityName());        &#125;    &#125;&#125;\n\n输出结果：\nChinaSat Oct 01 08:00:00 CST 1949province:GDgetBirthDate:Sat Feb 04 08:00:00 CST 20171 gz2 dg\n\n解析的时候如果碰到集合类，那么可以使用 TypeReference 类\n@Testpublic void JsonStr2List() throws IOException&#123;    City city1 = new City();    city1.setId(1);    city1.setCityName(&quot;gz&quot;);    City city2 = new City();    city2.setId(2);    city2.setCityName(&quot;dg&quot;);    List&lt;City&gt; cities = new ArrayList&lt;City&gt;();    cities.add(city1);    cities.add(city2);    ObjectMapper mapper = new ObjectMapper();    String listJsonStr = mapper.writeValueAsString(cities);    System.out.println(listJsonStr);    List&lt;City&gt; list = mapper.readValue(listJsonStr, new  TypeReference&lt;List&lt;City&gt;&gt;()&#123;&#125; );    for (City city: list) &#123;        System.out.println(&quot;id:&quot;+city.getId()+&quot; cityName:&quot;+city.getCityName());    &#125;&#125;\n\n2）Streaming API\nJackson 提供了一套底层 API 来解析 Json 字符串，这个 API 为每个 Json 对象提供了符号。例如， ‘{’ 是解析器提供的第一个对象（writeStartObject()），键值对是解析器提供的另一个单独对象（writeString(key,value)）。这些 API 很强大，但是需要大量的代码。大多数情况下，Tree Model 和 Data Binding 可以代替 Streaming API。\n上面代码如果注释掉 city1.setId(1);这行，结果为：\n[&#123;&quot;id&quot;:null,&quot;cityName&quot;:&quot;gz&quot;&#125;,&#123;&quot;id&quot;:2,&quot;cityName&quot;:&quot;dg&quot;&#125;]id:null cityName:gzid:2 cityName:dg\n\n但假如想让 id 为 null 的不输出，不为 null 的输出除了 mapper.setSerializationInclusion(Include.NON_EMPTY); &#x2F;&#x2F; 配置 mapper 忽略空属性 这种方法外还可以在 ObjectMapper 中注册一个自定义的序列化 JsonSerializer 和反序列化JsonDeSerializer:\nCityJsonSerializer.java\npackage com.myjackson.databinding;import java.io.IOException;import com.fasterxml.jackson.core.JsonGenerator;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JsonSerializer;import com.fasterxml.jackson.databind.SerializerProvider;public class CityJsonSerializer extends JsonSerializer&lt;City&gt;&#123;    @Override    public void serialize(City city, JsonGenerator jsonGenerator, SerializerProvider arg2)            throws IOException, JsonProcessingException &#123;         jsonGenerator.writeStartObject();         if ( city.getId()!=null) &#123;             jsonGenerator.writeNumberField(&quot;id&quot;, city.getId());         &#125;         jsonGenerator.writeStringField(&quot;cityName&quot;, city.getCityName());         jsonGenerator.writeEndObject();    &#125;&#125;\n\nCityJsonDeSerializer.java\npackage com.myjackson.databinding;import java.io.IOException;import java.util.ArrayList;import java.util.List;import com.fasterxml.jackson.core.JsonParser;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.core.JsonToken;import com.fasterxml.jackson.databind.DeserializationContext;import com.fasterxml.jackson.databind.JsonDeserializer;public class CityJsonDeSerializer extends JsonDeserializer&lt;List&lt;City&gt;&gt;&#123;    @Override    public List&lt;City&gt; deserialize(JsonParser parser,DeserializationContext deserializationcontext) throws IOException,            JsonProcessingException &#123;        List&lt;City&gt; list = new ArrayList&lt;City&gt;();        // 开始解析数组，第一个JsonToken必须是JsonToken.START_ARRAY&quot;[&quot;         if (!JsonToken.START_ARRAY.equals(parser.getCurrentToken())) &#123;             System.out.println(parser.getCurrentToken());             return null;         &#125;        // 解析符号直到字符串结尾        while (!parser.isClosed()) &#123;            // 如果有必要的话，这个方法会沿着流前进直到足以确下一个JsonToken的类型            JsonToken token = parser.nextToken();            // 如果是最后一个JsonToken，那么就结束了            if (token == null)                break;            // 数组的每个元素都是对象，因此下一个JsonToken是JsonToken.START_OBJECT&quot;&#123;&quot;            if (!JsonToken.START_OBJECT.equals(token)) &#123;                break;            &#125;            City city = null;            // 输出id字段的值            while (true) &#123;                if (JsonToken.START_OBJECT.equals(token)) &#123;                    city = new City();                &#125;                token = parser.nextToken();                if (token == null)                    break;                if (JsonToken.FIELD_NAME.equals(token) ) &#123;                    if(&quot;id&quot;.equals(parser.getCurrentName()))&#123;                        token = parser.nextToken();                        city.setId(parser.getIntValue());                    &#125;else if(&quot;cityName&quot;.equals(parser.getCurrentName()))&#123;                        token = parser.nextToken();                        city.setCityName(parser.getText());                    &#125;                &#125;                if(JsonToken.END_OBJECT.equals(token))&#123;                    list.add(city);                &#125;            &#125;        &#125;        return list;    &#125;&#125;\n\n测试：\n@Testpublic void StreamJsonStr2List() throws IOException&#123;    City city1 = new City();    //city1.setId(1);    city1.setCityName(&quot;gz&quot;);    City city2 = new City();    city2.setId(2);    city2.setCityName(&quot;dg&quot;);    List&lt;City&gt; cities = new ArrayList&lt;City&gt;();    cities.add(city1);    cities.add(city2);    ObjectMapper mapper = new ObjectMapper();    SimpleModule module = new SimpleModule();    module.addSerializer(City.class, new CityJsonSerializer());    mapper.registerModule(module);    String listJsonStr = mapper.writeValueAsString(cities);    System.out.println(listJsonStr);    ObjectMapper mapper2 = new ObjectMapper();    SimpleModule module2 = new SimpleModule();    module2.addDeserializer(List.class, new CityJsonDeSerializer());    mapper2.registerModule(module2);    List&lt;City&gt; list = mapper2.readValue(listJsonStr, new  TypeReference&lt;List&lt;City&gt;&gt;()&#123;&#125; );    for (City city: list) &#123;        System.out.println(&quot;id:&quot;+city.getId()+&quot; cityName:&quot;+city.getCityName());    &#125;&#125;\n\n也可以简单一点，使用注解，省去在 ObjectMapper 中注册 SimpleModule\nimport com.fasterxml.jackson.databind.annotation.JsonSerialize;@JsonSerialize(using=CityJsonSerializer.class)public class City &#123;...&#125;\n\n运行结果:\n[&#123;&quot;cityName&quot;:&quot;gz&quot;&#125;,&#123;&quot;id&quot;:2,&quot;cityName&quot;:&quot;dg&quot;&#125;]id:null cityName:gzid:2 cityName:dg\n\n3）Tree Mode\n如果不想为 Json 结构写一个 class 的话，Tree Mode 是一个很好的选择。\n生成 json:\n@Testpublic void TreeMode2Json() throws IOException&#123;        //创建一个节点工厂,为我们提供所有节点        JsonNodeFactory factory = new JsonNodeFactory(false);        //创建一个json factory来写tree modle为json        JsonFactory jsonFactory = new JsonFactory();        //创建一个json生成器        JsonGenerator generator = jsonFactory.createGenerator(new FileWriter(new File(&quot;country2.json&quot;)));        //注意，默认情况下对象映射器不会指定根节点，下面设根节点为country        ObjectMapper mapper = new ObjectMapper();        ObjectNode country = factory.objectNode();        country.put(&quot;id&quot;,   1);        country.put(&quot;countryName&quot;,&quot;China&quot;);        country.put(&quot;establishTime&quot;, &quot;1949-10-01&quot;);        ArrayNode provinces = factory.arrayNode();        ObjectNode province = factory.objectNode();        ObjectNode city1 = factory.objectNode();        city1.put(&quot;id&quot;, 1);        city1.put(&quot;cityName&quot;, &quot;gz&quot;);        ObjectNode city2 = factory.objectNode();        city2.put(&quot;id&quot;, 1);        city2.put(&quot;cityName&quot;, &quot;dg&quot;);        ArrayNode cities = factory.arrayNode();        cities.add(city1).add(city2);        province.put(&quot;cities&quot;, cities);        provinces.add(province);        country.put(&quot;provinces&quot;,provinces);        ArrayNode lakes = factory.arrayNode();        lakes.add(&quot;QingHai Lake&quot;).add(&quot;Poyang Lake&quot;).add(&quot;Dongting Lake&quot;).add(&quot;Taihu Lake&quot;);        country.put(&quot;lakes&quot;,lakes);        ObjectNode forest = factory.objectNode();        forest.put(&quot;no.1&quot;,&quot;dxal&quot;);        forest.put(&quot;no.2&quot;, &quot;xxal&quot;);        country.put(&quot;forest&quot;, forest);        mapper.setSerializationInclusion(Include.NON_EMPTY);  // 配置mapper忽略空属性        mapper.writeTree(generator, country);    &#125;\n\n结果：\n&#123;  &quot;id&quot;: 1,  &quot;countryName&quot;: &quot;China&quot;,  &quot;establishTime&quot;: &quot;1949-10-01&quot;,  &quot;provinces&quot;: [    &#123;      &quot;cities&quot;: [        &#123; &quot;id&quot;: 1, &quot;cityName&quot;: &quot;gz&quot; &#125;,        &#123; &quot;id&quot;: 1, &quot;cityName&quot;: &quot;dg&quot; &#125;      ]    &#125;  ],  &quot;lakes&quot;: [&quot;QingHai Lake&quot;, &quot;Poyang Lake&quot;, &quot;Dongting Lake&quot;, &quot;Taihu Lake&quot;],  &quot;forest&quot;: &#123; &quot;no.1&quot;: &quot;dxal&quot;, &quot;no.2&quot;: &quot;xxal&quot; &#125;&#125;\n\n读取 json:\n@Testpublic void TreeModeReadJson() throws IOException&#123;    ObjectMapper mapper = new ObjectMapper();    // Jackson 提供一个树节点被称为&quot;JsonNode&quot;,ObjectMapper 提供方法来读 json 作为树的 JsonNode 根节点    JsonNode node = mapper.readTree(new File(&quot;country2.json&quot;));    // 看看根节点的类型    System.out.println(&quot;node JsonNodeType:&quot;+node.getNodeType());    System.out.println(&quot;---------得到所有 node 节点的子节点名称----------------------&quot;);    Iterator&lt;String&gt; fieldNames = node.fieldNames();    while (fieldNames.hasNext()) &#123;        String fieldName = fieldNames.next();        System.out.print(fieldName+&quot; &quot;);    &#125;    System.out.println(&quot;\\n---------------------------------------------------&quot;);    JsonNode lakes = node.get(&quot;lakes&quot;);    System.out.println(&quot;lakes:&quot;+lakes+&quot; JsonNodeType:&quot;+lakes.getNodeType());&#125;\n\n运行结果：\nnode JsonNodeType:OBJECT---------得到所有 node 节点的子节点名称-------------------------id countryName establishTime provinces lakes forest---lakes:[&quot;QingHai Lake&quot;,&quot;Poyang Lake&quot;,&quot;Dongting Lake&quot;,&quot;Taihu Lake&quot;] JsonNodeType:ARRAY\n\n5、结束Stream API 方式是开销最低、效率最高，但编写代码复杂度也最高，在生成 Json 时，需要逐步编写符号和字段拼接 json,在解析 Json 时，需要根据 token 指向也查找 json 值，生成和解析 json 都不是很方便，代码可读性也很低。Databinding 处理 Json 是最常用的 json 处理方式，生成 json 时，创建相关的 java 对象，并根据 json 内容结构把 java 对象组装起来，最后调用 writeValue 方法即可生成 json,解析时，就更简单了，直接把 json 映射到相关的 java 对象，然后就可以遍历 java 对象来获取值了。\nTreeModel 处理 Json，是以树型结构来生成和解析 json，生成 json 时，根据 json 内容结构，我们创建不同类型的节点对象，组装这些节点生成 json。解析 json 时，它不需要绑定 json 到 java bean，根据 json 结构，使用 path 或 get 方法轻松查找内容。\n6、解析 Jsonimport java.io.IOException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.TimeZone;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JsonNode;import com.fasterxml.jackson.databind.ObjectMapper;public class ParseJsonTest &#123;    /**     * @param args     */    public static void main(String[] args) &#123;        String data = &quot;&#123;\\&quot;type\\&quot;:2,\\&quot;range\\&quot;:1,\\&quot;start\\&quot;:1368417600,\\&quot;end\\&quot;:1368547140,&quot;                + &quot;\\&quot;cityName\\&quot;:\\&quot;天津\\&quot;,\\&quot;companyIds\\&quot;:[\\&quot;12000001\\&quot;],\\&quot;companyNames\\&quot;:[\\&quot;天津\\&quot;],&quot;                + &quot;\\&quot;12000001\\&quot;:&#123;\\&quot;data\\&quot;:[47947,48328,48573,48520],&quot;                + &quot;\\&quot;timestamps\\&quot;:[1368417600,1368417900,1368418200,1368418500]&#125;&#125;&quot;;        String data2 = parseJson(data);        System.out.println(data2);    &#125;    public static String parseJson(String data) &#123;        // 用来展现解析Json得到的值        StringBuffer buf = new StringBuffer();        ObjectMapper mapper = new ObjectMapper();        JsonNode rootNode = mapper.readTree(data); // 读取Json        // rootNode.path(&quot;xx&quot;)返回的还是一个JsonNode对象，调用该JsonNode的相应方法，得到键对应的值        int type = rootNode.path(&quot;type&quot;).asInt();        int range = rootNode.path(&quot;range&quot;).asInt();        long start = rootNode.path(&quot;start&quot;).asLong();        long end = rootNode.path(&quot;end&quot;).asLong();        String cityName = rootNode.path(&quot;cityName&quot;).asText();        // 转换时间格式        SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyyMMddHHmm&quot;);        sdf.setTimeZone(TimeZone.getTimeZone(&quot;GMT+8&quot;));        String str = &quot;类型(type):&quot; + type + &quot;\\r\\n&quot; + &quot;范围(range):&quot; + range                + &quot;\\r\\n&quot; + &quot;开始时间(start):&quot;                + sdf.format(new Date(start * 1000)) + &quot;\\r\\n&quot;                + &quot;结束时间(end):&quot; + sdf.format(new Date(end * 1000)) + &quot;\\r\\n&quot;                + &quot;城市名称(cityName):&quot; + cityName;        buf.append(str);        // 得到companyIds的JsonNode对象        JsonNode companyIds = rootNode.path(&quot;companyIds&quot;);        JsonNode companyNames = rootNode.path(&quot;companyNames&quot;);        // 遍历companyIds中的内容        for (int i = 0; i &lt; companyIds.size(); i++) &#123;            String companyId = companyIds.get(i).asText();            // 本例解析的Json字符串中companyIds与companyNames的长度是相同的，所有直接遍历companyNames            String companyName = companyNames.get(i).asText();            // companyId的值：12000001，对应Json串中的            // &quot;12000001&quot;:&#123;&quot;data&quot;:[...],&quot;timestamps&quot;:[....]&#125;            JsonNode infoNode = rootNode.path(companyId);            // 得到&quot;12000001&quot;:&#123;&quot;data&quot;:[...],&quot;timestamps&quot;:[....]&#125;中的data和timestamps的JsonNode对象            JsonNode dataNode = infoNode.path(&quot;data&quot;);            JsonNode timestampsNode = infoNode.path(&quot;timestamps&quot;);            // 遍历data和timestamps 本例中data.size与timestamps.size是相等的            buf.append(&quot;\\r\\n&#123;\\r\\n  公司ID(companyId):&quot; + companyId                    + &quot;\\r\\n  公司名称(companyName):&quot; + companyName + &quot;\\r\\n&quot;                    + &quot; data:&quot;);            for (int j = 0; j &lt; dataNode.size(); j++) &#123;                long dataValue = dataNode.get(j).asLong();                buf.append(dataValue + &quot;,&quot;);            &#125;            buf.append(&quot;\\r\\n time:&quot;);            for (int k = 0; k &lt; timestampsNode.size(); k++) &#123;                long timeValue = timestampsNode.get(k).asLong();                buf.append(sdf.format(new Date(timeValue * 1000)) + &quot;,&quot;);            &#125;            buf.append(&quot;\\r\\n&#125;\\r\\n&quot;);        &#125;        return buf.toString();    &#125;&#125;\n\n测试结果：\n类型(type):2范围(range):1开始时间(start):201305131200结束时间(end):201305142359城市名称(cityName):天津&#123;  公司ID(companyId):12000001  公司名称(companyName):天津  data:47947,48328,48573,48520,  time:201305131200,201305131205,201305131210,201305131215&#125;\n","categories":["后端技术","java"],"tags":["java","json","jackson"]},{"title":"jackson 将 json 串转成 List 或 Map 等集合","url":"/8a9db7f1-e38d-11ee-8d05-110f62540784/","content":"\n\n\n\n1、需求描述jackson 将 json 串转成 List、Map 等集合时，需要保证集合内的元素泛型不能丢失。\n2、案例1）需要构建 TypeReference 参数\npublic static &lt;T&gt; T json2Obj(String json, TypeReference&lt;T&gt; type) &#123;    return objectMapper.readValue(json, type);&#125;// 使用json2Obj(json, new TypeReference&lt;List&lt;String&gt;&gt;()&#123;&#125;);json2Obj(json, new TypeReference&lt;Map&lt;String, String&gt;&gt;()&#123;&#125;);\n\n2）collectionType\nprivate static JavaType collectionType(Class&lt;?&gt; collectionClz, Class&lt;?&gt; ...elementClz) &#123;    return om.getTypeFactory().constructParametricType(collectionClz, elementClz);&#125;public static List&lt;T&gt; json2List(String json, Class&lt;T&gt; elementClz) &#123;    objectMapper.readValue(json, collectionType(List.class, clz));&#125;public static List&lt;T&gt; json2Map(String json, Class&lt;T&gt; valueClz) &#123;    objectMapper.readValue(json, collectionType(Map.class, String.class, clz));&#125;// 使用json2List(json, String.class);json2Map(json. String.class);\n\n3）其他方法\npublic final class JsonUtils &#123;  private static ObjectMapper jackson = new ObjectMapper();  /**   * 把json转为键值对map   * @param jsonStr   * @return   */  public static Map jsonToMap(String jsonStr) &#123;    Map map = new HashMap&lt;String,Object&gt;();    try &#123;      map = jackson.readValue(jsonStr, HashMap.class);    &#125; catch (IOException e) &#123;      e.printStackTrace();    &#125;    return map;  &#125;  /**   * 把json转为List   * @param jsonStr   * @return   */  public static List jsonToList(String jsonStr) &#123;    List list = new ArrayList&lt;&gt;();    try &#123;      list = jackson.readValue(jsonStr,ArrayList.class);    &#125; catch (IOException e) &#123;      e.printStackTrace();    &#125;    return list;  &#125;&#125;\n","categories":["后端技术","java"],"tags":["java"]},{"title":"java-建立定时任务","url":"/58863540-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\nSpring 3.0 之后提供了 @EnableScheduling 注解和 @Scheduled 注解实现定时任务功能。本案例使用 SpringBoot 创建定时任务，主要有三种创建方式：\n\n使用 @Scheduled 注解\n实现 SchedulingConfigurer 接口\n基于注解设定多线程定时任务\n\n一、@Scheduled 注解1、在配置类上使用 @EnableScheduling 注解以开启计划任务。该方式默认为单线程，开启多个任务时，任务的执行时机会受上一个任务执行时间的影响。\n@EnableSchedulingpublic class SnippetApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SnippetApplication.class, args);    &#125;&#125;\n\n2、使用 @Scheduled 注解声明这是一个定时任务：\n@Componentpublic class BaseScheduled &#123;    @Scheduled(cron = &quot;0/10 * *  * * ?&quot;)    public void job() &#123;        System.out.println(Thread.currentThread().getName() + &quot;-&quot; + LocalDateTime.now());    &#125;&#125;\n\n3、@Scheduled 注解有如下属性\n\ncron，接收一个 cron 表达式\nzone 时区，接收一个 java.util.TimeZone#ID。默认是一个空字符串，取服务器所在地的时区。\nfixedDelay，服务启动后任务立即执行首次，延迟指定时间后再次执行。例如指定值 10s，相当于 cron 表达式 &quot;0/10 * * * * ?&quot;\nfixedDelayString，同 fixedDelay，值为字符串，并支持占位符\nfixedRate，上一次开始执行时间点之后多长时间再执行\nfixedRateString 同 fixedRate，值为字符串，并支持占位符\ninitialDelay，第一次延迟多长时间后再执行\ninitialDelayString，同 initialDelay，值为字符串，并支持占位符\ntimeUnit，以上计时属性的单位，默认毫秒（TimeUnit.MILLISECONDS）\n\n4、cron 属性接收的 cron 表达式支持占位符\napplication.yml 中添加如下定义\nscheduled:  cron: 0/10 * *  * * ?\n\n上述代码可更改为\n@Componentpublic class BaseScheduled &#123;    @Scheduled(cron = &quot;$&#123;scheduled.cron&#125;&quot;)    public void job() &#123;        System.out.println(Thread.currentThread().getName() + &quot;-&quot; + LocalDateTime.now());    &#125;&#125;\n\n查看完整代码\n@Scheduled(fixedDelayString = &quot;5&quot;, timeUnit = TimeUnit.SECONDS)public void job() throws InterruptedException, ExecutionException &#123;    System.out.println(&quot;定时任务开始=&quot; + Thread.currentThread().getName() + &quot;-&quot; + LocalDateTime.now());    BiFunction&lt;Integer, Integer, Callable&lt;String&gt;&gt; function = (id, second) -&gt; &#123;        return new Callable&lt;String&gt;() &#123;            @Override            public String call() throws Exception &#123;                TimeUnit.SECONDS.sleep(second);                return String.format(&quot;任务&#123; %s &#125;已完成，当前时间=&#123; %s &#125;&quot;, id, LocalDateTime.now());            &#125;        &#125;;    &#125;;    completionService.submit(function.apply(1, 2));    completionService.submit(function.apply(2, 8));    completionService.submit(function.apply(3, 10));    for (int index = 0; index &lt; 3; index++) &#123;        System.out.println(completionService.take().get());    &#125;&#125;\n\n执行几个周期，输出如下。\n定时任务开始=scheduling-1-2023-06-25T21:26:36.841582700【job1立即执行首次，理论上5s后执行，但是单线程，要等job2，只能排队】任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T21:26:38.844894 &#125;【job2立即执行首次，任务1的延迟2s】任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T21:26:44.842944900 &#125;【job2立即执行首次，任务2的延迟8s】任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T21:26:46.842699200 &#125;【job2立即执行首次，任务3的延迟10s】定时任务开始=scheduling-1-2023-06-25T21:26:46.842699200【job2完成，job1立刻执行，再次排队】任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T21:26:53.846321200 &#125;【job2等待5s后再次执行，加上任务1的延迟2s，共7s】任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T21:26:59.845000500 &#125;【job2等待5s后再次执行，加上任务2的延迟8s，共13s】任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T21:27:01.844899100 &#125;【job2等待5s后再次执行，加上任务3的延迟10s，共15s】定时任务开始=scheduling-1-2023-06-25T21:27:01.844899100任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T21:27:08.846885700 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T21:27:14.846942200 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T21:27:16.847136600 &#125;\n\n可见，两个任务的执行时间无法并行，完成后必须等待其他定时任务。若改为 fixedRateString，则结果为：\n2023-06-25T22:03:37.192+08:00  INFO 20272 --- [           main] com.lab.snippet.SnippetApplication       : Started SnippetApplication in 1.151 seconds (process running for 1.417)任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:03:39.192069600 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:03:45.193633600 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:03:47.192106900 &#125;定时任务开始=scheduling-1-2023-06-25T22:03:47.192106900任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:03:49.193520800 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:03:55.192690800 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:03:57.194620 &#125;定时任务开始=scheduling-1-2023-06-25T22:03:57.194620任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:03:59.207931100 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:04:05.203253700 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:04:07.205267400 &#125;定时任务开始=scheduling-1-2023-06-25T22:04:07.205267400\n\n此时，job2不在以上一次自己执行结束额时间为准，直接以job1的结束作为基准，2s后开始执行。但还是由于单线程，job1执行完仍然需要排队，等待job2完毕。\n改为每5s执行一次，结果不可控\n2023-06-25T22:24:53.688+08:00  INFO 14464 --- [           main] com.lab.snippet.SnippetApplication       : Started SnippetApplication in 1.135 seconds (process running for 1.386)任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:24:57.005405200 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:03.004356200 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:05.006176400 &#125;定时任务开始=scheduling-1-2023-06-25T22:25:05.006176400任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:12.016198400 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:18.001606600 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:20.001757800 &#125;定时任务开始=scheduling-1-2023-06-25T22:25:20.001757800定时任务开始=scheduling-1-2023-06-25T22:25:25.000208500任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:27.002035 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:33.013051900 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:35.007493700 &#125;定时任务开始=scheduling-1-2023-06-25T22:25:35.008453200定时任务开始=scheduling-1-2023-06-25T22:25:40.001605800任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:42.003821100 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:48.003383700 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:50.002780300 &#125;定时任务开始=scheduling-1-2023-06-25T22:25:50.002780300定时任务开始=scheduling-1-2023-06-25T22:25:55.001144200任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:25:57.002327300 &#125;\n\n2023-06-25T22:27:40.868+08:00  INFO 8008 --- [           main] com.lab.snippet.SnippetApplication       : Started SnippetApplication in 1.142 seconds (process running for 1.386)定时任务开始=scheduling-1-2023-06-25T22:27:45.000486300任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:27:47.005465 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:27:53.006984800 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:27:55.006056500 &#125;定时任务开始=scheduling-1-2023-06-25T22:27:55.007053500任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:28:02.009497100 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:28:08.013432600 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:28:10.003280800 &#125;定时任务开始=scheduling-1-2023-06-25T22:28:10.003280800定时任务开始=scheduling-1-2023-06-25T22:28:15.000889200任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:28:17.005103900 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:28:23.004417100 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:28:25.002408 &#125;定时任务开始=scheduling-1-2023-06-25T22:28:25.002408定时任务开始=scheduling-1-2023-06-25T22:28:30.000387200任务&#123; 1 &#125;已完成，当前时间=&#123; 2023-06-25T22:28:32.016138300 &#125;任务&#123; 2 &#125;已完成，当前时间=&#123; 2023-06-25T22:28:38.003692100 &#125;任务&#123; 3 &#125;已完成，当前时间=&#123; 2023-06-25T22:28:40.002122500 &#125;定时任务开始=scheduling-1-2023-06-25T22:28:40.002122500定时任务开始=scheduling-1-2023-06-25T22:28:45.001217","categories":["后端技术","java"],"tags":["java"]},{"title":"logback-日志配置","url":"/58863541-2a1e-11ee-846a-89c1529ebdf1/","content":"\n\n\n\n1 日志级别\n\n\n优先级\n日志级别\n描述\n\n\n\n1\ntrace\n追踪，指明程序运行轨迹\n\n\n2\ndebug\n调试，实际应用中一般将其作为最低级别\n\n\n3\ninfo\n输出重要的信息，使用较多\n\n\n4\nwarn\n警告\n\n\n5\nerror\n错误\n\n\n2 格式\n\n\n输出格式\n描述\n\n\n\n%date{yyyy-MM-dd HH:mm:ss.SSS}\n日志生产时间，精确到毫秒\n\n\n%-5level\n日志级别。例如 -5 表示左对齐并且固定输出 5 个字符，如果不足在右边补 0（ILoggingEvent.getLevel方法返回值）\n\n\n%logger\nlogger 的名称，例如 logger&#123;36&#125; 表示 logger 名字最长 36 个字符（ILoggingEvent.getLoggerName方法返回值）\n\n\n%thread\n输出当前线程名称（ILoggingEvent.getThreadName方法返回值）\n\n\n%p\n日志输出格式\n\n\n%msg\n日志内容\n\n\n%n\n换行符\n\n\n%class\n输出 java 类名\n\n\n%file\n输出文件名\n\n\n%L\n输出错误行号\n\n\n%method\n输出方法名\n\n\n%l\n输出语句所在的行数, 包括类名、方法名、文件名、行数\n\n\nhostName\n本地机器名\n\n\nhostAddress\n本地 ip 地址\n\n\n3 配置文件&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt;    &lt;!-- 定义日志输出格式和存储路径--&gt;    &lt;property name=&quot;LOG_PATTERN&quot; value=&quot;%date&#123;HH:mm:ss.SSS&#125;\\t[%thread]\\t%-5level %logger&#123;36&#125; - %msg%n&quot;/&gt;    &lt;!-- 注：如果最后打成jar包，日志将输出在logs目录下 --&gt;    &lt;property name=&quot;INFO_PATH&quot; value=&quot;logs/info.%d&#123;yyyy-MM-dd&#125;.%i.log&quot;/&gt;    &lt;property name=&quot;WARN_ERR_PATH&quot; value=&quot;logs/warn_err.%d&#123;yyyy-MM-dd&#125;.%i.log&quot;/&gt;    &lt;!-- 定义控制台输出 --&gt;    &lt;!-- 注1：如果最后打成jar包，该部分输出会出现在jar包所在目录下的sout.log文件 --&gt;    &lt;!-- 注2：name属性命名随意，引用时对应即可 --&gt;    &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;encoder&gt;            &lt;!-- 打印格式 --&gt;            &lt;pattern&gt;$&#123;LOG_PATTERN&#125;&lt;/pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;!-- info类型配置（仅显示info，过滤warn、error）--&gt;    &lt;appender name=&quot;FILE_INFO&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;!-- LevelFilter，按日志等级过滤 --&gt;        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;            &lt;level&gt;ERROR&lt;/level&gt;            &lt;onMatch&gt;DENY&lt;/onMatch&gt;        &lt;/filter&gt;        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;            &lt;level&gt;WARN&lt;/level&gt;            &lt;onMatch&gt;DENY&lt;/onMatch&gt;        &lt;/filter&gt;        &lt;!-- 自定义过滤器 --&gt;        &lt;filter class=&quot;com.xx.LogbackFilter&quot;/&gt;        &lt;!-- 文件名样式、保存周期、文件大小 --&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;            &lt;fileNamePattern&gt;$&#123;INFO_PATH&#125;&lt;/fileNamePattern&gt;            &lt;maxHistory&gt;3&lt;/maxHistory&gt;            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;                &lt;maxFileSize&gt;5MB&lt;/maxFileSize&gt;            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;        &lt;/rollingPolicy&gt;        &lt;encoder&gt;            &lt;pattern&gt;$&#123;LOG_PATTERN&#125;&lt;/pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;!--WARN、ERROR类型配置（仅显示warn及其以上等级）--&gt;    &lt;appender name=&quot;FILE_WARN_ERR&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;            &lt;level&gt;WARN&lt;/level&gt;        &lt;/filter&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;            &lt;fileNamePattern&gt;$&#123;WARN_ERR_PATH&#125;&lt;/fileNamePattern&gt;            &lt;maxHistory&gt;10&lt;/maxHistory&gt;            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;                &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt;            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;        &lt;/rollingPolicy&gt;        &lt;encoder&gt;            &lt;pattern&gt;$&#123;LOG_PATTERN&#125;&lt;/pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;!-- turboFilter类型的过滤器比appender先触发 --&gt;    &lt;turboFilter class=&quot;ch.qos.logback.classic.turbo.DynamicThresholdFilter&quot;&gt;        &lt;DefaultThreshold&gt;ERROR&lt;/DefaultThreshold&gt;        &lt;OnHigherOrEqual&gt;ACCEPT&lt;/OnHigherOrEqual&gt;        &lt;OnLower&gt;NEUTRAL&lt;/OnLower&gt;        &lt;Key&gt;cando&lt;/Key&gt;        &lt;MDCValueLevelPair&gt;            &lt;value&gt;read&lt;/value&gt;            &lt;level&gt;DEBUG&lt;/level&gt;        &lt;/MDCValueLevelPair&gt;        &lt;MDCValueLevelPair&gt;            &lt;value&gt;write&lt;/value&gt;            &lt;level&gt;INFO&lt;/level&gt;        &lt;/MDCValueLevelPair&gt;        &lt;MDCValueLevelPair&gt;            &lt;value&gt;all&lt;/value&gt;            &lt;level&gt;WARN&lt;/level&gt;        &lt;/MDCValueLevelPair&gt;    &lt;/turboFilter&gt;    &lt;!-- 根目录输出等级为DEBUG --&gt;    &lt;root level=&quot;DEBUG&quot;&gt;        &lt;appender-ref ref=&quot;FILE_INFO&quot;/&gt;        &lt;appender-ref ref=&quot;FILE_WARN_ERR&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;\n\n3.1 过滤器logbcak 允许给日志记录器 appender 配置一个或多个 Filter，或者给整体配置一个或多个 TurboFilter 实现当满足过滤器指定的条件时处理日志。\n\n\n\n过滤器\n类型\n描述\n\n\n\nLevelFilter\nFilter\n对等于（onMatch）或不等于（onMismatch）指定 level 的日志进行处理\n\n\nThresholdFilter\nFilter\n对大于或等于（onMatch）指定 level 的日志进行处理；小于（onMismatch）指定 level 的日志进行处理\n\n\nEvaluatorFilter\nFilter\n对满足（onMatch）或不满足（onMismatch）指定表达式的日志进行处理\n\n\nMDCFilter\nTurboFilter\n对等于（onMatch）或不等于（onMismatch） MDCKey 及其 Value 的日志进行处理\n\n\nDuplicateMessageFilter\nTurboFilter\n不记录多余的重复的日志。有两个子标签：&lt;cacheSize&gt; 表示内部缓存对旧消息引用的个数上限，默认 100；&lt;allowedRepetitions&gt; 表示允许消息出现的重复次数上限，超过次数上限的记录请求将被丢弃\n\n\nDynamicThresholdFilter\nTurboFilter\n动态版的 ThresholdFilter，根据 MDC 域中是否存在某个键，该键对应的值是否相等，可实现日志级别动态切换\n\n\nMarkerFilter\nTurboFilter\n对带有指定标记的日志进行处理\n\n\n\nonMatch、onMismatch 的三种取值和处理方式：\n\n\nDENY：拒绝了记录\nNEUTRAL：本级过滤器放行，不记录。注意，如果日志途径的所有过滤器都是 NEUTRAL，则记录\nACCEPT：需要记录\n\nEvaluatorFilter 例子\n在 &lt;appender&gt; 标签中使用，需要额外引入依赖：\n// https://mvnrepository.com/artifact/org.codehaus.janino/janinoimplementation group: &#x27;org.codehaus.janino&#x27;, name: &#x27;janino&#x27;, version: &#x27;3.1.9&#x27;\n\n当前需要拒绝来自 org.apache.http.wire 类和 org.apache.http.headers 类的日志信息，其他日志记录：\n&lt;filter class=&quot;ch.qos.logback.core.filter.EvaluatorFilter&quot;&gt;    &lt;evaluator&gt;        &lt;expression&gt;            if(event.getLoggerName().contains(&quot;org.apache.http.wire&quot;) || event.getLoggerName().contains(&quot;org.apache.http.headers&quot;))&#123;                return true;            &#125; else &#123;                return false;            &#125;        &lt;/expression&gt;    &lt;/evaluator&gt;    &lt;OnMatch&gt;DENY&lt;/OnMatch&gt;    &lt;OnMismatch&gt;ACCEPT&lt;/OnMismatch&gt;&lt;/filter&gt;\n\nMDCFilter 例子\n例如，仅记录 MDCKey 为 cando，Value 为 read 的日志：\n&lt;turboFilter class=&quot;ch.qos.logback.classic.turbo.MDCFilter&quot;&gt;    &lt;MDCKey&gt;cando&lt;/MDCKey&gt;    &lt;Value&gt;read&lt;/Value&gt;    &lt;OnMatch&gt;ACCEPT&lt;/OnMatch&gt;    &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;&lt;/turboFilter&gt;\n\nDuplicateMessageFilter 例子\n限制仅显示 1 条日志\n&lt;turboFilter class=&quot;ch.qos.logback.classic.turbo.DuplicateMessageFilter&quot;&gt;    &lt;AllowedRepetitions&gt;1&lt;/AllowedRepetitions&gt;&lt;/turboFilter&gt;\n\n测试代码：\nlog.info(marker, &quot;this is marker&quot;);log.info(&quot;this is marker&quot;);log.info(String.format(&quot;this is marker&quot;, 1));log.info(String.format(&quot;this is marker&quot;, 2));\n\n测试代码中第 2-4 行判断为重复，输出结果：\n16:52:01.698\t[Test worker]\tINFO  s.ApplicationTests - this is marker16:52:01.699\t[Test worker]\tINFO  s.ApplicationTests - this is marker\n\nDynamicThresholdFilter 例子&#96;\n测试代码：\nMDC.put(&quot;null&quot;, &quot;none&quot;);log.trace(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; TRACE &#125;&quot;);log.debug(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; DEBUG &#125;&quot;);log.info(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; INFO &#125;&quot;);log.warn(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; WARN &#125;&quot;);log.error(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; ERROR &#125;&quot;);MDC.put(&quot;cando&quot;, &quot;read&quot;);log.trace(&quot;key=&#123; cando &#125;,value=&#123; read &#125;,level=&#123; TRACE &#125;&quot;);log.debug(&quot;key=&#123; cando &#125;,value=&#123; read &#125;,level=&#123; DEBUG &#125;&quot;);log.info(&quot;key=&#123; cando &#125;,value=&#123; read &#125;,level=&#123; INFO &#125;&quot;);log.warn(&quot;key=&#123; cando &#125;,value=&#123; read &#125;,level=&#123; WARN &#125;&quot;);log.error(&quot;key=&#123; cando &#125;,value=&#123; read &#125;,level=&#123; ERROR &#125;&quot;);MDC.put(&quot;cando&quot;, &quot;write&quot;);log.trace(&quot;key=&#123; cando &#125;,value=&#123; write &#125;,level=&#123; TRACE &#125;&quot;);log.debug(&quot;key=&#123; cando &#125;,value=&#123; write &#125;,level=&#123; DEBUG &#125;&quot;);log.info(&quot;key=&#123; cando &#125;,value=&#123; write &#125;,level=&#123; INFO &#125;&quot;);log.warn(&quot;key=&#123; cando &#125;,value=&#123; write &#125;,level=&#123; WARN &#125;&quot;);log.error(&quot;key=&#123; cando &#125;,value=&#123; write &#125;,level=&#123; ERROR &#125;&quot;);MDC.put(&quot;cando&quot;, &quot;none&quot;);log.trace(&quot;key=&#123; cando &#125;,value=&#123; none &#125;,level=&#123; TRACE &#125;&quot;);log.debug(&quot;key=&#123; cando &#125;,value=&#123; none &#125;,level=&#123; DEBUG &#125;&quot;);log.info(&quot;key=&#123; cando &#125;,value=&#123; none &#125;,level=&#123; INFO &#125;&quot;);log.warn(&quot;key=&#123; cando &#125;,value=&#123; none &#125;,level=&#123; WARN &#125;&quot;);log.error(&quot;key=&#123; cando &#125;,value=&#123; none &#125;,level=&#123; ERROR &#125;&quot;);MDC.put(&quot;cando&quot;, &quot;all&quot;);log.trace(&quot;key=&#123; cando &#125;,value=&#123; all &#125;,level=&#123; TRACE &#125;&quot;);log.debug(&quot;key=&#123; cando &#125;,value=&#123; all &#125;,level=&#123; DEBUG &#125;&quot;);log.info(&quot;key=&#123; cando &#125;,value=&#123; all &#125;,level=&#123; INFO &#125;&quot;);log.warn(&quot;key=&#123; cando &#125;,value=&#123; all &#125;,level=&#123; WARN &#125;&quot;);log.error(&quot;key=&#123; cando &#125;,value=&#123; all &#125;,level=&#123; ERROR &#125;&quot;);MDC.put(&quot;null&quot;, &quot;none&quot;);log.trace(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; TRACE &#125;&quot;);log.debug(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; DEBUG &#125;&quot;);log.info(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; INFO &#125;&quot;);log.warn(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; WARN &#125;&quot;);log.error(&quot;key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; ERROR &#125;&quot;);\n\n执行结果：\n\n当 key 和 value 都对应时，记录大于等于给定 level 的日志\n当 key 对应，value 不对应时，按&lt;DefaultThreshold&gt;标签处理\n当 key 不对应时，无论 value 是否对应，所得结果不确定：在首位调用，仅记录ERROR，满足&lt;DefaultThreshold&gt;标签限定；若紧跟其他调用，会与该调用的等级相同。\n\n13:41:52.810\t[Test worker]\tERROR s.ApplicationTests - key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; ERROR &#125;13:41:52.811\t[Test worker]\tDEBUG s.ApplicationTests - key=&#123; cando &#125;,value=&#123; read &#125;,level=&#123; DEBUG &#125;13:41:52.811\t[Test worker]\tINFO  s.ApplicationTests - key=&#123; cando &#125;,value=&#123; read &#125;,level=&#123; INFO &#125;13:41:52.811\t[Test worker]\tWARN  s.ApplicationTests - key=&#123; cando &#125;,value=&#123; read &#125;,level=&#123; WARN &#125;13:41:52.811\t[Test worker]\tERROR s.ApplicationTests - key=&#123; cando &#125;,value=&#123; read &#125;,level=&#123; ERROR &#125;13:41:52.811\t[Test worker]\tINFO  s.ApplicationTests - key=&#123; cando &#125;,value=&#123; write &#125;,level=&#123; INFO &#125;13:41:52.811\t[Test worker]\tWARN  s.ApplicationTests - key=&#123; cando &#125;,value=&#123; write &#125;,level=&#123; WARN &#125;13:41:52.811\t[Test worker]\tERROR s.ApplicationTests - key=&#123; cando &#125;,value=&#123; write &#125;,level=&#123; ERROR &#125;13:41:52.811\t[Test worker]\tERROR s.ApplicationTests - key=&#123; cando &#125;,value=&#123; none &#125;,level=&#123; ERROR &#125;13:41:52.811\t[Test worker]\tWARN  s.ApplicationTests - key=&#123; cando &#125;,value=&#123; all &#125;,level=&#123; WARN &#125;13:41:52.811\t[Test worker]\tERROR s.ApplicationTests - key=&#123; cando &#125;,value=&#123; all &#125;,level=&#123; ERROR &#125;13:41:52.811\t[Test worker]\tWARN  s.ApplicationTests - key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; WARN &#125;13:41:52.811\t[Test worker]\tERROR s.ApplicationTests - key=&#123; null &#125;,value=&#123; none &#125;,level=&#123; ERROR &#125;\n\nMarkerFilter 例子\n指定记录带有 test 标记的日志：\n&lt;turboFilter class=&quot;ch.qos.logback.classic.turbo.MarkerFilter&quot;&gt;    &lt;Marker&gt;test&lt;/Marker&gt;    &lt;OnMatch&gt;ACCEPT&lt;/OnMatch&gt;    &lt;OnMismatch&gt;DENY&lt;/OnMismatch&gt;&lt;/turboFilter&gt;\n\n测试代码：\nMarker marker = MarkerFactory.getMarker(&quot;test&quot;);log.info(marker,&quot;this is marker&quot;);log.info(&quot;a normal log&quot;);\n\n3.2 自定义过滤器实现一个与上文相同的功能，拒绝来自 org.apache.http.wire 类和 org.apache.http.headers 类的日志信息，其他日志记录：\npublic class LogbackFilter extends Filter&lt;ILoggingEvent&gt; &#123;    @Override    public FilterReply decide(ILoggingEvent event) &#123;        if(event.getLoggerName().contains(&quot;org.apache.http.wire&quot;) || event.getLoggerName().contains(&quot;org.apache.http.headers&quot;))&#123;            return FilterReply.DENY;        &#125;        return FilterReply.NEUTRAL;    &#125;&#125;\n","categories":["后端技术","java"],"tags":["java","logback"]},{"title":"spring 之 FileSystemResource","url":"/3c6aeb00-e213-11ee-8578-cb8bdeddad57/","content":"\n\n\n\n1、来源FileSystemResource 是 Spring 框架中 Resource 接口的一个实现类，主要用于访问文件系统中的资源。这个类封装了对文件系统的直接访问能力，使得在 Spring 的上下文中可以方便地以统一的方式处理本地文件。\n2、作用1）统一资源访问接口\nSpring 提供了 Resource 接口来抽象不同类型的资源（如文件、类路径资源、URL 资源等），而 FileSystemResource 是针对文件系统资源的实现，提供了一种与具体文件系统交互的标准方式。\n2）读取和操作文件\n通过 FileSystemResource，开发者能够根据给定的文件系统路径读取文件内容、获取文件信息（如文件名、路径、是否存在、最后修改时间等）以及进行文件的读写操作。\n3）集成到 Spring 框架中\n在 Spring 的配置文件加载、组件扫描、自动装配等场景下，当需要从文件系统加载资源时，会隐式或显式地创建 FileSystemResource 对象\n3、案例import org.springframework.core.io.FileSystemResource;// 创建一个指向文件系统的资源对象FileSystemResource resource = new FileSystemResource(&quot;/path/to/myfile.txt&quot;);// 使用资源对象读取文件内容InputStream inputStream = resource.getInputStream();byte[] contentBytes = StreamUtils.copyToByteArray(inputStream);// 或者使用Spring的Resource工具方法直接读取字符串内容String content = FileCopyUtils.copyToString(new InputStreamReader(resource.getInputStream()));// 获取文件相关信息boolean exists = resource.exists();long lastModified = resource.lastModified();// 写入文件OutputStream outputStream = resource.getOutputStream();outputStream.write(someData);outputStream.close();\n","categories":["后端技术","java"],"tags":["java"]},{"title":"spring 之 ServletUriComponentsBuilder","url":"/3c6aeb01-e213-11ee-8578-cb8bdeddad57/","content":"\n\n\n\n1、来源ServletUriComponentsBuilder 是 Spring Framework 中用于构建和操作 URI 的一个类，特别适合在基于 Servlet 容器的 Web 应用程序中使用。它主要用于从当前 Servlet 请求上下文中获取相关信息（如主机名、端口、scheme 等），然后构造或修改完整的 URI。\n2、作用1）基于当前请求构建 URI\n当需要生成一个与当前请求相关的新的 URI 时，比如创建一个重定向 URL 或是一个 API 资源链接时，可以利用 ServletUriComponentsBuilder 从当前 Servlet 映射提取信息。\n2）动态替换路径变量\n类似于 MVC 视图中的模型属性，可以在 URI 模板字符串中定义占位符，并通过 .expand() 方法动态地将实际值插入到这些占位符中。\n3）处理反向代理\n在有 Nginx 等反向代理服务器的情况下，可以通过读取 X-Forwarded-* 标头来正确识别客户端的原始请求信息，从而构建正确的完整 URI。\n3、案例import org.springframework.web.servlet.support.ServletUriComponentsBuilder;// 基于当前请求映射构建新URIURI newLocation = ServletUriComponentsBuilder.fromCurrentServletMapping()    .path(&quot;/api/users/&#123;id&#125;&quot;)    .buildAndExpand(123) // 替换&#123;id&#125;为实际ID值    .toUri();// 直接指定主机、端口、路径等构建URIURI customLocation = ServletUriComponentsBuilder.newInstance()    .scheme(&quot;https&quot;)    .host(&quot;example.com&quot;)    .port(443)    .path(&quot;/v1/resources&quot;)    .build()    .toUri();// 处理Nginx反向代理，确保构建出的是用户看到的实际URL// （假设Spring配置已启用对X-Forwarded-*头的支持）URI proxiedLocation = ServletUriComponentsBuilder.fromCurrentRequest()    .pathSegment(&quot;proxied-resource&quot;)    .build()    .toUri();\n","categories":["后端技术","java"],"tags":["java"]},{"title":"springboot 数据源配置","url":"/d27a8f70-9bfe-11ee-a92b-05e08d68d559/","content":"\n\n\n\n1、环境及依赖\nAmazon Corretto 17\nSpring Boot 3.2.0\nGradle 7.4.2\npostgresql 15.5-1\nmariadb 10.11.6\n\ndependencies &#123;    implementation &#x27;org.mybatis.spring.boot:mybatis-spring-boot-starter:3.0.3&#x27;    compileOnly &#x27;org.projectlombok:lombok&#x27;    runtimeOnly &#x27;org.mariadb.jdbc:mariadb-java-client&#x27;    runtimeOnly &#x27;org.postgresql:postgresql&#x27;    annotationProcessor &#x27;org.projectlombok:lombok&#x27;    testImplementation &#x27;org.springframework.boot:spring-boot-starter-test&#x27;    testImplementation &#x27;org.mybatis.spring.boot:mybatis-spring-boot-starter-test:3.0.3&#x27;&#125;\n\n2、application.ymlspring:  datasource:    main:      driverClassName: org.mariadb.jdbc.Driver      jdbc-url: jdbc:mariadb://localhost:3306/demo?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true      username: root      password: root    secondary:      driverClassName: org.postgresql.Driver      url: jdbc:postgresql://192.168.1.5:5432/postgres?currentSchema=demo      username: postgres      password: postgres\n\n配置要点\n\n每个数据库要分别指定名称，必须有一个主数据库。本例中主数据库为 main，次数据库为 secondary\n本例使用 Hikari 作为连接池。多数据库的地址字段为应显示指定为 jdbc-url 而非 url。单个数据库时，可配置为 url。主数据库使用 @ConfigurationProperties 注解指定相关配置项。为便于对比，次数据库使用另一种等效方式：从配置文件指定的位置取值，此时不受 jdbc-url 或 url 的限制。\npg 数据库有「模式（Schema）」的概念，配置文件可指定模式，如果不指定，则相应 sql 语句需要带上模式名称，否则默认指向 public，如：insert into demo.test_table(name, age) VALUES (&#39;haha&#39;,123);\n\n3、配置数据源MainDataSourceConfig.java\n@Configuration@MapperScan(basePackages = &quot;com.example.dao.main&quot;, sqlSessionTemplateRef = &quot;mainSqlSessionTemplate&quot;)public class MainDataSourceConfig &#123;    @Bean(name = &quot;mainDataSource&quot;)    @Primary    @ConfigurationProperties(prefix = &quot;spring.datasource.main&quot;)    public DataSource dataSource() &#123;        return DataSourceBuilder.create().build();    &#125;    @Bean(name = &quot;mainSqlSessionFactory&quot;)    @Primary    public SqlSessionFactory sqlSessionFactory(@Qualifier(&quot;mainDataSource&quot;) DataSource dataSource) throws Exception &#123;        SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();        sessionFactory.setDataSource(dataSource);        sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath*:mapper/main/*.xml&quot;));        sessionFactory.setTypeAliasesPackage(&quot;com.example.entity&quot;);        org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration();        configuration.setJdbcTypeForNull(JdbcType.NULL);        configuration.setCallSettersOnNulls(true);        configuration.setLogImpl(StdOutImpl.class);        sessionFactory.setConfiguration(configuration);        return sessionFactory.getObject();    &#125;    @Bean(name = &quot;mainTransactionManager&quot;)    @Primary    public DataSourceTransactionManager dataSourceTransactionManager(@Qualifier(&quot;mainDataSource&quot;) DataSource dataSource) &#123;        return new DataSourceTransactionManager(dataSource);    &#125;    @Bean(name = &quot;mainSqlSessionTemplate&quot;)    @Primary    public SqlSessionTemplate sqlSessionTemplate(@Qualifier(&quot;mainSqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) &#123;        return new SqlSessionTemplate(sqlSessionFactory);    &#125;&#125;\n\nSecondaryDataSourceConfig.java\n@Configuration@MapperScan(basePackages = &quot;com.example.dao.secondary&quot;, sqlSessionTemplateRef = &quot;secondarySqlSessionTemplate&quot;)public class SecondaryDataSourceConfig &#123;    @Value(&quot;$&#123;spring.datasource.driverClassName&#125;&quot;)    private String driverClassName;    @Value(&quot;$&#123;spring.datasource.secondary.url&#125;&quot;)    private String url;    @Value(&quot;$&#123;spring.datasource.secondary.username&#125;&quot;)    private String user;    @Value(&quot;$&#123;spring.datasource.secondary.password&#125;&quot;)    private String password;    @Bean(name = &quot;secondaryDataSource&quot;)    public DataSource dataSource() &#123;        DataSourceBuilder&lt;?&gt; dataSourceBuilder = DataSourceBuilder.create();        dataSourceBuilder.driverClassName(driverClassName);        dataSourceBuilder.url(url);        dataSourceBuilder.password(password);        dataSourceBuilder.username(user);        return dataSourceBuilder.build();        // 或者使用 DriverManagerDataSource        // DriverManagerDataSource dataSource = new DriverManagerDataSource();        // dataSource.setDriverClassName(driverClassName);        // dataSource.setUrl(url);        // dataSource.setUsername(user);        // dataSource.setPassword(password);        //        // return dataSource;    &#125;    @Bean(name = &quot;secondarySqlSessionFactory&quot;)    public SqlSessionFactory sqlSessionFactory(@Qualifier(&quot;secondaryDataSource&quot;) DataSource dataSource) throws Exception &#123;        SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();        sessionFactory.setDataSource(dataSource);        sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath*:mapper/secondary/*.xml&quot;));        sessionFactory.setTypeAliasesPackage(&quot;com.example.entity&quot;);        org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration();        configuration.setJdbcTypeForNull(JdbcType.NULL);        configuration.setCallSettersOnNulls(true);        configuration.setLogImpl(StdOutImpl.class);        sessionFactory.setConfiguration(configuration);        return sessionFactory.getObject();    &#125;    @Bean(name = &quot;secondaryTransactionManager&quot;)    public DataSourceTransactionManager dataSourceTransactionManager(@Qualifier(&quot;secondaryDataSource&quot;) DataSource dataSource) &#123;        return new DataSourceTransactionManager(dataSource);    &#125;    @Bean(name = &quot;secondarySqlSessionTemplate&quot;)    public SqlSessionTemplate sqlSessionTemplate(@Qualifier(&quot;secondarySqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) &#123;        return new SqlSessionTemplate(sqlSessionFactory);    &#125;&#125;\n\n配置要点\n\n如果使用注解，可不配置 classpath*:mapper/secondary/*.xml\n\n4、数据表及 dao 接口1）测试表定义\nmariadb\ncreate table test_table(    id   bigint auto_increment        primary key,    name char(5) not null,    age  int     not null);\n\npg\ncreate table test_table(    id   bigserial        constraint test_table_pk            primary key,    name char(5) not null,    age  integer not null);alter table test_table    owner to postgres;\n\n2）dao\nIMain\n@Repository@Mapperpublic interface IMain &#123;    @Insert(&quot;insert into test_table(name, age) VALUES (#&#123;name&#125;,23);&quot;)    void insertData(String name);&#125;\n\nISecondary\n@Repository@Mapperpublic interface ISecondary &#123;    @Insert(&quot;insert into test_table(name, age) VALUES (#&#123;name&#125;,23);&quot;)    void insertData(String name);&#125;\n\n配置要点\n\npg 数据库如果在配置文件不指定模式，则相应 sql 语句需要带上模式名称，如：insert into demo.test_table(name, age)，否则默认指向 public\n\n5、测试@SpringBootTestclass MutiDatabaseApplicationTests &#123;    @Resource    private ISecondary iSecondary;    @Resource    private IMain iMain;    @Test    void contextLoads() &#123;        iSecondary.insertData(&quot;jack&quot;);        iMain.insertData(&quot;mark&quot;);    &#125;&#125;\n","categories":["后端技术","java"],"tags":["springboot","java"]},{"title":"springboot 服务运行时读取目录下文件","url":"/3c6aeb02-e213-11ee-8578-cb8bdeddad57/","content":"\n\n\n\n1 问题描述服务执行时，读取 jar 所在目录的外部文件\n2 解决方案通过 ApplicationHome 获取 jar 所在目录路径\nApplicationHome home = new ApplicationHome(TestSpringBootApplication.class);String jarPath = home.getDir().toString();\n\n3 案例1）建立一个 Controller，响应更新所在目录路径\n@RestControllerpublic class ActionController &#123;    @RequestMapping(&quot;/dir&quot;)    public String updateDirMsg() &#123;        // 获取jar所在目录路径        ApplicationHome home = new ApplicationHome(TestSpringBootApplication.class);        String jarPath = home.getDir().toString();        try (BufferedWriter writer = new BufferedWriter(new FileWriter(jarPath + &quot;/path.txt&quot;, true))) &#123;            writer.write(LocalDateTime.now() + &quot; :&quot; + jarPath);            writer.newLine();            writer.flush();        &#125; catch (IOException e) &#123;            System.err.println(&quot;写入文件时发生错误: &quot; + e.getMessage());        &#125;        return jarPath;    &#125;&#125;\n\n2）更进一步，利用路径保存上传的文件\n@Controllerpublic class FileUploadController &#123;    // 设置上传文件的根目录    private static final String UPLOAD_ROOT_DIR = new ApplicationHome(TestSpringBootApplication.class).getDir().toString();    @PostMapping(&quot;/upload&quot;)    public ResponseEntity&lt;String&gt; uploadFile(@RequestParam(&quot;file&quot;) MultipartFile file) &#123;        if (file.isEmpty()) &#123;            return ResponseEntity.badRequest().body(&quot;上传的压缩包不能为空&quot;);        &#125;        try &#123;            Path targetPath = Paths.get(UPLOAD_ROOT_DIR, file.getOriginalFilename());            // 确保父目录存在            Files.createDirectories(targetPath.getParent());            // 保存上传的压缩包            file.transferTo(targetPath.toFile());            // 解压文件到指定目录            unzipFile(targetPath.toString(), UPLOAD_ROOT_DIR);            FileSystemResource fileSystemResource = new FileSystemResource(targetPath.toFile());            return ResponseEntity.ok().body(String.valueOf(fileSystemResource));        &#125; catch (IOException e) &#123;            e.printStackTrace();            return ResponseEntity.status(500).body(&quot;上传过程中发生错误：&quot; + e.getMessage());        &#125;    &#125;    private void unzipFile(String zipFilePath, String destDir) throws IOException &#123;        try (ZipInputStream zis = new ZipInputStream(new FileInputStream(zipFilePath))) &#123;            ZipEntry entry = zis.getNextEntry();            while (entry != null) &#123;                Path filePath = Paths.get(destDir, entry.getName());                if (!entry.isDirectory()) &#123;                    Files.createDirectories(filePath.getParent());                    Files.copy(zis, filePath);                &#125; else &#123;                    Files.createDirectories(filePath);                &#125;                zis.closeEntry();                entry = zis.getNextEntry();            &#125;        &#125;    &#125;\n\n相应的前端案例代码\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;Upload Zip File&lt;/title&gt;    &lt;link href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;container mt-4&quot;&gt;    &lt;h2&gt;Upload and Extract ZIP File&lt;/h2&gt;    &lt;form id=&quot;uploadForm&quot; enctype=&quot;multipart/form-data&quot;&gt;        &lt;div class=&quot;mb-3&quot;&gt;            &lt;label for=&quot;zipFile&quot; class=&quot;form-label&quot;&gt;Select a ZIP file to upload:&lt;/label&gt;            &lt;input type=&quot;file&quot; class=&quot;form-control&quot; id=&quot;zipFile&quot; name=&quot;file&quot; accept=&quot;.zip&quot;&gt;        &lt;/div&gt;        &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot; id=&quot;uploadButton&quot;&gt;Upload &amp; Extract&lt;/button&gt;    &lt;/form&gt;    &lt;div id=&quot;responseMessage&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;script&gt;    document.addEventListener(&#x27;DOMContentLoaded&#x27;, function() &#123;        const uploadForm = document.getElementById(&#x27;uploadForm&#x27;);        const zipFileInput = document.getElementById(&#x27;zipFile&#x27;);        const responseMessage = document.getElementById(&#x27;responseMessage&#x27;);        const uploadButton = document.getElementById(&#x27;uploadButton&#x27;);        uploadButton.addEventListener(&#x27;click&#x27;, function(event) &#123;            event.preventDefault(); // 阻止表单默认提交行为            if (!zipFileInput.files.length) &#123;                responseMessage.textContent = &quot;Please select a ZIP file.&quot;;                return;            &#125;            const formData = new FormData(uploadForm);            fetch(&#x27;/upload&#x27;, &#123;                method: &#x27;POST&#x27;,                body: formData,            &#125;)                .then(response =&gt; response.text())                .then(data =&gt; &#123;                    responseMessage.textContent = data;                    // 在这里可以添加跳转到查看解压后文件列表的逻辑                &#125;)                .catch(error =&gt; &#123;                    responseMessage.textContent = &quot;An error occurred while uploading the file: &quot; + error;                &#125;);            // 清空已选择的文件            zipFileInput.value = &#x27;&#x27;;        &#125;);    &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n","categories":["后端技术","java"],"tags":["java"]},{"title":"前端无法获取响应头 Content-disposition","url":"/931e2911-e409-11ee-86b7-fb4c7634711e/","content":"\n\n\n\n\n部分内容引用自：Access-Control-Expose-Headers（MDN）\n\n默认情况下，只有六种 simple response headers 可以暴露给外部：\n\nCache-Control\nContent-Language\nContent-Type\nExpires\nLast-Modified\nPragma\n\n想要暴露一个非简单响应头，可以这样指定：\nAccess-Control-Expose-Headers: Content-Length\n\n想要额外暴露自定义的头，例如 X-Kuma-Revision，也可以指定多个，用逗号隔开：\nAccess-Control-Expose-Headers: Content-Length, X-Kuma-Revision\n\n以此类推，在服务端增加如下代码即可：\n@RequestMapping(value = &quot;/mapping&quot;, method = RequestMethod.POST)public void exportExcel(HttpServletResponse response) throws Exception &#123;    ...    response.setHeader(&quot;Access-Control-Expose-Headers&quot;,&quot;Content-disposition&quot;);    response.setHeader(&quot;Content-disposition&quot;, &quot;attachment;value=123&quot;);&#125;\n","categories":["后端技术","java"],"tags":["java"]},{"title":"Anaconda 下修改 Jupyter 的默认路径","url":"/8a9db7f0-e38d-11ee-8d05-110f62540784/","content":"\n\n\n\n1、解决步骤1）建立要更改的目录，如 D:\\Desktop\\jupyterDir\n2）打开 Anaconda Prompt，输入以下命令\njupyter notebook --generate-config\n\n\n该命令将生成 Jupyter 配置文件，如果提示是否覆盖，确认覆盖即可。\n\n3）根据上述路径找到 jupyter_notebook_config.py，搜索 c.NotebookApp.notebook_dir，删除 # 取消注释，将路径填入：\nc.NotebookApp.notebook_dir = r&#x27;D:\\Desktop\\jupyterDir&#x27;\n\n或\nc.NotebookApp.notebook_dir = &#x27;D:\\\\Desktop\\\\jupyterDir&#x27;\n\n4）找到 Jupyter 快捷方式，将 目标 最后面的 %USERPROFILE% 删除。\n","categories":["后端技术","python"],"tags":["Anaconda","Jupyter"]},{"title":"python 的字符串前缀","url":"/97816df0-a133-11ee-9970-39bf61dae061/","content":"\n\n\n\n1、u例如：u&#39;中文字符串&#39;，表示该字符串是 unicode 编码，一般在 Python2 中使用，用在含有中文字符的字符串前，防止因为编码问题导致中文出现乱码，一般也在文件开关标明编码方式采用 utf8。在 Python3 中，所有字符串默认都是 unicode 字符串，前缀是否带 u 问题不大。\n2、r例如：r&quot;msg.*?\\((.*)\\)&quot;、r&#39;C:\\app\\userdata&#39;，不开启反斜杠的转义机制。\n3、b表示 bytes 对象，用在 Python3 中。Python3 里默认的 str 是 unicode 类。Python2 的 str 就是 bytes 类。\n\nPython3 中，bytes 和 str 的互相转换：\n\nstr.encode(&#x27;utf-8&#x27;)bytes.decode(&#x27;utf-8&#x27;)\n\n4、f例如：f&quot;server received: &#123;data&#125;&quot;，Python3.6 新加特性：格式化字符串。支持在大括号内，运行 Python 表达式。\n","categories":["后端技术","python"],"tags":["python"]},{"title":"使用 poetry 进行依赖管理","url":"/97819500-a133-11ee-9970-39bf61dae061/","content":"\n\n\n\n官网：https://python-poetry.org/\n1、安装及使用1）执行 pip install poetry\n\n最好全局安装，不同项目之间切换时不用重复激活和安装依赖，比较方便。\n\n2）如果是新项目，则可使用 poetry 初始化。执行 poetry new poetry-demo，项目结构如下：\npoetry-demo├── pyproject.toml├── README.md├── poetry_demo│   └── __init__.py└── tests    └── __init__.py\n\n3）如果是既有项目引入 poetry，可在项目根目录执行 poetry init，通过互动配置生成 pyproject.toml 文件。\n\nwin 环境下，默认虚拟环境在 C:\\Users\\用户名\\AppData\\Local\\pypoetry\\Cache\\virtualenvs 目录下，虚拟环境名称会包含项目名称。\n\n2、常用命令\npoetry shell，进入虚拟环境\n\n\n注意：poetry 2.0.0 后该命令变更为插件，需另外安装 poetry self add poetry-plugin-shell。详见 issues#9962\n\n根据 pyproject.toml 文件来确定需要启动的虚拟环境。\n\npoetry install，安装全部依赖。\n\n例如从远程仓库 clone 的项目不包含依赖，执行该命令则按 poetry.lock 新建。\n\npoetry install --no-dev，安装非开发环境的依赖，部署时使用\n\npoetry add &lt;name&gt;，引入依赖，会同时更新 poetry.lock 文件\n\n\n\n可指定为开发时依赖：poetry add &lt;name&gt; --dev，将添加到 [tool.poetry.dev-dependencies] 区域\n\n\npoetry lock，更新 poetry.lock 文件\n\n如果手工修改了 pyproject.toml，比如指定特定模块的版本，此时 poetry.lock 的内容与 pyproject.toml 出现了脱钩，应执行上述命令保持两者一致。注意：该命令仅更新文件，不会安装模块至虚拟环境，要再使用 poetry install 安装模块。\n因此，在执行完 poetry lock 指令后，必须再使用 poetry install 来安装模块\n\npoetry update，更新依赖，或 poetry update requests 指定更新某个依赖\n\npoetry show，列出当前环境已安装依赖，或 poetry show -t 以树形结构查看\n\n\n\n显示的是 poetry.lock 的内容\n\n\npoetry show --tree，树状显示模块依赖层级，或 poetry show requests --tree 仅显示指定模块的依赖层级\n\npoetry remove &lt;name&gt;，移除依赖\n\npoetry config --list，查看 poetry 配置\n\npoetry source show，显示下载源\n\npoetry source remove &lt;源名称&gt;，删除下载源\n\n&#96;&#96;\n\n\n3、实用设置1）将虚拟环境建立在项目目录下。\n\n使用 poetry config --list 指令查看当前配置，如下所示；\n执行 poetry config virtualenvs.in-project true，修改配置，将虚拟环境建立在项目目录；\n执行 poetry env remove python 删除默认路径的虚拟环境；\n执行 poetry env use python 重建虚拟环境，名称为 .venv\n\nUsing version ^2.1.4 for pandascache-dir = &quot;C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\pypoetry\\\\Cache&quot;experimental.system-git-client = falseinstaller.max-workers = nullinstaller.modern-installation = trueinstaller.no-binary = nullinstaller.parallel = truerepositories.tsinghua.url = &quot;https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/&quot;virtualenvs.create = truevirtualenvs.in-project = nullvirtualenvs.options.always-copy = falsevirtualenvs.options.no-pip = falsevirtualenvs.options.no-setuptools = falsevirtualenvs.options.system-site-packages = falsevirtualenvs.path = &quot;&#123;cache-dir&#125;\\\\virtualenvs&quot;  # C:\\Users\\Admin\\AppData\\Local\\pypoetry\\Cache\\virtualenvsvirtualenvs.prefer-active-python = falsevirtualenvs.prompt = &quot;&#123;project_name&#125;-py&#123;python_version&#125;&quot;warnings.export = true\n\n\n虚拟环境在项目目录时，注意添加 .venv 到 .gitignore\n\n2）增加下载源\n使用默认源有时会出现连接超时的情况，可执行 poetry source add &lt;source_name&gt; &lt;source_url&gt; 添加任一国内源解决这个问题：\n\npoetry source add aliyun https://mirrors.aliyun.com/pypi/simple/，添加阿里源【首选】\npoetry source add tsinghua https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/，添加清华源\npoetry source add tencent https://mirrors.cloud.tencent.com/pypi/simple/，添加腾讯源\n\n\n命令参数可见 https://python-poetry.org/docs/cli#source\n\n4、其他1）当添加自定义源后，可能会遇到如下警告：\nWarning: In a future version of Poetry, PyPI will be disabled automatically if at least one custom primary source is configured. In order to avoid a breaking change and make your pyproject.toml forward compatible, add PyPI explicitly via &#x27;poetry source add pypi&#x27;. By the way, this has the advantage that you can set the priority of PyPI as with any other source.警告：在未来版本的 Poetry 中，如果配置了至少一个自定义主源，PyPI 将被自动禁用。为了避免破坏性更改并使 pyproject.toml 向前兼容，请通过 &#x27;poetry source add pypi&#x27; 显式地添加 PyPI。顺便说一下，这样做的好处是你可以像使用任何其他源一样设置 PyPI 的优先级。\n\n按照提示，执行 poetry source add pypi 即可。\n","categories":["后端技术","python"],"tags":["poetry"]},{"title":"MySQL-8.x-问题处理汇总","url":"/ef12f513-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n\n● MySQL 8.0.15 报 SSLException 异常问题描述该问题可能会导致连接关闭，\nSun May 12 22:08:48 CST 2019 WARN: Caught while disconnecting...EXCEPTION STACK TRACE:** BEGIN NESTED EXCEPTION **javax.net.ssl.SSLExceptionMESSAGE: closing inbound before receiving peer&#x27;s close_notifySTACKTRACE:javax.net.ssl.SSLException: closing inbound before receiving peer&#x27;s close_notify\tat java.base/sun.security.ssl.Alert.createSSLException(Alert.java:133)\tat java.base/sun.security.ssl.Alert.createSSLException(Alert.java:117)\tat java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:308)\tat java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:264)\tat java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:255)\tat java.base/sun.security.ssl.SSLSocketImpl.shutdownInput(SSLSocketImpl.java:645)\tat java.base/sun.security.ssl.SSLSocketImpl.shutdownInput(SSLSocketImpl.java:624)\tat com.mysql.cj.protocol.a.NativeProtocol.quit(NativeProtocol.java:1319)\tat com.mysql.cj.NativeSession.quit(NativeSession.java:182)\tat com.mysql.cj.jdbc.ConnectionImpl.realClose(ConnectionImpl.java:1750)\tat com.mysql.cj.jdbc.ConnectionImpl.close(ConnectionImpl.java:720)\tat com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection(PoolBase.java:132)\tat com.zaxxer.hikari.pool.HikariPool.lambda$closeConnection$1(HikariPool.java:434)\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\tat java.base/java.lang.Thread.run(Thread.java:834)** END NESTED EXCEPTION **\n\n解决方案数据库 URL 需要声明是否使用 SSL 安全验证及指定服务器上的时区，将 useSSL 设置为 false，即：?useSSL=false&amp;serverTimezone=UTC&quot;\n● MySQL 8.0.15 驱动类名称问题描述旧版驱动类是 com.mysql.jdbc.Driver，但是如果在 8.0 还继续用这个类，就会提示：\nLoading class `com.mysql.jdbc.Driver&#x27;. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver&#x27;. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.\n\n解决方案需要用新的驱动类，在配置文件中改为：driver=com.mysql.cj.jdbc.Driver\n● MySQL 8.0.15 时区指定问题描述驱动类正确，但是报错：\njava.sql.SQLException: The server time zone value &#x27;ÖÐ¹ú±ê×¼Ê±¼ä&#x27; is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the serverTimezone configuration property) to use a more specifc time zone value if you want to utilize time zone support.\n\n解决方案手动指定时区，如果服务器也是东八区（GMT+8），那么在 URL 后面加上参数 serverTimezone=GMT%2B8 即可：\nurl=jdbc:mysql://localhost:3306/test?serverTimezone=GMT%2B8\n\n● MySQL 8.0.15 getTables 默认返回所有库的表问题描述8.0 及以上版本的驱动默认将 nullCatalogMeansCurrent 的默认值由 true 改为了 false，如果使用 DatabaseMetaData 类的对象调用 getTables 方法，就会返回所有库的表，而非在 url 参数中指定的数据库（本例中数据库名为 test）\n解决方案手动在参数中指定 nullCatalogMeansCurrent 值为 true\nurl=jdbc:mysql://localhost:3306/test?serverTimezone=GMT%2B8&amp;useSSL=false&amp;useSSL=false&amp;allowPublicKeyRetrieval=true&amp;nullCatalogMeansCurrent=true\n\n● SpringBoot 连接 MySql 8.x 时出现 CLIENT_PLUGIN_AUTH is required 异常问题描述SpringBoot 连接 MySql 8.x 时出现 CLIENT_PLUGIN_AUTH is required 异常\n解决方案修改 mysql-connector-java 依赖版本为低版本，如：\n// https://mvnrepository.com/artifact/mysql/mysql-connector-javacompile group: &#x27;mysql&#x27;, name: &#x27;mysql-connector-java&#x27;, version: &#x27;5.1.47&#x27;\n\n● MySQL 8.0.15 SSL问题描述关闭连接对象时会产生的一个无关紧要的报错，不解决也可以正常使用，会占据控制台的大量篇幅，导致使用体验极差：\njavax.net.ssl.SSLExceptionMESSAGE: closing inbound before receiving peer&#x27;s close_notify\n\n解决方案MySQL 8.0 开始，数据库 URL 需要设置是否使用 SSL 安全连接，在 URL 后面加上参数 useSSL&#x3D;false 即可，多个参数键值对中间用 &amp; 隔开：\nurl=jdbc:mysql://localhost:3306/test?serverTimezone=GMT%2B8&amp;useSSL=false\n\n● MySQL 8.0.15 Public Key Retrieval 报错问题描述重启服务器后出现 Public Key Retrieval 报错：\njava.sql.SQLNonTransientConnectionException: Public Key Retrieval is not allowed\n\n解决方案在 URL 后加上 allowPublicKeyRetrieval=true 即可\nurl=jdbc:mysql://localhost:3306/test?serverTimezone=GMT%2B8&amp;useSSL=false&amp;allowPublicKeyRetrieval=true\n\n● 使用可视化客户端连接 MySQL 时出现 2058 错误解决方案MySQL 8.0 采用了 caching_sha2_password 加密，是 sha256 的改进版加密方式，多数第三方客户端都不支持这种加密方式，自带的命令行可支持。具体可参看 官方文档 有关该内容说明。要解决该问题，需要修改加密方式。以 root 用户为例，如果要配置其他用户或授权 IP，对应修改名称和地址即可。\nALTER USER &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;password&#x27;;\n","categories":["后端技术","数据库"],"tags":["mysql"]},{"title":"MySQL 使用存储过程批量建表","url":"/ef131c21-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n\n需求建立 data_0 开始，到 data_9 共 10 张表，各表的字段结构、数据引擎、编码方式等均相同。\n解决方案使用如下存储过程：\nDELIMITER //CREATE PROCEDURE create_table()BEGINDECLARE `@i` INT(11);DECLARE `@sqlstr` VARCHAR(2560);SET `@i`=0;WHILE `@i` &lt; 10 DOSET @sqlstr = CONCAT(&quot;CREATE TABLE data_&quot;,`@i`,&quot;(`ID` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT,  `field1` VARCHAR(6) NOT NULL,  `field2` VARCHAR(10) NOT NULL,  `field3` VARCHAR(10) NOT NULL,  `field4` VARCHAR(10) NOT NULL,  `field5` VARCHAR(10) NOT NULL,  PRIMARY KEY (`ID`)) ENGINE=INNODB DEFAULT CHARSET=utf8 &quot;);PREPARE stmt FROM @sqlstr;EXECUTE stmt;SET `@i` = `@i` + 1;END WHILE;END;\n\n执行存储过程，执行后删除存储过程并恢复默认命令结束符：\nCALL create_table();DROP PROCEDURE create_table;DELIMITER ;\n\n注意事项创建存储过程时，若采用命令行的方式，要先修改默认命令结束符，这样将 CREATE 到 END 之间的代码当是一条语句来执行。例如上述代码中的 DELIMITER //，将命令结束符修改为 //，执行结束后再修改回 ;。\n","categories":["后端技术","数据库"],"tags":["mysql"]},{"title":"mariadb 报错 The total number of locks exceeds the lock table size 的解决","url":"/d0d9c500-5563-11ee-b900-f9a67c785a37/","content":"\n\n\n\n1、问题描述修改表某字段 decimal(10,2) 类型为 decimal(10,3)，该表数据量约 2 亿行。执行时报如题错误。\n2、解决方案1）执行 show variables like &quot;%_buffer%&quot;; 查看当前 innodb_buffer_pool_size 参数，默认为 134217728（128M）\n2）执行 SET GLOBAL innodb_buffer_pool_size= 1073741824，临时设置参数值为 1G\n3、参考文献\nhttps://www.cnblogs.com/innocenter/p/14948857.html\n\n","categories":["后端技术","数据库"],"tags":["mariadb"]},{"title":"oracle 12c 使用 WM_CONCAT 函数提示标识符无效","url":"/ef12f514-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n\n问题描述查询语句使用 WM_CONCAT 函数时报错：\nError querying database.  Cause: java.sql.SQLSyntaxErrorException: ORA-00904: &quot;WM_CONCAT&quot;: 标识符无效\n\n解决方案11gR2 和 12c 上已经摒弃了该函数，在程序中若使用该函数，将导致程序出现错误\n\n在我们需要将某字段多行内容拼接起来的时候，wm_concat 提供了简洁的方法，这使得这个未公开的函数得到了广泛的宣传与运用。但是，不公开就意味着随时可能发生变更。在 10.2.0.5 上，其返回类型从 varchar2 变为了 clob，而在 12c 当中，干脆就取消了此函数。同样未公开的，还有 reverse 函数。\n\n用 listagg 函数替代，效果相同。\n","categories":["后端技术","数据库"],"tags":["oracle"]},{"title":"oracle、postgresql、mysql行转列的内置函数","url":"/8a9db7f2-e38d-11ee-8d05-110f62540784/","content":"\n\n\n\n1、需求描述查询人员的年龄\nselect t.age,t.name from table_name t where t.age = 20;\n\n\n\n\nage\nname\n\n\n\n16\nJack\n\n\n16\nJones\n\n\n16\nMark\n\n\n16\nLucy\n\n\n16\nAdams\n\n\n要达到的效果：\n\n\n\nage\nnames\n\n\n\n16\nJack,Jones,Mark,Lucy,Adams\n\n\n2、解决方案1）oracle：listagg() within group()\nselect t.age, listagg(t.name, &#x27;,&#x27;) within group (order by t.name) namesfrom table_name twhere t.age = 20 group by t.age\n\n2） postgresql：string_agg()\nselect t.age, string_agg(t.name, &#x27;,&#x27;) as namesfrom table_name twhere t.age = 20 group by t.age\n\n3） mysql：group_concat()\nselect t.age, group_concat(t.name order by t.name separator &#x27;,&#x27;) as namesfrom table_name twhere t.age = 20 group by t.age\n","categories":["后端技术","数据库"],"tags":["mysql","postgresql","oracle"]},{"title":"触发器案例（MySQL）","url":"/ef131c20-4937-11ee-861d-b3cf05b530a5/","content":"\n\n\n\n\nMySQL 包含对触发器的支持。触发器是一种与表操作有关的数据库对象，当触发器所在表上出现指定事件时，将调用该对象，即表的操作事件触发表上的触发器的执行。\n创建触发器在 MySQL 中，创建触发器语法如下：\nCREATE TRIGGER trigger_nametrigger_timetrigger_event ON tbl_nameFOR EACH ROWtrigger_stmt\n\n其中：\n\ntrigger_name：标识触发器名称，用户自行指定；\ntrigger_time：标识触发时机，取值为 BEFORE 或 AFTER；\ntrigger_event：标识触发事件，取值为 INSERT、UPDATE 或 DELETE；\ntbl_name：标识建立触发器的表名，即在哪张表上建立触发器；\ntrigger_stmt：触发器程序体，可以是一句 SQL 语句，或者用 BEGIN 和 END 包含的多条语句。\n\n由此可见，可以建立 6 种触发器，即：BEFORE INSERT、BEFORE UPDATE、BEFORE DELETE、AFTER INSERT、AFTER UPDATE、AFTER DELETE。\n另外有一个限制是不能同时在一个表上建立 2 个相同类型的触发器，因此在一个表上最多建立 6 个触发器。\ntrigger_eventMySQL 除了对 INSERT、UPDATE、DELETE 基本操作进行定义外，还定义了 LOAD DATA 和 REPLACE 语句，这两种语句也能引起上述 6 中类型的触发器的触发。\nLOAD DATA 语句用于将一个文件装入到一个数据表中，相当与一系列的 INSERT 操作。\nREPLACE 语句一般来说和 INSERT 语句很像，只是在表中有 primary key 或 unique 索引时，如果插入的数据和原来 primary key 或 unique 索引一致时，会先删除原来的数据，然后增加一条新数据，也就是说，一条 REPLACE 语句有时候等价于一条。\nINSERT 语句，有时候等价于一条 DELETE 语句加上一条 INSERT 语句。\n\nINSERT 型触发器：插入某一行时激活触发器，可能通过 INSERT、LOAD DATA、REPLACE 语句触发；\nUPDATE 型触发器：更改某一行时激活触发器，可能通过 UPDATE 语句触发；\nDELETE 型触发器：删除某一行时激活触发器，可能通过 DELETE、REPLACE 语句触发。\n\nBEGIN … END在 MySQL 中，BEGIN … END 语句的语法为：\nBEGIN[statement_list]END\n\n其中，statement_list 代表一个或多个语句的列表，列表内的每条语句都必须用分号（;）来结尾。而在 MySQL 中，分号是语句结束的标识符，遇到分号表示该段语句已经结束，MySQL 可以开始执行了。因此，解释器遇到 statement_list 中的分号后就开始执行，然后会报出错误，因为没有找到和 BEGIN 匹配的 END。\n这时就会用到 DELIMITER 命令（DELIMITER 是定界符，分隔符的意思），它是一条命令，不需要语句结束标识，语法为：DELIMITER new_delemiter。new_delemiter 可以设为 1 个或多个长度的符号，默认的是分号（;），我们可以把它修改为其他符号，如$：DELIMITER $，在这之后的语句，以分号结束，解释器不会有什么反应，只有遇到了$，才认为是语句结束。注意，使用完之后，我们还应该记得把它给修改回来。\n案例假设系统中有两个表：\n\n班级表 class(班级号 classID, 班内学生数 stuCount)\n学生表 student(学号 stuID, 所属班级号 classID)\n\n要创建触发器来使班级表中的班内学生数随着学生的添加自动更新，代码如下：\nDELIMITER $create trigger tri_stuInsert after inserton student for each rowbegindeclare c int;set c = (select stuCount from class where classID=new.classID);update class set stuCount = c + 1 where classID = new.classID;end$DELIMITER ;\n\nMySQL 中使用 DECLARE 来定义一局部变量，该变量只能在 BEGIN … END 复合语句中使用，并且应该定义在复合语句的开头，即其它语句之前，语法如下：\nDECLARE var_name[,...] type [DEFAULT value]\n\n其中，var_name 为变量名称，同 SQL 语句一样，变量名不区分大小写；type 为 MySQL 支持的任何数据类型；可以同时定义多个同类型的变量，用逗号隔开；变量初始值为 NULL，如果需要，可以使用 DEFAULT 子句提供默认值，值可以被指定为一个表达式。\n对变量赋值采用 SET 语句，语法为：SET var_name = expr [,var_name = expr] ...\nNEW 与 OLD 详解上述示例中使用了 NEW 关键字，和 MS SQL Server 中的 INSERTED 和 DELETED 类似，MySQL 中定义了 NEW 和 OLD，用来表示触发器的所在表中，触发了触发器的那一行数据。具体地：\n\n在 INSERT 型触发器中，NEW 用来表示将要（BEFORE）或已经（AFTER）插入的新数据；\n在 UPDATE 型触发器中，OLD 用来表示将要或已经被修改的原数据，NEW 用来表示将要或已经修改为的新数据；\n在 DELETE 型触发器中，OLD 用来表示将要或已经被删除的原数据；\n\n使用方法： NEW.columnName （columnName 为相应数据表某一列名）。另外，OLD 是只读的，而 NEW 则可以在触发器中使用 SET 赋值，这样不会再次触发触发器，造成循环调用（如每插入一个学生前，都在其学号前加“2013”）。\n查看触发器和查看数据库（show databases;）查看表格（show tables;）一样，查看触发器的语法如下：\nSHOW TRIGGERS [FROM schema_name];\n\n其中，schema_name 即 Schema 的名称，在 MySQL 中 Schema 和 Database 是一样的，也就是说，可以指定数据库名，这样就\n不必先“USE database_name;”了。\n删除触发器和删除数据库、删除表格一样，删除触发器的语法如下：\nDROP TRIGGER [IF EXISTS][schema_name.]trigger_name\n\n触发器的执行顺序我们建立的数据库一般都是 InnoDB 数据库，其上建立的表是事务性表，也就是事务安全的。这时，若 SQL 语句或触发器执行失败，MySQL 会回滚事务，有：\n\n如果 BEFORE 触发器执行失败，SQL 无法正确执行。\nSQL 执行失败时，AFTER 型触发器不会触发。\nAFTER 类型的触发器执行失败，SQL 会回滚。\n\n","categories":["后端技术","数据库"],"tags":["mysql"]}]